<?xml version="1.0"?>
<doc>
    <assembly>
        <name>OpenAI.Official</name>
    </assembly>
    <members>
        <member name="T:OpenAI.Official.Embedding">
            <summary>
            Represents an embedding vector returned by embedding endpoint.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Embedding.Vector">
            <summary>
            The embedding vector, which is a list of floats.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Embedding.Index">
            <inheritdoc cref="P:OpenAI.Official.Internal.Embedding.Index"/>
        </member>
        <member name="P:OpenAI.Official.Embedding.Usage">
            <inheritdoc cref="P:OpenAI.Official.Internal.CreateEmbeddingResponse.Usage"/>
        </member>
        <member name="T:OpenAI.Official.EmbeddingClient">
            <summary> The service client for the OpenAI Embeddings endpoint. </summary>
        </member>
        <member name="M:OpenAI.Official.EmbeddingClient.GenerateEmbeddings(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <inheritdoc cref="M:OpenAI.Official.Internal.Embeddings.CreateEmbedding(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)"/>
        </member>
        <member name="M:OpenAI.Official.EmbeddingClient.GenerateEmbeddingsAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <inheritdoc cref="M:OpenAI.Official.Internal.Embeddings.CreateEmbeddingAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)"/>
        </member>
        <member name="T:OpenAI.Official.EmbeddingClientOptions">
            <summary>
            Client-level options for OpenAI Embeddings.
            </summary>
        </member>
        <member name="P:OpenAI.Official.EmbeddingOptions.User">
            <inheritdoc cref="P:OpenAI.Official.Internal.CreateEmbeddingRequest.User"/>
        </member>
        <member name="P:OpenAI.Official.EmbeddingOptions.Dimensions">
            <inheritdoc cref="P:OpenAI.Official.Internal.CreateEmbeddingRequest.Dimensions"/>
        </member>
        <member name="P:OpenAI.Official.EmbeddingTokenUsage.InputTokens">
            <inheritdoc cref="P:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.PromptTokens"/>
        </member>
        <member name="P:OpenAI.Official.EmbeddingTokenUsage.TotalTokens">
            <inheritdoc cref="P:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.TotalTokens"/>
        </member>
        <member name="T:OpenAI.Official.OpenAIClientOptions">
            <summary>
            Client-level options for the OpenAI service.
            </summary>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.CancellationToken">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.CancellationToken"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.ErrorBehavior">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.ErrorBehavior"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.PerTryPolicies">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.PerTryPolicies"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.PerCallPolicies">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.PerCallPolicies"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.RetryPolicy">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.RetryPolicy"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.LoggingPolicy">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.LoggingPolicy"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.Transport">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.Transport"/>
        </member>
        <member name="P:OpenAI.Official.OpenAIClientOptions.BufferResponse">
            <inheritdoc cref="P:System.ClientModel.RequestOptions.BufferResponse"/>
        </member>
        <member name="T:OpenAI.Official.Internal.AssistantFileObject">
            <summary> A list of [Files](/docs/api-reference/files) attached to an `assistant`. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.AssistantFileObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObject.#ctor(System.String,System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantFileObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant file was created. </param>
            <param name="assistantId"> The assistant ID that the file is attached to. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="assistantId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObject.#ctor(System.String,OpenAI.Official.Internal.AssistantFileObjectObject,System.DateTimeOffset,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantFileObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `assistant.file`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant file was created. </param>
            <param name="assistantId"> The assistant ID that the file is attached to. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantFileObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantFileObject.Id">
            <summary> The identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantFileObject.Object">
            <summary> The object type, which is always `assistant.file`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantFileObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the assistant file was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantFileObject.AssistantId">
            <summary> The assistant ID that the file is attached to. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.AssistantFileObjectObject">
            <summary> The AssistantFileObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantFileObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantFileObjectObject.AssistantFile">
            <summary> assistant.file. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.op_Equality(OpenAI.Official.Internal.AssistantFileObjectObject,OpenAI.Official.Internal.AssistantFileObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.AssistantFileObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.op_Inequality(OpenAI.Official.Internal.AssistantFileObjectObject,OpenAI.Official.Internal.AssistantFileObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.AssistantFileObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.AssistantFileObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.AssistantFileObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.Equals(OpenAI.Official.Internal.AssistantFileObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantFileObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.AssistantObject">
            <summary> Represents an `assistant` that can call the model and use tools. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.AssistantObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObject.#ctor(System.String,System.DateTimeOffset,System.String,System.String,System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant was created. </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="model"/>, <paramref name="tools"/> or <paramref name="fileIds"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObject.#ctor(System.String,OpenAI.Official.Internal.AssistantObjectObject,System.DateTimeOffset,System.String,System.String,System.String,System.String,System.Collections.Generic.IReadOnlyList{System.BinaryData},System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `assistant`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant was created. </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Id">
            <summary> The identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Object">
            <summary> The object type, which is always `assistant`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the assistant was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Name">
            <summary> The name of the assistant. The maximum length is 256 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Description">
            <summary> The description of the assistant. The maximum length is 512 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Model">
            <summary>
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Instructions">
            <summary> The system instructions that the assistant uses. The maximum length is 32768 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Tools">
            <summary>
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.FileIds">
            <summary>
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObject.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.AssistantObjectObject">
            <summary> The AssistantObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AssistantObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.AssistantObjectObject.Assistant">
            <summary> assistant. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.op_Equality(OpenAI.Official.Internal.AssistantObjectObject,OpenAI.Official.Internal.AssistantObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.AssistantObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.op_Inequality(OpenAI.Official.Internal.AssistantObjectObject,OpenAI.Official.Internal.AssistantObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.AssistantObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.AssistantObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.AssistantObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.Equals(OpenAI.Official.Internal.AssistantObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.AssistantObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Assistants">
            <summary> The Assistants sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Assistants.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Assistants.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.#ctor">
            <summary> Initializes a new instance of Assistants for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Assistants. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantAsync(OpenAI.Official.Internal.CreateAssistantRequest,System.Threading.CancellationToken)">
            <summary> Create an assistant with a model and instructions. </summary>
            <param name="assistant"> The <see cref="T:OpenAI.Official.Internal.CreateAssistantRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistant"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistant(OpenAI.Official.Internal.CreateAssistantRequest,System.Threading.CancellationToken)">
            <summary> Create an assistant with a model and instructions. </summary>
            <param name="assistant"> The <see cref="T:OpenAI.Official.Internal.CreateAssistantRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistant"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create an assistant with a model and instructions.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.CreateAssistantAsync(OpenAI.Official.Internal.CreateAssistantRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistant(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create an assistant with a model and instructions.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.CreateAssistant(OpenAI.Official.Internal.CreateAssistantRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantsAsync(System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of assistants. </summary>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistants(System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of assistants. </summary>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantsAsync(System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of assistants.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantsAsync(System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistants(System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of assistants.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistants(System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantAsync(System.String,System.Threading.CancellationToken)">
            <summary> Retrieves an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistant(System.String,System.Threading.CancellationToken)">
            <summary> Retrieves an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistant(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistant(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.ModifyAssistantAsync(System.String,OpenAI.Official.Internal.ModifyAssistantRequest,System.Threading.CancellationToken)">
            <summary> Modifies an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to modify. </param>
            <param name="assistant"> The <see cref="T:OpenAI.Official.Internal.ModifyAssistantRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="assistant"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.ModifyAssistant(System.String,OpenAI.Official.Internal.ModifyAssistantRequest,System.Threading.CancellationToken)">
            <summary> Modifies an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to modify. </param>
            <param name="assistant"> The <see cref="T:OpenAI.Official.Internal.ModifyAssistantRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="assistant"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.ModifyAssistantAsync(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.ModifyAssistantAsync(System.String,OpenAI.Official.Internal.ModifyAssistantRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.ModifyAssistant(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.ModifyAssistant(System.String,OpenAI.Official.Internal.ModifyAssistantRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantAsync(System.String,System.Threading.CancellationToken)">
            <summary> Delete an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistant(System.String,System.Threading.CancellationToken)">
            <summary> Delete an assistant. </summary>
            <param name="assistantId"> The ID of the assistant to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.DeleteAssistantAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistant(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete an assistant.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.DeleteAssistant(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantFileAsync(System.String,OpenAI.Official.Internal.CreateAssistantFileRequest,System.Threading.CancellationToken)">
            <summary>
            Create an assistant file by attaching a [File](/docs/api-reference/files) to a
            [assistant](/docs/api-reference/assistants).
            </summary>
            <param name="assistantId"> The ID of the assistant for which to create a file. </param>
            <param name="file"> The <see cref="T:OpenAI.Official.Internal.CreateAssistantFileRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="file"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantFile(System.String,OpenAI.Official.Internal.CreateAssistantFileRequest,System.Threading.CancellationToken)">
            <summary>
            Create an assistant file by attaching a [File](/docs/api-reference/files) to a
            [assistant](/docs/api-reference/assistants).
            </summary>
            <param name="assistantId"> The ID of the assistant for which to create a file. </param>
            <param name="file"> The <see cref="T:OpenAI.Official.Internal.CreateAssistantFileRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="file"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantFileAsync(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create an assistant file by attaching a [File](/docs/api-reference/files) to a
            [assistant](/docs/api-reference/assistants).
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.CreateAssistantFileAsync(System.String,OpenAI.Official.Internal.CreateAssistantFileRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant for which to create a file. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.CreateAssistantFile(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create an assistant file by attaching a [File](/docs/api-reference/files) to a
            [assistant](/docs/api-reference/assistants).
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.CreateAssistantFile(System.String,OpenAI.Official.Internal.CreateAssistantFileRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant for which to create a file. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFilesAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of assistant files. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFiles(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of assistant files. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFilesAsync(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of assistant files.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantFilesAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFiles(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of assistant files.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantFiles(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFileAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves an assistant file. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file we're getting. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFile(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves an assistant file. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file we're getting. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFileAsync(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves an assistant file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantFileAsync(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file we're getting. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.GetAssistantFile(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves an assistant file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.GetAssistantFile(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file we're getting. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFileAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Delete an assistant file. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFile(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Delete an assistant file. </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFileAsync(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete an assistant file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFileAsync(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFile(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete an assistant file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Assistants.DeleteAssistantFile(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="assistantId"> The ID of the assistant the file belongs to. </param>
            <param name="fileId"> The ID of the file to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="assistantId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.Audio">
            <summary> The Audio sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Audio.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Audio.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.#ctor">
            <summary> Initializes a new instance of Audio for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Audio. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateSpeechAsync(OpenAI.Official.Internal.CreateSpeechRequest,System.Threading.CancellationToken)">
            <summary> Generates audio from the input text. </summary>
            <param name="speech"> The <see cref="T:OpenAI.Official.Internal.CreateSpeechRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="speech"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateSpeech(OpenAI.Official.Internal.CreateSpeechRequest,System.Threading.CancellationToken)">
            <summary> Generates audio from the input text. </summary>
            <param name="speech"> The <see cref="T:OpenAI.Official.Internal.CreateSpeechRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="speech"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateSpeechAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Generates audio from the input text.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateSpeechAsync(OpenAI.Official.Internal.CreateSpeechRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateSpeech(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Generates audio from the input text.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateSpeech(OpenAI.Official.Internal.CreateSpeechRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranscriptionAsync(OpenAI.Official.Internal.CreateTranscriptionRequest,System.Threading.CancellationToken)">
            <summary> Transcribes audio into the input language. </summary>
            <param name="audio"> The <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="audio"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranscription(OpenAI.Official.Internal.CreateTranscriptionRequest,System.Threading.CancellationToken)">
            <summary> Transcribes audio into the input language. </summary>
            <param name="audio"> The <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="audio"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranscriptionAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Transcribes audio into the input language.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateTranscriptionAsync(OpenAI.Official.Internal.CreateTranscriptionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranscription(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Transcribes audio into the input language.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateTranscription(OpenAI.Official.Internal.CreateTranscriptionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranslationAsync(OpenAI.Official.Internal.CreateTranslationRequest,System.Threading.CancellationToken)">
            <summary> Translates audio into English.. </summary>
            <param name="audio"> The <see cref="T:OpenAI.Official.Internal.CreateTranslationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="audio"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranslation(OpenAI.Official.Internal.CreateTranslationRequest,System.Threading.CancellationToken)">
            <summary> Translates audio into English.. </summary>
            <param name="audio"> The <see cref="T:OpenAI.Official.Internal.CreateTranslationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="audio"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranslationAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Translates audio into English..
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateTranslationAsync(OpenAI.Official.Internal.CreateTranslationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Audio.CreateTranslation(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Translates audio into English..
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Audio.CreateTranslation(OpenAI.Official.Internal.CreateTranslationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.AudioSegment">
            <summary> The AudioSegment. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.AudioSegment._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AudioSegment.#ctor(System.Int64,System.Int64,System.TimeSpan,System.TimeSpan,System.String,System.Collections.Generic.IEnumerable{System.Int64},System.Double,System.Double,System.Double,System.Double)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AudioSegment"/>. </summary>
            <param name="id"> The zero-based index of this segment. </param>
            <param name="seek">
            The seek position associated with the processing of this audio segment. Seek positions are
            expressed as hundredths of seconds. The model may process several segments from a single seek
            position, so while the seek position will never represent a later time than the segment's
            start, the segment's start may represent a significantly later time than the segment's
            associated seek position.
            </param>
            <param name="start"> The time at which this segment started relative to the beginning of the audio. </param>
            <param name="end"> The time at which this segment ended relative to the beginning of the audio. </param>
            <param name="text"> The text that was part of this audio segment. </param>
            <param name="tokens"> The token IDs matching the text in this audio segment. </param>
            <param name="temperature"> The temperature score associated with this audio segment. </param>
            <param name="avgLogprob"> The average log probability associated with this audio segment. </param>
            <param name="compressionRatio"> The compression ratio of this audio segment. </param>
            <param name="noSpeechProb"> The probability of no speech detection within this audio segment. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="text"/> or <paramref name="tokens"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.AudioSegment.#ctor(System.Int64,System.Int64,System.TimeSpan,System.TimeSpan,System.String,System.Collections.Generic.IReadOnlyList{System.Int64},System.Double,System.Double,System.Double,System.Double,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AudioSegment"/>. </summary>
            <param name="id"> The zero-based index of this segment. </param>
            <param name="seek">
            The seek position associated with the processing of this audio segment. Seek positions are
            expressed as hundredths of seconds. The model may process several segments from a single seek
            position, so while the seek position will never represent a later time than the segment's
            start, the segment's start may represent a significantly later time than the segment's
            associated seek position.
            </param>
            <param name="start"> The time at which this segment started relative to the beginning of the audio. </param>
            <param name="end"> The time at which this segment ended relative to the beginning of the audio. </param>
            <param name="text"> The text that was part of this audio segment. </param>
            <param name="tokens"> The token IDs matching the text in this audio segment. </param>
            <param name="temperature"> The temperature score associated with this audio segment. </param>
            <param name="avgLogprob"> The average log probability associated with this audio segment. </param>
            <param name="compressionRatio"> The compression ratio of this audio segment. </param>
            <param name="noSpeechProb"> The probability of no speech detection within this audio segment. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AudioSegment.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.AudioSegment"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Id">
            <summary> The zero-based index of this segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Seek">
            <summary>
            The seek position associated with the processing of this audio segment. Seek positions are
            expressed as hundredths of seconds. The model may process several segments from a single seek
            position, so while the seek position will never represent a later time than the segment's
            start, the segment's start may represent a significantly later time than the segment's
            associated seek position.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Start">
            <summary> The time at which this segment started relative to the beginning of the audio. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.End">
            <summary> The time at which this segment ended relative to the beginning of the audio. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Text">
            <summary> The text that was part of this audio segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Tokens">
            <summary> The token IDs matching the text in this audio segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.Temperature">
            <summary> The temperature score associated with this audio segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.AvgLogprob">
            <summary> The average log probability associated with this audio segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.CompressionRatio">
            <summary> The compression ratio of this audio segment. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.AudioSegment.NoSpeechProb">
            <summary> The probability of no speech detection within this audio segment. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.AudioSegment.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.AudioSegment.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.Chat">
            <summary> The Chat sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Chat.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Chat.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.#ctor">
            <summary> Initializes a new instance of Chat for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Chat. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.CreateChatCompletionAsync(OpenAI.Official.Internal.CreateChatCompletionRequest,System.Threading.CancellationToken)">
            <summary> Creates a model response for the given chat conversation. </summary>
            <param name="createChatCompletionRequest"> The <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="createChatCompletionRequest"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.CreateChatCompletion(OpenAI.Official.Internal.CreateChatCompletionRequest,System.Threading.CancellationToken)">
            <summary> Creates a model response for the given chat conversation. </summary>
            <param name="createChatCompletionRequest"> The <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="createChatCompletionRequest"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.CreateChatCompletionAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates a model response for the given chat conversation.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Chat.CreateChatCompletionAsync(OpenAI.Official.Internal.CreateChatCompletionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Chat.CreateChatCompletion(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates a model response for the given chat conversation.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Chat.CreateChatCompletion(OpenAI.Official.Internal.CreateChatCompletionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionFunctionCallOption">
            <summary>
            Specifying a particular function via `{"name": "my_function"}` forces the model to call that
            function.
            </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionFunctionCallOption._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctionCallOption"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctionCallOption"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctionCallOption"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctionCallOption.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionFunctions">
            <summary> The ChatCompletionFunctions. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionFunctions._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctions.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctions"/>. </summary>
            <param name="name">
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctions.#ctor(System.String,System.String,OpenAI.Official.Internal.FunctionParameters,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctions"/>. </summary>
            <param name="description">
            A description of what the function does, used by the model to choose when and how to call the
            function.
            </param>
            <param name="name">
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </param>
            <param name="parameters"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctions.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionFunctions"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionFunctions.Description">
            <summary>
            A description of what the function does, used by the model to choose when and how to call the
            function.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionFunctions.Name">
            <summary>
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionFunctions.Parameters">
            <summary> Gets or sets the parameters. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctions.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionFunctions.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionMessageToolCall">
            <summary> The ChatCompletionMessageToolCall. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionMessageToolCall._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCall.#ctor(System.String,OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCall"/>. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="function"> The function that the model called. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="function"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCall.#ctor(System.String,OpenAI.Official.Internal.ChatCompletionMessageToolCallType,OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCall"/>. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function that the model called. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCall.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCall"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCall.Id">
            <summary> The ID of the tool call. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCall.Type">
            <summary> The type of the tool. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCall.Function">
            <summary> The function that the model called. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCall.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCall.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction">
            <summary> The ChatCompletionMessageToolCallFunction. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> or <paramref name="arguments"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.Arguments">
            <summary>
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallType">
            <summary> The ChatCompletionMessageToolCall_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.op_Equality(OpenAI.Official.Internal.ChatCompletionMessageToolCallType,OpenAI.Official.Internal.ChatCompletionMessageToolCallType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.op_Inequality(OpenAI.Official.Internal.ChatCompletionMessageToolCallType,OpenAI.Official.Internal.ChatCompletionMessageToolCallType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.op_Implicit(System.String)~OpenAI.Official.Internal.ChatCompletionMessageToolCallType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ChatCompletionMessageToolCallType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.Equals(OpenAI.Official.Internal.ChatCompletionMessageToolCallType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionMessageToolCallType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoice">
            <summary> Specifies a tool the model should use. Use to force the model to call a specific function. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionNamedToolChoice._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.#ctor(OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoice"/>. </summary>
            <param name="function"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="function"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.#ctor(OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType,OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoice"/>. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoice"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.Type">
            <summary> The type of the tool. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.Function">
            <summary> Gets the function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoice.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction">
            <summary> The ChatCompletionNamedToolChoiceFunction. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction"/>. </summary>
            <param name="name"> The name of the function to call. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceFunction.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType">
            <summary> The ChatCompletionNamedToolChoice_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.op_Equality(OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType,OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.op_Inequality(OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType,OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.op_Implicit(System.String)~OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.Equals(OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionNamedToolChoiceType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionResponseMessage">
            <summary> The ChatCompletionResponseMessage. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionResponseMessage._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessage.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessage"/>. </summary>
            <param name="content"> The contents of the message. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessage.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.ChatCompletionMessageToolCall},OpenAI.Official.Internal.ChatCompletionResponseMessageRole,OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessage"/>. </summary>
            <param name="content"> The contents of the message. </param>
            <param name="toolCalls"></param>
            <param name="role"> The role of the author of this message. </param>
            <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessage.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessage"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessage.Content">
            <summary> The contents of the message. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessage.ToolCalls">
            <summary> Gets the tool calls. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessage.Role">
            <summary> The role of the author of this message. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessage.FunctionCall">
            <summary> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessage.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessage.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall">
            <summary> The ChatCompletionResponseMessageFunctionCall. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall"/>. </summary>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </param>
            <param name="name"> The name of the function to call. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="arguments"/> or <paramref name="name"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall"/>. </summary>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </param>
            <param name="name"> The name of the function to call. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.Arguments">
            <summary>
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.Name">
            <summary> The name of the function to call. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionResponseMessageRole">
            <summary> The ChatCompletionResponseMessage_role. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageRole"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.Assistant">
            <summary> assistant. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.op_Equality(OpenAI.Official.Internal.ChatCompletionResponseMessageRole,OpenAI.Official.Internal.ChatCompletionResponseMessageRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageRole"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.op_Inequality(OpenAI.Official.Internal.ChatCompletionResponseMessageRole,OpenAI.Official.Internal.ChatCompletionResponseMessageRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageRole"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.op_Implicit(System.String)~OpenAI.Official.Internal.ChatCompletionResponseMessageRole">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ChatCompletionResponseMessageRole"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.Equals(OpenAI.Official.Internal.ChatCompletionResponseMessageRole)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionResponseMessageRole.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionTokenLogprob">
            <summary> The ChatCompletionTokenLogprob. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionTokenLogprob._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprob.#ctor(System.String,System.Double,System.Collections.Generic.IEnumerable{System.Int64},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <param name="topLogprobs">
            List of the most likely tokens and their log probability, at this token position. In rare
            cases, there may be fewer than the number of requested `top_logprobs` returned.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="token"/> or <paramref name="topLogprobs"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprob.#ctor(System.String,System.Double,System.Collections.Generic.IReadOnlyList{System.Int64},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <param name="topLogprobs">
            List of the most likely tokens and their log probability, at this token position. In rare
            cases, there may be fewer than the number of requested `top_logprobs` returned.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprob.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprob"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprob.Token">
            <summary> The token. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprob.Logprob">
            <summary> The log probability of this token. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprob.Bytes">
            <summary>
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprob.TopLogprobs">
            <summary>
            List of the most likely tokens and their log probability, at this token position. In rare
            cases, there may be fewer than the number of requested `top_logprobs` returned.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprob.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprob.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob">
            <summary> The ChatCompletionTokenLogprobTopLogprob. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.#ctor(System.String,System.Double,System.Collections.Generic.IEnumerable{System.Int64})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="token"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.#ctor(System.String,System.Double,System.Collections.Generic.IReadOnlyList{System.Int64},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.Token">
            <summary> The token. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.Logprob">
            <summary> The log probability of this token. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.Bytes">
            <summary>
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionTool">
            <summary> The ChatCompletionTool. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ChatCompletionTool._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTool.#ctor(OpenAI.Official.Internal.FunctionObject)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTool"/>. </summary>
            <param name="function"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="function"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTool.#ctor(OpenAI.Official.Internal.ChatCompletionToolType,OpenAI.Official.Internal.FunctionObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTool"/>. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTool.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionTool"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTool.Type">
            <summary> The type of the tool. Currently, only `function` is supported. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionTool.Function">
            <summary> Gets the function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTool.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionTool.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ChatCompletionToolType">
            <summary> The ChatCompletionTool_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ChatCompletionToolType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ChatCompletionToolType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.op_Equality(OpenAI.Official.Internal.ChatCompletionToolType,OpenAI.Official.Internal.ChatCompletionToolType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionToolType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.op_Inequality(OpenAI.Official.Internal.ChatCompletionToolType,OpenAI.Official.Internal.ChatCompletionToolType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ChatCompletionToolType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.op_Implicit(System.String)~OpenAI.Official.Internal.ChatCompletionToolType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ChatCompletionToolType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.Equals(OpenAI.Official.Internal.ChatCompletionToolType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ChatCompletionToolType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Completions">
            <summary> The Completions sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Completions.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Completions.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.#ctor">
            <summary> Initializes a new instance of Completions for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Completions. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.CreateCompletionAsync(OpenAI.Official.Internal.CreateCompletionRequest,System.Threading.CancellationToken)">
            <summary> Creates a completion for the provided prompt and parameters. </summary>
            <param name="createCompletionRequest"> The <see cref="T:OpenAI.Official.Internal.CreateCompletionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="createCompletionRequest"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.CreateCompletion(OpenAI.Official.Internal.CreateCompletionRequest,System.Threading.CancellationToken)">
            <summary> Creates a completion for the provided prompt and parameters. </summary>
            <param name="createCompletionRequest"> The <see cref="T:OpenAI.Official.Internal.CreateCompletionRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="createCompletionRequest"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.CreateCompletionAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates a completion for the provided prompt and parameters.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Completions.CreateCompletionAsync(OpenAI.Official.Internal.CreateCompletionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Completions.CreateCompletion(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates a completion for the provided prompt and parameters.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Completions.CreateCompletion(OpenAI.Official.Internal.CreateCompletionRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.CompletionUsage">
            <summary> Usage statistics for the completion request. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CompletionUsage._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CompletionUsage.#ctor(System.Int64,System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CompletionUsage"/>. </summary>
            <param name="promptTokens"> Number of tokens in the prompt. </param>
            <param name="completionTokens"> Number of tokens in the generated completion. </param>
            <param name="totalTokens"> Total number of tokens used in the request (prompt + completion). </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CompletionUsage.#ctor(System.Int64,System.Int64,System.Int64,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CompletionUsage"/>. </summary>
            <param name="promptTokens"> Number of tokens in the prompt. </param>
            <param name="completionTokens"> Number of tokens in the generated completion. </param>
            <param name="totalTokens"> Total number of tokens used in the request (prompt + completion). </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CompletionUsage.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CompletionUsage"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CompletionUsage.PromptTokens">
            <summary> Number of tokens in the prompt. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CompletionUsage.CompletionTokens">
            <summary> Number of tokens in the generated completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CompletionUsage.TotalTokens">
            <summary> Total number of tokens used in the request (prompt + completion). </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CompletionUsage.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CompletionUsage.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateAssistantFileRequest">
            <summary> The CreateAssistantFileRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateAssistantFileRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantFileRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantFileRequest"/>. </summary>
            <param name="fileId">
            A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should
            use. Useful for tools like `retrieval` and `code_interpreter` that can access files.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantFileRequest.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantFileRequest"/>. </summary>
            <param name="fileId">
            A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should
            use. Useful for tools like `retrieval` and `code_interpreter` that can access files.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantFileRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantFileRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantFileRequest.FileId">
            <summary>
            A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should
            use. Useful for tools like `retrieval` and `code_interpreter` that can access files.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantFileRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantFileRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateAssistantRequest">
            <summary> The CreateAssistantRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateAssistantRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantRequest"/>. </summary>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantRequest.#ctor(System.String,System.String,System.String,System.String,System.Collections.Generic.IList{System.BinaryData},System.Collections.Generic.IList{System.String},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantRequest"/>. </summary>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateAssistantRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Model">
            <summary>
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Name">
            <summary> The name of the assistant. The maximum length is 256 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Description">
            <summary> The description of the assistant. The maximum length is 512 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Instructions">
            <summary> The system instructions that the assistant uses. The maximum length is 32768 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Tools">
            <summary>
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.FileIds">
            <summary>
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateAssistantRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateAssistantRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionRequest">
            <summary> The CreateChatCompletionRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateChatCompletionRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequest.#ctor(System.Collections.Generic.IEnumerable{System.BinaryData},OpenAI.Official.Internal.CreateChatCompletionRequestModel)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequest"/>. </summary>
            <param name="messages">
            A list of messages comprising the conversation so far.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
            </param>
            <param name="model">
            ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
            table for details on which models work with the Chat API.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="messages"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequest.#ctor(System.Collections.Generic.IList{System.BinaryData},OpenAI.Official.Internal.CreateChatCompletionRequestModel,System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.Int64},System.Nullable{System.Boolean},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat,System.Nullable{System.Int64},System.BinaryData,System.Nullable{System.Boolean},System.Nullable{System.Double},System.Nullable{System.Double},System.Collections.Generic.IList{OpenAI.Official.Internal.ChatCompletionTool},System.BinaryData,System.String,System.BinaryData,System.Collections.Generic.IList{OpenAI.Official.Internal.ChatCompletionFunctions},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequest"/>. </summary>
             <param name="messages">
             A list of messages comprising the conversation so far.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
             </param>
             <param name="model">
             ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
             table for details on which models work with the Chat API.
             </param>
             <param name="frequencyPenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="logitBias">
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an
             associated bias value from -100 to 100. Mathematically, the bias is added to the logits
             generated by the model prior to sampling. The exact effect will vary per model, but values
             between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100
             should result in a ban or exclusive selection of the relevant token.
             </param>
             <param name="logprobs">
             Whether to return log probabilities of the output tokens or not. If true, returns the log
             probabilities of each output token returned in the `content` of `message`. This option is
             currently not available on the `gpt-4-vision-preview` model.
             </param>
             <param name="topLogprobs">
             An integer between 0 and 5 specifying the number of most likely tokens to return at each token
             position, each with an associated log probability. `logprobs` must be set to `true` if this
             parameter is used.
             </param>
             <param name="maxTokens">
             The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.
            
             The total length of input tokens and generated tokens is limited by the model's context length.
             [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
             for counting tokens.
             </param>
             <param name="n">
             How many chat completion choices to generate for each input message. Note that you will be
             charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to
             minimize costs.
             </param>
             <param name="presencePenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="responseFormat">
             An object specifying the format that the model must output. Compatible with
             [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and `gpt-3.5-turbo-1106`.
            
             Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the
             model generates is valid JSON.
            
             **Important:** when using JSON mode, you **must** also instruct the model to produce JSON
             yourself via a system or user message. Without this, the model may generate an unending stream
             of whitespace until the generation reaches the token limit, resulting in a long-running and
             seemingly "stuck" request. Also note that the message content may be partially cut off if
             `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the
             conversation exceeded the max context length.
             </param>
             <param name="seed">
             This feature is in Beta.
            
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </param>
             <param name="stop"> Up to 4 sequences where the API will stop generating further tokens. </param>
             <param name="stream">
             If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available, with the stream terminated by a `data: [DONE]` message.
             [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
             </param>
             <param name="temperature">
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </param>
             <param name="topP">
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </param>
             <param name="tools">
             A list of tools the model may call. Currently, only functions are supported as a tool. Use this
             to provide a list of functions the model may generate JSON inputs for.
             </param>
             <param name="toolChoice"></param>
             <param name="user">
             A unique identifier representing your end-user, which can help OpenAI to monitor and detect
             abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
             </param>
             <param name="functionCall">
             Deprecated in favor of `tool_choice`.
            
             Controls which (if any) function is called by the model. `none` means the model will not call a
             function and instead generates a message. `auto` means the model can pick between generating a
             message or calling a function. Specifying a particular function via `{"name": "my_function"}`
             forces the model to call that function.
            
             `none` is the default when no functions are present. `auto` is the default if functions are
             present.
             </param>
             <param name="functions">
             Deprecated in favor of `tools`.
            
             A list of functions the model may generate JSON inputs for.
             </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Messages">
            <summary>
            A list of messages comprising the conversation so far.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Model">
            <summary>
            ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
            table for details on which models work with the Chat API.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.FrequencyPenalty">
             <summary>
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.LogitBias">
             <summary>
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an
             associated bias value from -100 to 100. Mathematically, the bias is added to the logits
             generated by the model prior to sampling. The exact effect will vary per model, but values
             between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100
             should result in a ban or exclusive selection of the relevant token.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Logprobs">
            <summary>
            Whether to return log probabilities of the output tokens or not. If true, returns the log
            probabilities of each output token returned in the `content` of `message`. This option is
            currently not available on the `gpt-4-vision-preview` model.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.TopLogprobs">
            <summary>
            An integer between 0 and 5 specifying the number of most likely tokens to return at each token
            position, each with an associated log probability. `logprobs` must be set to `true` if this
            parameter is used.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.MaxTokens">
             <summary>
             The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.
            
             The total length of input tokens and generated tokens is limited by the model's context length.
             [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
             for counting tokens.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.N">
            <summary>
            How many chat completion choices to generate for each input message. Note that you will be
            charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to
            minimize costs.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.PresencePenalty">
             <summary>
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.ResponseFormat">
             <summary>
             An object specifying the format that the model must output. Compatible with
             [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and `gpt-3.5-turbo-1106`.
            
             Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the
             model generates is valid JSON.
            
             **Important:** when using JSON mode, you **must** also instruct the model to produce JSON
             yourself via a system or user message. Without this, the model may generate an unending stream
             of whitespace until the generation reaches the token limit, resulting in a long-running and
             seemingly "stuck" request. Also note that the message content may be partially cut off if
             `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the
             conversation exceeded the max context length.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Seed">
             <summary>
             This feature is in Beta.
            
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Stop">
            <summary>
            Up to 4 sequences where the API will stop generating further tokens.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.String"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.String"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Stream">
            <summary>
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
            [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message.
            [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Temperature">
             <summary>
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.TopP">
             <summary>
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Tools">
            <summary>
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this
            to provide a list of functions the model may generate JSON inputs for.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.ToolChoice">
            <summary>
            Gets or sets the tool choice
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description>"none"</description>
            </item>
            <item>
            <description>"auto"</description>
            </item>
            <item>
            <description><see cref="T:OpenAI.Official.Internal.ChatCompletionNamedToolChoice"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.FunctionCall">
             <summary>
             Deprecated in favor of `tool_choice`.
            
             Controls which (if any) function is called by the model. `none` means the model will not call a
             function and instead generates a message. `auto` means the model can pick between generating a
             message or calling a function. Specifying a particular function via `{"name": "my_function"}`
             forces the model to call that function.
            
             `none` is the default when no functions are present. `auto` is the default if functions are
             present.
             <para>
             To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
             </para>
             <para>
             To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
             </para>
             <para>
             <remarks>
             Supported types:
             <list type="bullet">
             <item>
             <description>"none"</description>
             </item>
             <item>
             <description>"auto"</description>
             </item>
             <item>
             <description><see cref="T:OpenAI.Official.Internal.ChatCompletionFunctionCallOption"/></description>
             </item>
             </list>
             </remarks>
             Examples:
             <list type="bullet">
             <item>
             <term>BinaryData.FromObjectAsJson("foo")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromString("\"foo\"")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             <item>
             <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             </list>
             </para>
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequest.Functions">
             <summary>
             Deprecated in favor of `tools`.
            
             A list of functions the model may generate JSON inputs for.
             </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionRequestModel">
            <summary> Enum for model in CreateChatCompletionRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt40125Preview">
            <summary> gpt-4-0125-preview. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt4TurboPreview">
            <summary> gpt-4-turbo-preview. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt41106Preview">
            <summary> gpt-4-1106-preview. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt4VisionPreview">
            <summary> gpt-4-vision-preview. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt4">
            <summary> gpt-4. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt40314">
            <summary> gpt-4-0314. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt40613">
            <summary> gpt-4-0613. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt432k">
            <summary> gpt-4-32k. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt432k0314">
            <summary> gpt-4-32k-0314. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt432k0613">
            <summary> gpt-4-32k-0613. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo">
            <summary> gpt-3.5-turbo. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo16k">
            <summary> gpt-3.5-turbo-16k. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo0301">
            <summary> gpt-3.5-turbo-0301. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo0613">
            <summary> gpt-3.5-turbo-0613. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo1106">
            <summary> gpt-3.5-turbo-1106. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Gpt35Turbo16k0613">
            <summary> gpt-3.5-turbo-16k-0613. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.op_Equality(OpenAI.Official.Internal.CreateChatCompletionRequestModel,OpenAI.Official.Internal.CreateChatCompletionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.op_Inequality(OpenAI.Official.Internal.CreateChatCompletionRequestModel,OpenAI.Official.Internal.CreateChatCompletionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateChatCompletionRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.Equals(OpenAI.Official.Internal.CreateChatCompletionRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat">
            <summary> The CreateChatCompletionRequestResponseFormat. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat.#ctor(System.Nullable{OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat"/>. </summary>
            <param name="type"> Must be one of `text` or `json_object`. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat.Type">
            <summary> Must be one of `text` or `json_object`. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType">
            <summary> Enum for type in CreateChatCompletionRequestResponseFormat. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.Text">
            <summary> text. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.JsonObject">
            <summary> json_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.op_Equality(OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType,OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.op_Inequality(OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType,OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.op_Implicit(System.String)~OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.Equals(OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormatType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionResponse">
            <summary> Represents a chat completion response returned by model, based on the provided input. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateChatCompletionResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateChatCompletionResponseChoice},System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponse"/>. </summary>
            <param name="id"> A unique identifier for the chat completion. </param>
            <param name="choices"> A list of chat completion choices. Can be more than one if `n` is greater than 1. </param>
            <param name="created"> The Unix timestamp (in seconds) of when the chat completion was created. </param>
            <param name="model"> The model used for the chat completion. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="choices"/> or <paramref name="model"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.CreateChatCompletionResponseChoice},System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.CreateChatCompletionResponseObject,OpenAI.Official.Internal.CompletionUsage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponse"/>. </summary>
             <param name="id"> A unique identifier for the chat completion. </param>
             <param name="choices"> A list of chat completion choices. Can be more than one if `n` is greater than 1. </param>
             <param name="created"> The Unix timestamp (in seconds) of when the chat completion was created. </param>
             <param name="model"> The model used for the chat completion. </param>
             <param name="systemFingerprint">
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </param>
             <param name="object"> The object type, which is always `chat.completion`. </param>
             <param name="usage"></param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Id">
            <summary> A unique identifier for the chat completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Choices">
            <summary> A list of chat completion choices. Can be more than one if `n` is greater than 1. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Created">
            <summary> The Unix timestamp (in seconds) of when the chat completion was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Model">
            <summary> The model used for the chat completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.SystemFingerprint">
             <summary>
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Object">
            <summary> The object type, which is always `chat.completion`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponse.Usage">
            <summary> Gets the usage. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoice">
            <summary> The CreateChatCompletionResponseChoice. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateChatCompletionResponseChoice._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.#ctor(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason,System.Int64,OpenAI.Official.Internal.ChatCompletionResponseMessage,OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoice"/>. </summary>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, `length` if the maximum number of tokens
            specified in the request was reached, `content_filter` if content was omitted due to a flag
            from our content filters, `tool_calls` if the model called a tool, or `function_call`
            (deprecated) if the model called a function.
            </param>
            <param name="index"> The index of the choice in the list of choices. </param>
            <param name="message"></param>
            <param name="logprobs"> Log probability information for the choice. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="message"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.#ctor(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason,System.Int64,OpenAI.Official.Internal.ChatCompletionResponseMessage,OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoice"/>. </summary>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, `length` if the maximum number of tokens
            specified in the request was reached, `content_filter` if content was omitted due to a flag
            from our content filters, `tool_calls` if the model called a tool, or `function_call`
            (deprecated) if the model called a function.
            </param>
            <param name="index"> The index of the choice in the list of choices. </param>
            <param name="message"></param>
            <param name="logprobs"> Log probability information for the choice. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoice"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.FinishReason">
            <summary>
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, `length` if the maximum number of tokens
            specified in the request was reached, `content_filter` if content was omitted due to a flag
            from our content filters, `tool_calls` if the model called a tool, or `function_call`
            (deprecated) if the model called a function.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.Index">
            <summary> The index of the choice in the list of choices. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.Message">
            <summary> Gets the message. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.Logprobs">
            <summary> Log probability information for the choice. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoice.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason">
            <summary> Enum for finish_reason in CreateChatCompletionResponseChoice. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.Stop">
            <summary> stop. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.Length">
            <summary> length. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.ToolCalls">
            <summary> tool_calls. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.ContentFilter">
            <summary> content_filter. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.FunctionCall">
            <summary> function_call. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.op_Equality(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason,OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.op_Inequality(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason,OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.op_Implicit(System.String)~OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.Equals(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs">
            <summary> The CreateChatCompletionResponseChoiceLogprobs. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionTokenLogprob})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="content"></param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.#ctor(System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.ChatCompletionTokenLogprob},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="content"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.Content">
            <summary> Gets the content. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateChatCompletionResponseObject">
            <summary> The CreateChatCompletionResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateChatCompletionResponseObject.ChatCompletion">
            <summary> chat.completion. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.op_Equality(OpenAI.Official.Internal.CreateChatCompletionResponseObject,OpenAI.Official.Internal.CreateChatCompletionResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.op_Inequality(OpenAI.Official.Internal.CreateChatCompletionResponseObject,OpenAI.Official.Internal.CreateChatCompletionResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.CreateChatCompletionResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateChatCompletionResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.Equals(OpenAI.Official.Internal.CreateChatCompletionResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateChatCompletionResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionRequest">
            <summary> The CreateCompletionRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateCompletionRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequest.#ctor(OpenAI.Official.Internal.CreateCompletionRequestModel,System.BinaryData)">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionRequest"/>. </summary>
             <param name="model">
             ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
             see all of your available models, or see our [Model overview](/docs/models/overview) for
             descriptions of them.
             </param>
             <param name="prompt">
             The prompt(s) to generate completions for, encoded as a string, array of strings, array of
             tokens, or array of token arrays.
            
             Note that &lt;|endoftext|&gt; is the document separator that the model sees during training, so if a
             prompt is not specified the model will generate as if from the beginning of a new document.
             </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequest.#ctor(OpenAI.Official.Internal.CreateCompletionRequestModel,System.BinaryData,System.Nullable{System.Int64},System.Nullable{System.Boolean},System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},System.Nullable{System.Int64},System.BinaryData,System.Nullable{System.Boolean},System.String,System.Nullable{System.Double},System.Nullable{System.Double},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionRequest"/>. </summary>
             <param name="model">
             ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
             see all of your available models, or see our [Model overview](/docs/models/overview) for
             descriptions of them.
             </param>
             <param name="prompt">
             The prompt(s) to generate completions for, encoded as a string, array of strings, array of
             tokens, or array of token arrays.
            
             Note that &lt;|endoftext|&gt; is the document separator that the model sees during training, so if a
             prompt is not specified the model will generate as if from the beginning of a new document.
             </param>
             <param name="bestOf">
             Generates `best_of` completions server-side and returns the "best" (the one with the highest
             log probability per token). Results cannot be streamed.
            
             When used with `n`, `best_of` controls the number of candidate completions and `n` specifies
             how many to return – `best_of` must be greater than `n`.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </param>
             <param name="echo"> Echo back the prompt in addition to the completion. </param>
             <param name="frequencyPenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="logitBias">
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an
             associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe)
             to convert text to token IDs. Mathematically, the bias is added to the logits generated by the
             model prior to sampling. The exact effect will vary per model, but values between -1 and 1
             should decrease or increase likelihood of selection; values like -100 or 100 should result in a
             ban or exclusive selection of the relevant token.
            
             As an example, you can pass `{"50256": -100}` to prevent the &lt;|endoftext|&gt; token from being
             generated.
             </param>
             <param name="logprobs">
             Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens.
             For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The
             API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1`
             elements in the response.
            
             The maximum value for `logprobs` is 5.
             </param>
             <param name="maxTokens">
             The maximum number of [tokens](/tokenizer) to generate in the completion.
            
             The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
             for counting tokens.
             </param>
             <param name="n">
             How many completions to generate for each prompt.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </param>
             <param name="presencePenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="seed">
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </param>
             <param name="stop"> Up to 4 sequences where the API will stop generating further tokens. </param>
             <param name="stream">
             If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available, with the stream terminated by a `data: [DONE]` message.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
             </param>
             <param name="suffix"> The suffix that comes after a completion of inserted text. </param>
             <param name="temperature">
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </param>
             <param name="topP">
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </param>
             <param name="user">
             A unique identifier representing your end-user, which can help OpenAI to monitor and detect
             abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
             </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Model">
            <summary>
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Prompt">
             <summary>
             The prompt(s) to generate completions for, encoded as a string, array of strings, array of
             tokens, or array of token arrays.
            
             Note that &lt;|endoftext|&gt; is the document separator that the model sees during training, so if a
             prompt is not specified the model will generate as if from the beginning of a new document.
             <para>
             To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
             </para>
             <para>
             To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
             </para>
             <para>
             <remarks>
             Supported types:
             <list type="bullet">
             <item>
             <description><see cref="T:System.String"/></description>
             </item>
             <item>
             <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.String"/></description>
             </item>
             <item>
             <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.Int64"/></description>
             </item>
             <item>
             <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <c>IList{long}</c></description>
             </item>
             </list>
             </remarks>
             Examples:
             <list type="bullet">
             <item>
             <term>BinaryData.FromObjectAsJson("foo")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromString("\"foo\"")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             <item>
             <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             </list>
             </para>
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.BestOf">
             <summary>
             Generates `best_of` completions server-side and returns the "best" (the one with the highest
             log probability per token). Results cannot be streamed.
            
             When used with `n`, `best_of` controls the number of candidate completions and `n` specifies
             how many to return – `best_of` must be greater than `n`.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Echo">
            <summary> Echo back the prompt in addition to the completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.FrequencyPenalty">
             <summary>
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.LogitBias">
             <summary>
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an
             associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe)
             to convert text to token IDs. Mathematically, the bias is added to the logits generated by the
             model prior to sampling. The exact effect will vary per model, but values between -1 and 1
             should decrease or increase likelihood of selection; values like -100 or 100 should result in a
             ban or exclusive selection of the relevant token.
            
             As an example, you can pass `{"50256": -100}` to prevent the &lt;|endoftext|&gt; token from being
             generated.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Logprobs">
             <summary>
             Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens.
             For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The
             API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1`
             elements in the response.
            
             The maximum value for `logprobs` is 5.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.MaxTokens">
             <summary>
             The maximum number of [tokens](/tokenizer) to generate in the completion.
            
             The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
             for counting tokens.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.N">
             <summary>
             How many completions to generate for each prompt.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.PresencePenalty">
             <summary>
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Seed">
             <summary>
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Stop">
            <summary>
            Up to 4 sequences where the API will stop generating further tokens.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.String"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.String"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Stream">
            <summary>
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
            [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Suffix">
            <summary> The suffix that comes after a completion of inserted text. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.Temperature">
             <summary>
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.TopP">
             <summary>
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionRequestModel">
            <summary> Enum for model in CreateCompletionRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequestModel.Gpt35TurboInstruct">
            <summary> gpt-3.5-turbo-instruct. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequestModel.Davinci002">
            <summary> davinci-002. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionRequestModel.Babbage002">
            <summary> babbage-002. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.op_Equality(OpenAI.Official.Internal.CreateCompletionRequestModel,OpenAI.Official.Internal.CreateCompletionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.op_Inequality(OpenAI.Official.Internal.CreateCompletionRequestModel,OpenAI.Official.Internal.CreateCompletionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateCompletionRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateCompletionRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.Equals(OpenAI.Official.Internal.CreateCompletionRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionResponse">
            <summary>
            Represents a completion response from the API. Note: both the streamed and non-streamed response
            objects share the same shape (unlike the chat endpoint).
            </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateCompletionResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateCompletionResponseChoice},System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponse"/>. </summary>
            <param name="id"> A unique identifier for the completion. </param>
            <param name="choices"> The list of completion choices the model generated for the input. </param>
            <param name="created"> The Unix timestamp (in seconds) of when the completion was created. </param>
            <param name="model"> The model used for the completion. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="choices"/> or <paramref name="model"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.CreateCompletionResponseChoice},System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.CreateCompletionResponseObject,OpenAI.Official.Internal.CompletionUsage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponse"/>. </summary>
             <param name="id"> A unique identifier for the completion. </param>
             <param name="choices"> The list of completion choices the model generated for the input. </param>
             <param name="created"> The Unix timestamp (in seconds) of when the completion was created. </param>
             <param name="model"> The model used for the completion. </param>
             <param name="systemFingerprint">
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </param>
             <param name="object"> The object type, which is always `text_completion`. </param>
             <param name="usage"> Usage statistics for the completion request. </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Id">
            <summary> A unique identifier for the completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Choices">
            <summary> The list of completion choices the model generated for the input. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Created">
            <summary> The Unix timestamp (in seconds) of when the completion was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Model">
            <summary> The model used for the completion. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.SystemFingerprint">
             <summary>
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Object">
            <summary> The object type, which is always `text_completion`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponse.Usage">
            <summary> Usage statistics for the completion request. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionResponseChoice">
            <summary> The CreateCompletionResponseChoice. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateCompletionResponseChoice._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoice.#ctor(System.Int64,System.String,OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs,OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoice"/>. </summary>
            <param name="index"></param>
            <param name="text"></param>
            <param name="logprobs"></param>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, or `content_filter` if content was omitted
            due to a flag from our content filters, `length` if the maximum number of tokens specified
            in the request was reached, or `content_filter` if content was omitted due to a flag from our
            content filters.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="text"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoice.#ctor(System.Int64,System.String,OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs,OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoice"/>. </summary>
            <param name="index"></param>
            <param name="text"></param>
            <param name="logprobs"></param>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, or `content_filter` if content was omitted
            due to a flag from our content filters, `length` if the maximum number of tokens specified
            in the request was reached, or `content_filter` if content was omitted due to a flag from our
            content filters.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoice.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoice"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoice.Index">
            <summary> Gets the index. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoice.Text">
            <summary> Gets the text. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoice.Logprobs">
            <summary> Gets the logprobs. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoice.FinishReason">
            <summary>
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, or `content_filter` if content was omitted
            due to a flag from our content filters, `length` if the maximum number of tokens specified
            in the request was reached, or `content_filter` if content was omitted due to a flag from our
            content filters.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoice.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoice.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason">
            <summary> Enum for finish_reason in CreateCompletionResponseChoice. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.Stop">
            <summary> stop. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.Length">
            <summary> length. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.ContentFilter">
            <summary> content_filter. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.op_Equality(OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason,OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.op_Inequality(OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason,OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.op_Implicit(System.String)~OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.Equals(OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs">
            <summary> The CreateCompletionResponseChoiceLogprobs. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.#ctor(System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Collections.Generic.IDictionary{System.String,System.Int64}},System.Collections.Generic.IEnumerable{System.Int64})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="tokens"></param>
            <param name="tokenLogprobs"></param>
            <param name="topLogprobs"></param>
            <param name="textOffset"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="tokens"/>, <paramref name="tokenLogprobs"/>, <paramref name="topLogprobs"/> or <paramref name="textOffset"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.#ctor(System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.IReadOnlyList{System.Double},System.Collections.Generic.IReadOnlyList{System.Collections.Generic.IDictionary{System.String,System.Int64}},System.Collections.Generic.IReadOnlyList{System.Int64},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="tokens"></param>
            <param name="tokenLogprobs"></param>
            <param name="topLogprobs"></param>
            <param name="textOffset"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.Tokens">
            <summary> Gets the tokens. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.TokenLogprobs">
            <summary> Gets the token logprobs. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.TopLogprobs">
            <summary> Gets the top logprobs. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.TextOffset">
            <summary> Gets the text offset. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateCompletionResponseObject">
            <summary> The CreateCompletionResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateCompletionResponseObject.TextCompletion">
            <summary> text_completion. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.op_Equality(OpenAI.Official.Internal.CreateCompletionResponseObject,OpenAI.Official.Internal.CreateCompletionResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.op_Inequality(OpenAI.Official.Internal.CreateCompletionResponseObject,OpenAI.Official.Internal.CreateCompletionResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.CreateCompletionResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateCompletionResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.Equals(OpenAI.Official.Internal.CreateCompletionResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateCompletionResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingRequest">
            <summary> The CreateEmbeddingRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateEmbeddingRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateEmbeddingRequestModel)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequest"/>. </summary>
            <param name="input">
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
            single request, pass an array of strings or array of token arrays. Each input must not exceed
            the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an
            empty string.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
            </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="input"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateEmbeddingRequestModel,System.Nullable{OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat},System.Nullable{System.Int64},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequest"/>. </summary>
            <param name="input">
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
            single request, pass an array of strings or array of token arrays. Each input must not exceed
            the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an
            empty string.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
            </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="encodingFormat">
            The format to return the embeddings in. Can be either `float` or
            [`base64`](https://pypi.org/project/pybase64/).
            </param>
            <param name="dimensions">
            The number of dimensions the resulting output embeddings should have. Only supported in
            `text-embedding-3` and later models.
            </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequest.Input">
            <summary>
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
            single request, pass an array of strings or array of token arrays. Each input must not exceed
            the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an
            empty string.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.String"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.String"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.Int64"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <c>IList{long}</c></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequest.Model">
            <summary>
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequest.EncodingFormat">
            <summary>
            The format to return the embeddings in. Can be either `float` or
            [`base64`](https://pypi.org/project/pybase64/).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequest.Dimensions">
            <summary>
            The number of dimensions the resulting output embeddings should have. Only supported in
            `text-embedding-3` and later models.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat">
            <summary> Enum for encoding_format in CreateEmbeddingRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.Float">
            <summary> float. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.Base64">
            <summary> base64. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.op_Equality(OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat,OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.op_Inequality(OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat,OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.Equals(OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingRequestModel">
            <summary> Enum for model in CreateEmbeddingRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequestModel.TextEmbeddingAda002">
            <summary> text-embedding-ada-002. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequestModel.TextEmbedding3Small">
            <summary> text-embedding-3-small. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingRequestModel.TextEmbedding3Large">
            <summary> text-embedding-3-large. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.op_Equality(OpenAI.Official.Internal.CreateEmbeddingRequestModel,OpenAI.Official.Internal.CreateEmbeddingRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.op_Inequality(OpenAI.Official.Internal.CreateEmbeddingRequestModel,OpenAI.Official.Internal.CreateEmbeddingRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateEmbeddingRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.Equals(OpenAI.Official.Internal.CreateEmbeddingRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingResponse">
            <summary> The CreateEmbeddingResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateEmbeddingResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Embedding},System.String,OpenAI.Official.Internal.CreateEmbeddingResponseUsage)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponse"/>. </summary>
            <param name="data"> The list of embeddings generated by the model. </param>
            <param name="model"> The name of the model used to generate the embedding. </param>
            <param name="usage"> The usage information for the request. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="model"/> or <paramref name="usage"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponse.#ctor(System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.Embedding},System.String,OpenAI.Official.Internal.CreateEmbeddingResponseObject,OpenAI.Official.Internal.CreateEmbeddingResponseUsage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponse"/>. </summary>
            <param name="data"> The list of embeddings generated by the model. </param>
            <param name="model"> The name of the model used to generate the embedding. </param>
            <param name="object"> The object type, which is always "list". </param>
            <param name="usage"> The usage information for the request. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponse.Data">
            <summary> The list of embeddings generated by the model. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponse.Model">
            <summary> The name of the model used to generate the embedding. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponse.Object">
            <summary> The object type, which is always "list". </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponse.Usage">
            <summary> The usage information for the request. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingResponseObject">
            <summary> The CreateEmbeddingResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.op_Equality(OpenAI.Official.Internal.CreateEmbeddingResponseObject,OpenAI.Official.Internal.CreateEmbeddingResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.op_Inequality(OpenAI.Official.Internal.CreateEmbeddingResponseObject,OpenAI.Official.Internal.CreateEmbeddingResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.CreateEmbeddingResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.Equals(OpenAI.Official.Internal.CreateEmbeddingResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateEmbeddingResponseUsage">
            <summary> The CreateEmbeddingResponseUsage. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateEmbeddingResponseUsage._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.#ctor(System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseUsage"/>. </summary>
            <param name="promptTokens"> The number of tokens used by the prompt. </param>
            <param name="totalTokens"> The total number of tokens used by the request. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.#ctor(System.Int64,System.Int64,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseUsage"/>. </summary>
            <param name="promptTokens"> The number of tokens used by the prompt. </param>
            <param name="totalTokens"> The total number of tokens used by the request. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateEmbeddingResponseUsage"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.PromptTokens">
            <summary> The number of tokens used by the prompt. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.TotalTokens">
            <summary> The total number of tokens used by the request. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateEmbeddingResponseUsage.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFileRequest">
            <summary> The CreateFileRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateFileRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateFileRequestPurpose)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFileRequest"/>. </summary>
            <param name="file"> The file object (not file name) to be uploaded. </param>
            <param name="purpose">
            The intended purpose of the uploaded file. Use "fine-tune" for
            [Fine-tuning](/docs/api-reference/fine-tuning) and "assistants" for
            [Assistants](/docs/api-reference/assistants) and [Messages](/docs/api-reference/messages). This
            allows us to validate the format of the uploaded file is correct for fine-tuning.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="file"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateFileRequestPurpose,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFileRequest"/>. </summary>
            <param name="file"> The file object (not file name) to be uploaded. </param>
            <param name="purpose">
            The intended purpose of the uploaded file. Use "fine-tune" for
            [Fine-tuning](/docs/api-reference/fine-tuning) and "assistants" for
            [Assistants](/docs/api-reference/assistants) and [Messages](/docs/api-reference/messages). This
            allows us to validate the format of the uploaded file is correct for fine-tuning.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFileRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFileRequest.File">
            <summary>
            The file object (not file name) to be uploaded.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFileRequest.Purpose">
            <summary>
            The intended purpose of the uploaded file. Use "fine-tune" for
            [Fine-tuning](/docs/api-reference/fine-tuning) and "assistants" for
            [Assistants](/docs/api-reference/assistants) and [Messages](/docs/api-reference/messages). This
            allows us to validate the format of the uploaded file is correct for fine-tuning.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFileRequestPurpose">
            <summary> Enum for purpose in CreateFileRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFileRequestPurpose"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFileRequestPurpose.FineTune">
            <summary> fine-tune. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFileRequestPurpose.Assistants">
            <summary> assistants. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.op_Equality(OpenAI.Official.Internal.CreateFileRequestPurpose,OpenAI.Official.Internal.CreateFileRequestPurpose)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFileRequestPurpose"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.op_Inequality(OpenAI.Official.Internal.CreateFileRequestPurpose,OpenAI.Official.Internal.CreateFileRequestPurpose)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFileRequestPurpose"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.op_Implicit(System.String)~OpenAI.Official.Internal.CreateFileRequestPurpose">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateFileRequestPurpose"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.Equals(OpenAI.Official.Internal.CreateFileRequestPurpose)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFileRequestPurpose.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFineTuneRequest">
            <summary> The CreateFineTuneRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateFineTuneRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequest.#ctor(System.String)">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file, where each training example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="trainingFile"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequest.#ctor(System.String,System.String,System.Nullable{OpenAI.Official.Internal.CreateFineTuneRequestModel},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{System.Boolean},System.Nullable{System.Int64},System.String,System.Collections.Generic.IList{System.Double},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file, where each training example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </param>
             <param name="validationFile">
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the
             [fine-tuning results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
             Your train and validation data should be mutually exclusive.
            
             Your dataset must be formatted as a JSONL file, where each validation example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </param>
             <param name="model">
             The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie",
             "davinci", or a fine-tuned model created after 2022-04-21 and before 2023-08-22. To learn more
             about these models, see the [Models](/docs/models) documentation.
             </param>
             <param name="nEpochs">
             The number of epochs to train the model for. An epoch refers to one full cycle through the
             training dataset.
             </param>
             <param name="batchSize">
             The batch size to use for training. The batch size is the number of training examples used to
             train a single forward and backward pass.
            
             By default, the batch size will be dynamically configured to be ~0.2% of the number of examples
             in the training set, capped at 256 - in general, we've found that larger batch sizes tend to
             work better for larger datasets.
             </param>
             <param name="learningRateMultiplier">
             The learning rate multiplier to use for training. The fine-tuning learning rate is the original
             learning rate used for pretraining multiplied by this value.
            
             By default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final
             `batch_size` (larger learning rates tend to perform better with larger batch sizes). We
             recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best
             results.
             </param>
             <param name="promptLossRate">
             The weight to use for loss on the prompt tokens. This controls how much the model tries to
             learn to generate the prompt (as compared to the completion which always has a weight of 1.0),
             and can add a stabilizing effect to training when completions are short.
            
             If prompts are extremely long (relative to completions), it may make sense to reduce this
             weight so as to avoid over-prioritizing learning the prompt.
             </param>
             <param name="computeClassificationMetrics">
             If set, we calculate classification-specific metrics such as accuracy and F-1 score using the
             validation set at the end of every epoch. These metrics can be viewed in the
             [results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
            
             In order to compute classification metrics, you must provide a `validation_file`. Additionally,
             you must specify `classification_n_classes` for multiclass classification or
             `classification_positive_class` for binary classification.
             </param>
             <param name="classificationNClasses">
             The number of classes in a classification task.
            
             This parameter is required for multiclass classification.
             </param>
             <param name="classificationPositiveClass">
             The positive class in binary classification.
            
             This parameter is needed to generate precision, recall, and F1 metrics when doing binary
             classification.
             </param>
             <param name="classificationBetas">
             If this is provided, we calculate F-beta scores at the specified beta values. The F-beta score
             is a generalization of F-1 score. This is only used for binary classification.
            
             With a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger
             beta score puts more weight on recall and less on precision. A smaller beta score puts more
             weight on precision and less on recall.
             </param>
             <param name="suffix">
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.
             </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.TrainingFile">
             <summary>
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file, where each training example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.ValidationFile">
             <summary>
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the
             [fine-tuning results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
             Your train and validation data should be mutually exclusive.
            
             Your dataset must be formatted as a JSONL file, where each validation example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.Model">
            <summary>
            The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie",
            "davinci", or a fine-tuned model created after 2022-04-21 and before 2023-08-22. To learn more
            about these models, see the [Models](/docs/models) documentation.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.NEpochs">
            <summary>
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.BatchSize">
             <summary>
             The batch size to use for training. The batch size is the number of training examples used to
             train a single forward and backward pass.
            
             By default, the batch size will be dynamically configured to be ~0.2% of the number of examples
             in the training set, capped at 256 - in general, we've found that larger batch sizes tend to
             work better for larger datasets.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.LearningRateMultiplier">
             <summary>
             The learning rate multiplier to use for training. The fine-tuning learning rate is the original
             learning rate used for pretraining multiplied by this value.
            
             By default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final
             `batch_size` (larger learning rates tend to perform better with larger batch sizes). We
             recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best
             results.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.PromptLossRate">
             <summary>
             The weight to use for loss on the prompt tokens. This controls how much the model tries to
             learn to generate the prompt (as compared to the completion which always has a weight of 1.0),
             and can add a stabilizing effect to training when completions are short.
            
             If prompts are extremely long (relative to completions), it may make sense to reduce this
             weight so as to avoid over-prioritizing learning the prompt.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.ComputeClassificationMetrics">
             <summary>
             If set, we calculate classification-specific metrics such as accuracy and F-1 score using the
             validation set at the end of every epoch. These metrics can be viewed in the
             [results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
            
             In order to compute classification metrics, you must provide a `validation_file`. Additionally,
             you must specify `classification_n_classes` for multiclass classification or
             `classification_positive_class` for binary classification.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.ClassificationNClasses">
             <summary>
             The number of classes in a classification task.
            
             This parameter is required for multiclass classification.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.ClassificationPositiveClass">
             <summary>
             The positive class in binary classification.
            
             This parameter is needed to generate precision, recall, and F1 metrics when doing binary
             classification.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.ClassificationBetas">
             <summary>
             If this is provided, we calculate F-beta scores at the specified beta values. The F-beta score
             is a generalization of F-1 score. This is only used for binary classification.
            
             With a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger
             beta score puts more weight on recall and less on precision. A smaller beta score puts more
             weight on precision and less on recall.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequest.Suffix">
             <summary>
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.
             </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFineTuneRequestModel">
            <summary> Enum for model in CreateFineTuneRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequestModel.Ada">
            <summary> ada. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequestModel.Babbage">
            <summary> babbage. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequestModel.Curie">
            <summary> curie. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuneRequestModel.Davinci">
            <summary> davinci. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.op_Equality(OpenAI.Official.Internal.CreateFineTuneRequestModel,OpenAI.Official.Internal.CreateFineTuneRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.op_Inequality(OpenAI.Official.Internal.CreateFineTuneRequestModel,OpenAI.Official.Internal.CreateFineTuneRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateFineTuneRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.Equals(OpenAI.Official.Internal.CreateFineTuneRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuneRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFineTuningJobRequest">
            <summary> The CreateFineTuningJobRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateFineTuningJobRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequest.#ctor(System.String,OpenAI.Official.Internal.CreateFineTuningJobRequestModel)">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with
             the purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </param>
             <param name="model">
             The name of the model to fine-tune. You can select one of the
             [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
             </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="trainingFile"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequest.#ctor(System.String,System.String,OpenAI.Official.Internal.CreateFineTuningJobRequestModel,OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with
             the purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </param>
             <param name="validationFile">
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should
             not be present in both train and validation files.
            
             Your dataset must be formatted as a JSONL file. You must upload your file with the purpose
             `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </param>
             <param name="model">
             The name of the model to fine-tune. You can select one of the
             [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
             </param>
             <param name="hyperparameters"> The hyperparameters used for the fine-tuning job. </param>
             <param name="suffix">
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
             </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequest.TrainingFile">
             <summary>
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with
             the purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequest.ValidationFile">
             <summary>
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should
             not be present in both train and validation files.
            
             Your dataset must be formatted as a JSONL file. You must upload your file with the purpose
             `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequest.Model">
            <summary>
            The name of the model to fine-tune. You can select one of the
            [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequest.Hyperparameters">
            <summary> The hyperparameters used for the fine-tuning job. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequest.Suffix">
             <summary>
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
             </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters">
            <summary> The CreateFineTuningJobRequestHyperparameters. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters.#ctor(System.BinaryData,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters"/>. </summary>
            <param name="nEpochs">
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters.NEpochs">
            <summary>
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description>"auto"</description>
            </item>
            <item>
            <description><see cref="T:System.Int64"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateFineTuningJobRequestModel">
            <summary> Enum for model in CreateFineTuningJobRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.Babbage002">
            <summary> babbage-002. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.Davinci002">
            <summary> davinci-002. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.Gpt35Turbo">
            <summary> gpt-3.5-turbo. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.op_Equality(OpenAI.Official.Internal.CreateFineTuningJobRequestModel,OpenAI.Official.Internal.CreateFineTuningJobRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.op_Inequality(OpenAI.Official.Internal.CreateFineTuningJobRequestModel,OpenAI.Official.Internal.CreateFineTuningJobRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateFineTuningJobRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.Equals(OpenAI.Official.Internal.CreateFineTuningJobRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateFineTuningJobRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageEditRequest">
            <summary> The CreateImageEditRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateImageEditRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequest.#ctor(System.BinaryData,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequest"/>. </summary>
            <param name="image">
            The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
            provided, image must have transparency, which will be used as the mask.
            </param>
            <param name="prompt"> A text description of the desired image(s). The maximum length is 1000 characters. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> or <paramref name="prompt"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequest.#ctor(System.BinaryData,System.String,System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestSize},System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestResponseFormat},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequest"/>. </summary>
            <param name="image">
            The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
            provided, image must have transparency, which will be used as the mask.
            </param>
            <param name="prompt"> A text description of the desired image(s). The maximum length is 1000 characters. </param>
            <param name="mask">
            An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where
            `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions
            as `image`.
            </param>
            <param name="model"> The model to use for image generation. Only `dall-e-2` is supported at this time. </param>
            <param name="n"> The number of images to generate. Must be between 1 and 10. </param>
            <param name="size"> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.Image">
            <summary>
            The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
            provided, image must have transparency, which will be used as the mask.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.Prompt">
            <summary> A text description of the desired image(s). The maximum length is 1000 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.Mask">
            <summary>
            An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where
            `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions
            as `image`.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.Model">
            <summary> The model to use for image generation. Only `dall-e-2` is supported at this time. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.N">
            <summary> The number of images to generate. Must be between 1 and 10. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.Size">
            <summary> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.ResponseFormat">
            <summary> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageEditRequestModel">
            <summary> Enum for model in CreateImageEditRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestModel.DallE2">
            <summary> dall-e-2. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.op_Equality(OpenAI.Official.Internal.CreateImageEditRequestModel,OpenAI.Official.Internal.CreateImageEditRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.op_Inequality(OpenAI.Official.Internal.CreateImageEditRequestModel,OpenAI.Official.Internal.CreateImageEditRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageEditRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.Equals(OpenAI.Official.Internal.CreateImageEditRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat">
            <summary> Enum for response_format in CreateImageEditRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.Url">
            <summary> url. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.B64Json">
            <summary> b64_json. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateImageEditRequestResponseFormat,OpenAI.Official.Internal.CreateImageEditRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateImageEditRequestResponseFormat,OpenAI.Official.Internal.CreateImageEditRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageEditRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateImageEditRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageEditRequestSize">
            <summary> Enum for size in CreateImageEditRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestSize"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestSize._256x256">
            <summary> 256x256. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestSize._512x512">
            <summary> 512x512. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageEditRequestSize._1024x1024">
            <summary> 1024x1024. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.op_Equality(OpenAI.Official.Internal.CreateImageEditRequestSize,OpenAI.Official.Internal.CreateImageEditRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestSize"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.op_Inequality(OpenAI.Official.Internal.CreateImageEditRequestSize,OpenAI.Official.Internal.CreateImageEditRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestSize"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageEditRequestSize">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageEditRequestSize"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.Equals(OpenAI.Official.Internal.CreateImageEditRequestSize)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageEditRequestSize.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequest">
            <summary> The CreateImageRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateImageRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequest"/>. </summary>
            <param name="prompt">
            A text description of the desired image(s). The maximum length is 1000 characters for
            `dall-e-2` and 4000 characters for `dall-e-3`.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="prompt"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequest.#ctor(System.String,System.Nullable{OpenAI.Official.Internal.CreateImageRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageRequestQuality},System.Nullable{OpenAI.Official.Internal.CreateImageRequestResponseFormat},System.Nullable{OpenAI.Official.Internal.CreateImageRequestSize},System.Nullable{OpenAI.Official.Internal.CreateImageRequestStyle},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequest"/>. </summary>
            <param name="prompt">
            A text description of the desired image(s). The maximum length is 1000 characters for
            `dall-e-2` and 4000 characters for `dall-e-3`.
            </param>
            <param name="model"> The model to use for image generation. </param>
            <param name="n">
            The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is
            supported.
            </param>
            <param name="quality">
            The quality of the image that will be generated. `hd` creates images with finer details and
            greater consistency across the image. This param is only supported for `dall-e-3`.
            </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="size">
            The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for
            `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.
            </param>
            <param name="style">
            The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model
            to lean towards generating hyper-real and dramatic images. Natural causes the model to produce
            more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.
            </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.Prompt">
            <summary>
            A text description of the desired image(s). The maximum length is 1000 characters for
            `dall-e-2` and 4000 characters for `dall-e-3`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.Model">
            <summary> The model to use for image generation. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.N">
            <summary>
            The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is
            supported.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.Quality">
            <summary>
            The quality of the image that will be generated. `hd` creates images with finer details and
            greater consistency across the image. This param is only supported for `dall-e-3`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.ResponseFormat">
            <summary> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.Size">
            <summary>
            The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for
            `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.Style">
            <summary>
            The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model
            to lean towards generating hyper-real and dramatic images. Natural causes the model to produce
            more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequestModel">
            <summary> Enum for model in CreateImageRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestModel.DallE2">
            <summary> dall-e-2. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestModel.DallE3">
            <summary> dall-e-3. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.op_Equality(OpenAI.Official.Internal.CreateImageRequestModel,OpenAI.Official.Internal.CreateImageRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.op_Inequality(OpenAI.Official.Internal.CreateImageRequestModel,OpenAI.Official.Internal.CreateImageRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.Equals(OpenAI.Official.Internal.CreateImageRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequestQuality">
            <summary> Enum for quality in CreateImageRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequestQuality"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestQuality.Standard">
            <summary> standard. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestQuality.Hd">
            <summary> hd. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.op_Equality(OpenAI.Official.Internal.CreateImageRequestQuality,OpenAI.Official.Internal.CreateImageRequestQuality)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestQuality"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.op_Inequality(OpenAI.Official.Internal.CreateImageRequestQuality,OpenAI.Official.Internal.CreateImageRequestQuality)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestQuality"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageRequestQuality">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageRequestQuality"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.Equals(OpenAI.Official.Internal.CreateImageRequestQuality)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestQuality.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequestResponseFormat">
            <summary> Enum for response_format in CreateImageRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestResponseFormat.Url">
            <summary> url. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestResponseFormat.B64Json">
            <summary> b64_json. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateImageRequestResponseFormat,OpenAI.Official.Internal.CreateImageRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateImageRequestResponseFormat,OpenAI.Official.Internal.CreateImageRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateImageRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequestSize">
            <summary> Enum for size in CreateImageRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequestSize"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestSize._256x256">
            <summary> 256x256. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestSize._512x512">
            <summary> 512x512. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestSize._1024x1024">
            <summary> 1024x1024. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestSize._1792x1024">
            <summary> 1792x1024. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestSize._1024x1792">
            <summary> 1024x1792. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.op_Equality(OpenAI.Official.Internal.CreateImageRequestSize,OpenAI.Official.Internal.CreateImageRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestSize"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.op_Inequality(OpenAI.Official.Internal.CreateImageRequestSize,OpenAI.Official.Internal.CreateImageRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestSize"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageRequestSize">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageRequestSize"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.Equals(OpenAI.Official.Internal.CreateImageRequestSize)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestSize.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageRequestStyle">
            <summary> Enum for style in CreateImageRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageRequestStyle"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestStyle.Vivid">
            <summary> vivid. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageRequestStyle.Natural">
            <summary> natural. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.op_Equality(OpenAI.Official.Internal.CreateImageRequestStyle,OpenAI.Official.Internal.CreateImageRequestStyle)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestStyle"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.op_Inequality(OpenAI.Official.Internal.CreateImageRequestStyle,OpenAI.Official.Internal.CreateImageRequestStyle)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageRequestStyle"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageRequestStyle">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageRequestStyle"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.Equals(OpenAI.Official.Internal.CreateImageRequestStyle)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageRequestStyle.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageVariationRequest">
            <summary> The CreateImageVariationRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateImageVariationRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequest.#ctor(System.BinaryData)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequest"/>. </summary>
            <param name="image">
            The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB,
            and square.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequest.#ctor(System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat},System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestSize},System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequest"/>. </summary>
            <param name="image">
            The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB,
            and square.
            </param>
            <param name="model"> The model to use for image generation. Only `dall-e-2` is supported at this time. </param>
            <param name="n"> The number of images to generate. Must be between 1 and 10. </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="size"> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.Image">
            <summary>
            The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB,
            and square.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.Model">
            <summary> The model to use for image generation. Only `dall-e-2` is supported at this time. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.N">
            <summary> The number of images to generate. Must be between 1 and 10. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.ResponseFormat">
            <summary> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.Size">
            <summary> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequest.User">
            <summary>
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageVariationRequestModel">
            <summary> Enum for model in CreateImageVariationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestModel.DallE2">
            <summary> dall-e-2. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.op_Equality(OpenAI.Official.Internal.CreateImageVariationRequestModel,OpenAI.Official.Internal.CreateImageVariationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.op_Inequality(OpenAI.Official.Internal.CreateImageVariationRequestModel,OpenAI.Official.Internal.CreateImageVariationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageVariationRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.Equals(OpenAI.Official.Internal.CreateImageVariationRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat">
            <summary> Enum for response_format in CreateImageVariationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.Url">
            <summary> url. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.B64Json">
            <summary> b64_json. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat,OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat,OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateImageVariationRequestSize">
            <summary> Enum for size in CreateImageVariationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestSize"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestSize._256x256">
            <summary> 256x256. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestSize._512x512">
            <summary> 512x512. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateImageVariationRequestSize._1024x1024">
            <summary> 1024x1024. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.op_Equality(OpenAI.Official.Internal.CreateImageVariationRequestSize,OpenAI.Official.Internal.CreateImageVariationRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestSize"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.op_Inequality(OpenAI.Official.Internal.CreateImageVariationRequestSize,OpenAI.Official.Internal.CreateImageVariationRequestSize)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestSize"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.op_Implicit(System.String)~OpenAI.Official.Internal.CreateImageVariationRequestSize">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequestSize"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.Equals(OpenAI.Official.Internal.CreateImageVariationRequestSize)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateImageVariationRequestSize.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateMessageRequest">
            <summary> The CreateMessageRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateMessageRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateMessageRequest"/>. </summary>
            <param name="content"> The content of the message. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequest.#ctor(OpenAI.Official.Internal.CreateMessageRequestRole,System.String,System.Collections.Generic.IList{System.String},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateMessageRequest"/>. </summary>
            <param name="role"> The role of the entity that is creating the message. Currently only `user` is supported. </param>
            <param name="content"> The content of the message. </param>
            <param name="fileIds">
            A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a
            maximum of 10 files attached to a message. Useful for tools like `retrieval` and
            `code_interpreter` that can access and use files.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateMessageRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateMessageRequest.Role">
            <summary> The role of the entity that is creating the message. Currently only `user` is supported. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateMessageRequest.Content">
            <summary> The content of the message. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateMessageRequest.FileIds">
            <summary>
            A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a
            maximum of 10 files attached to a message. Useful for tools like `retrieval` and
            `code_interpreter` that can access and use files.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateMessageRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateMessageRequestRole">
            <summary> The CreateMessageRequest_role. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateMessageRequestRole"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateMessageRequestRole.User">
            <summary> user. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.op_Equality(OpenAI.Official.Internal.CreateMessageRequestRole,OpenAI.Official.Internal.CreateMessageRequestRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateMessageRequestRole"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.op_Inequality(OpenAI.Official.Internal.CreateMessageRequestRole,OpenAI.Official.Internal.CreateMessageRequestRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateMessageRequestRole"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.op_Implicit(System.String)~OpenAI.Official.Internal.CreateMessageRequestRole">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateMessageRequestRole"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.Equals(OpenAI.Official.Internal.CreateMessageRequestRole)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateMessageRequestRole.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationRequest">
            <summary> The CreateModerationRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateModerationRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequest.#ctor(System.BinaryData)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationRequest"/>. </summary>
            <param name="input"> The input text to classify. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="input"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequest.#ctor(System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateModerationRequestModel},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationRequest"/>. </summary>
            <param name="input"> The input text to classify. </param>
            <param name="model">
            Two content moderations models are available: `text-moderation-stable` and
            `text-moderation-latest`. The default is `text-moderation-latest` which will be automatically
            upgraded over time. This ensures you are always using our most accurate model. If you use
            `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy
            of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationRequest.Input">
            <summary>
            The input text to classify
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.String"/></description>
            </item>
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.String"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationRequest.Model">
            <summary>
            Two content moderations models are available: `text-moderation-stable` and
            `text-moderation-latest`. The default is `text-moderation-latest` which will be automatically
            upgraded over time. This ensures you are always using our most accurate model. If you use
            `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy
            of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationRequestModel">
            <summary> Enum for model in CreateModerationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationRequestModel.TextModerationLatest">
            <summary> text-moderation-latest. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationRequestModel.TextModerationStable">
            <summary> text-moderation-stable. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.op_Equality(OpenAI.Official.Internal.CreateModerationRequestModel,OpenAI.Official.Internal.CreateModerationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateModerationRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.op_Inequality(OpenAI.Official.Internal.CreateModerationRequestModel,OpenAI.Official.Internal.CreateModerationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateModerationRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateModerationRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateModerationRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.Equals(OpenAI.Official.Internal.CreateModerationRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationResponse">
            <summary> Represents policy compliance report by OpenAI's content moderation model against a given input. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateModerationResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponse.#ctor(System.String,System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateModerationResponseResult})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponse"/>. </summary>
            <param name="id"> The unique identifier for the moderation request. </param>
            <param name="model"> The model used to generate the moderation results. </param>
            <param name="results"> A list of moderation objects. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="model"/> or <paramref name="results"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponse.#ctor(System.String,System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.CreateModerationResponseResult},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponse"/>. </summary>
            <param name="id"> The unique identifier for the moderation request. </param>
            <param name="model"> The model used to generate the moderation results. </param>
            <param name="results"> A list of moderation objects. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponse.Id">
            <summary> The unique identifier for the moderation request. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponse.Model">
            <summary> The model used to generate the moderation results. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponse.Results">
            <summary> A list of moderation objects. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationResponseResult">
            <summary> The CreateModerationResponseResult. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateModerationResponseResult._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResult.#ctor(System.Boolean,OpenAI.Official.Internal.CreateModerationResponseResultCategories,OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResult"/>. </summary>
            <param name="flagged"> Whether the content violates [OpenAI's usage policies](/policies/usage-policies). </param>
            <param name="categories"> A list of the categories, and whether they are flagged or not. </param>
            <param name="categoryScores"> A list of the categories along with their scores as predicted by model. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="categories"/> or <paramref name="categoryScores"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResult.#ctor(System.Boolean,OpenAI.Official.Internal.CreateModerationResponseResultCategories,OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResult"/>. </summary>
            <param name="flagged"> Whether the content violates [OpenAI's usage policies](/policies/usage-policies). </param>
            <param name="categories"> A list of the categories, and whether they are flagged or not. </param>
            <param name="categoryScores"> A list of the categories along with their scores as predicted by model. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResult"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResult.Flagged">
            <summary> Whether the content violates [OpenAI's usage policies](/policies/usage-policies). </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResult.Categories">
            <summary> A list of the categories, and whether they are flagged or not. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResult.CategoryScores">
            <summary> A list of the categories along with their scores as predicted by model. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResult.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResult.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationResponseResultCategories">
            <summary> The CreateModerationResponseResultCategories. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateModerationResponseResultCategories._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategories.#ctor(System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategories"/>. </summary>
            <param name="hate">
            Content that expresses, incites, or promotes hate based on race, gender, ethnicity,
            religion, nationality, sexual orientation, disability status, or caste. Hateful content
            aimed at non-protected groups (e.g., chess players) is harrassment.
            </param>
            <param name="hateThreatening">
            Hateful content that also includes violence or serious harm towards the targeted group
            based on race, gender, ethnicity, religion, nationality, sexual orientation, disability
            status, or caste.
            </param>
            <param name="harassment"> Content that expresses, incites, or promotes harassing language towards any target. </param>
            <param name="harassmentThreatening"> Harassment content that also includes violence or serious harm towards any target. </param>
            <param name="selfHarm">
            Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting,
            and eating disorders.
            </param>
            <param name="selfHarmIntent">
            Content where the speaker expresses that they are engaging or intend to engage in acts of
            self-harm, such as suicide, cutting, and eating disorders.
            </param>
            <param name="selfHarmInstructions">
            Content that encourages performing acts of self-harm, such as suicide, cutting, and eating
            disorders, or that gives instructions or advice on how to commit such acts.
            </param>
            <param name="sexual">
            Content meant to arouse sexual excitement, such as the description of sexual activity, or
            that promotes sexual services (excluding sex education and wellness).
            </param>
            <param name="sexualMinors"> Sexual content that includes an individual who is under 18 years old. </param>
            <param name="violence"> Content that depicts death, violence, or physical injury. </param>
            <param name="violenceGraphic"> Content that depicts death, violence, or physical injury in graphic detail. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategories.#ctor(System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategories"/>. </summary>
            <param name="hate">
            Content that expresses, incites, or promotes hate based on race, gender, ethnicity,
            religion, nationality, sexual orientation, disability status, or caste. Hateful content
            aimed at non-protected groups (e.g., chess players) is harrassment.
            </param>
            <param name="hateThreatening">
            Hateful content that also includes violence or serious harm towards the targeted group
            based on race, gender, ethnicity, religion, nationality, sexual orientation, disability
            status, or caste.
            </param>
            <param name="harassment"> Content that expresses, incites, or promotes harassing language towards any target. </param>
            <param name="harassmentThreatening"> Harassment content that also includes violence or serious harm towards any target. </param>
            <param name="selfHarm">
            Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting,
            and eating disorders.
            </param>
            <param name="selfHarmIntent">
            Content where the speaker expresses that they are engaging or intend to engage in acts of
            self-harm, such as suicide, cutting, and eating disorders.
            </param>
            <param name="selfHarmInstructions">
            Content that encourages performing acts of self-harm, such as suicide, cutting, and eating
            disorders, or that gives instructions or advice on how to commit such acts.
            </param>
            <param name="sexual">
            Content meant to arouse sexual excitement, such as the description of sexual activity, or
            that promotes sexual services (excluding sex education and wellness).
            </param>
            <param name="sexualMinors"> Sexual content that includes an individual who is under 18 years old. </param>
            <param name="violence"> Content that depicts death, violence, or physical injury. </param>
            <param name="violenceGraphic"> Content that depicts death, violence, or physical injury in graphic detail. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategories.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategories"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.Hate">
            <summary>
            Content that expresses, incites, or promotes hate based on race, gender, ethnicity,
            religion, nationality, sexual orientation, disability status, or caste. Hateful content
            aimed at non-protected groups (e.g., chess players) is harrassment.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.HateThreatening">
            <summary>
            Hateful content that also includes violence or serious harm towards the targeted group
            based on race, gender, ethnicity, religion, nationality, sexual orientation, disability
            status, or caste.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.Harassment">
            <summary> Content that expresses, incites, or promotes harassing language towards any target. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.HarassmentThreatening">
            <summary> Harassment content that also includes violence or serious harm towards any target. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.SelfHarm">
            <summary>
            Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting,
            and eating disorders.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.SelfHarmIntent">
            <summary>
            Content where the speaker expresses that they are engaging or intend to engage in acts of
            self-harm, such as suicide, cutting, and eating disorders.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.SelfHarmInstructions">
            <summary>
            Content that encourages performing acts of self-harm, such as suicide, cutting, and eating
            disorders, or that gives instructions or advice on how to commit such acts.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.Sexual">
            <summary>
            Content meant to arouse sexual excitement, such as the description of sexual activity, or
            that promotes sexual services (excluding sex education and wellness).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.SexualMinors">
            <summary> Sexual content that includes an individual who is under 18 years old. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.Violence">
            <summary> Content that depicts death, violence, or physical injury. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategories.ViolenceGraphic">
            <summary> Content that depicts death, violence, or physical injury in graphic detail. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategories.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategories.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores">
            <summary> The CreateModerationResponseResultCategoryScores. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.#ctor(System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores"/>. </summary>
            <param name="hate"> The score for the category 'hate'. </param>
            <param name="hateThreatening"> The score for the category 'hate/threatening'. </param>
            <param name="harassment"> The score for the category 'harassment'. </param>
            <param name="harassmentThreatening"> The score for the category 'harassment/threatening'. </param>
            <param name="selfHarm"> The score for the category 'self-harm'. </param>
            <param name="selfHarmIntent"> The score for the category 'self-harm/intent'. </param>
            <param name="selfHarmInstructions"> The score for the category 'self-harm/instructive'. </param>
            <param name="sexual"> The score for the category 'sexual'. </param>
            <param name="sexualMinors"> The score for the category 'sexual/minors'. </param>
            <param name="violence"> The score for the category 'violence'. </param>
            <param name="violenceGraphic"> The score for the category 'violence/graphic'. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.#ctor(System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores"/>. </summary>
            <param name="hate"> The score for the category 'hate'. </param>
            <param name="hateThreatening"> The score for the category 'hate/threatening'. </param>
            <param name="harassment"> The score for the category 'harassment'. </param>
            <param name="harassmentThreatening"> The score for the category 'harassment/threatening'. </param>
            <param name="selfHarm"> The score for the category 'self-harm'. </param>
            <param name="selfHarmIntent"> The score for the category 'self-harm/intent'. </param>
            <param name="selfHarmInstructions"> The score for the category 'self-harm/instructive'. </param>
            <param name="sexual"> The score for the category 'sexual'. </param>
            <param name="sexualMinors"> The score for the category 'sexual/minors'. </param>
            <param name="violence"> The score for the category 'violence'. </param>
            <param name="violenceGraphic"> The score for the category 'violence/graphic'. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.Hate">
            <summary> The score for the category 'hate'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.HateThreatening">
            <summary> The score for the category 'hate/threatening'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.Harassment">
            <summary> The score for the category 'harassment'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.HarassmentThreatening">
            <summary> The score for the category 'harassment/threatening'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.SelfHarm">
            <summary> The score for the category 'self-harm'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.SelfHarmIntent">
            <summary> The score for the category 'self-harm/intent'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.SelfHarmInstructions">
            <summary> The score for the category 'self-harm/instructive'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.Sexual">
            <summary> The score for the category 'sexual'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.SexualMinors">
            <summary> The score for the category 'sexual/minors'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.Violence">
            <summary> The score for the category 'violence'. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.ViolenceGraphic">
            <summary> The score for the category 'violence/graphic'. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateRunRequest">
            <summary> The CreateRunRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateRunRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateRunRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateRunRequest.#ctor(System.String,System.String,System.String,System.String,System.Collections.Generic.IList{System.BinaryData},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <param name="model">
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value
            is provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </param>
            <param name="instructions">
            Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant.
            This is useful for modifying the behavior on a per-run basis.
            </param>
            <param name="additionalInstructions">
            Appends additional instructions at the end of the instructions for the run. This is useful for
            modifying the behavior on a per-run basis without overriding other instructions.
            </param>
            <param name="tools">
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateRunRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateRunRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.AssistantId">
            <summary> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.Model">
            <summary>
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value
            is provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.Instructions">
            <summary>
            Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant.
            This is useful for modifying the behavior on a per-run basis.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.AdditionalInstructions">
            <summary>
            Appends additional instructions at the end of the instructions for the run. This is useful for
            modifying the behavior on a per-run basis without overriding other instructions.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.Tools">
            <summary>
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateRunRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateRunRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateRunRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateSpeechRequest">
            <summary> The CreateSpeechRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateSpeechRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequest.#ctor(OpenAI.Official.Internal.CreateSpeechRequestModel,System.String,OpenAI.Official.Internal.CreateSpeechRequestVoice)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequest"/>. </summary>
            <param name="model"> One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`. </param>
            <param name="input"> The text to generate audio for. The maximum length is 4096 characters. </param>
            <param name="voice">
            The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`,
            `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the
            [Text to speech guide](/docs/guides/text-to-speech/voice-options).
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="input"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequest.#ctor(OpenAI.Official.Internal.CreateSpeechRequestModel,System.String,OpenAI.Official.Internal.CreateSpeechRequestVoice,System.Nullable{OpenAI.Official.Internal.CreateSpeechRequestResponseFormat},System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequest"/>. </summary>
            <param name="model"> One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`. </param>
            <param name="input"> The text to generate audio for. The maximum length is 4096 characters. </param>
            <param name="voice">
            The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`,
            `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the
            [Text to speech guide](/docs/guides/text-to-speech/voice-options).
            </param>
            <param name="responseFormat"> The format to audio in. Supported formats are `mp3`, `opus`, `aac`, and `flac`. </param>
            <param name="speed"> The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequest.Model">
            <summary> One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequest.Input">
            <summary> The text to generate audio for. The maximum length is 4096 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequest.Voice">
            <summary>
            The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`,
            `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the
            [Text to speech guide](/docs/guides/text-to-speech/voice-options).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequest.ResponseFormat">
            <summary> The format to audio in. Supported formats are `mp3`, `opus`, `aac`, and `flac`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequest.Speed">
            <summary> The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateSpeechRequestModel">
            <summary> Enum for model in CreateSpeechRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestModel.Tts1">
            <summary> tts-1. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestModel.Tts1Hd">
            <summary> tts-1-hd. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.op_Equality(OpenAI.Official.Internal.CreateSpeechRequestModel,OpenAI.Official.Internal.CreateSpeechRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.op_Inequality(OpenAI.Official.Internal.CreateSpeechRequestModel,OpenAI.Official.Internal.CreateSpeechRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateSpeechRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.Equals(OpenAI.Official.Internal.CreateSpeechRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat">
            <summary> Enum for response_format in CreateSpeechRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Mp3">
            <summary> mp3. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Opus">
            <summary> opus. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Aac">
            <summary> aac. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Flac">
            <summary> flac. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateSpeechRequestResponseFormat,OpenAI.Official.Internal.CreateSpeechRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateSpeechRequestResponseFormat,OpenAI.Official.Internal.CreateSpeechRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateSpeechRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateSpeechRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateSpeechRequestVoice">
            <summary> Enum for voice in CreateSpeechRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestVoice"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Alloy">
            <summary> alloy. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Echo">
            <summary> echo. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Fable">
            <summary> fable. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Onyx">
            <summary> onyx. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Nova">
            <summary> nova. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateSpeechRequestVoice.Shimmer">
            <summary> shimmer. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.op_Equality(OpenAI.Official.Internal.CreateSpeechRequestVoice,OpenAI.Official.Internal.CreateSpeechRequestVoice)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestVoice"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.op_Inequality(OpenAI.Official.Internal.CreateSpeechRequestVoice,OpenAI.Official.Internal.CreateSpeechRequestVoice)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestVoice"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.op_Implicit(System.String)~OpenAI.Official.Internal.CreateSpeechRequestVoice">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateSpeechRequestVoice"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.Equals(OpenAI.Official.Internal.CreateSpeechRequestVoice)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateSpeechRequestVoice.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateThreadAndRunRequest">
            <summary> The CreateThreadAndRunRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateThreadAndRunRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadAndRunRequest.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateThreadAndRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadAndRunRequest.#ctor(System.String,OpenAI.Official.Internal.CreateThreadRequest,System.String,System.String,System.Collections.Generic.IList{System.BinaryData},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateThreadAndRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <param name="thread"> If no thread is provided, an empty thread will be created. </param>
            <param name="model">
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is
            provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </param>
            <param name="instructions">
            Override the default system message of the assistant. This is useful for modifying the behavior
            on a per-run basis.
            </param>
            <param name="tools">
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadAndRunRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateThreadAndRunRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.AssistantId">
            <summary> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.Thread">
            <summary> If no thread is provided, an empty thread will be created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.Model">
            <summary>
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is
            provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.Instructions">
            <summary>
            Override the default system message of the assistant. This is useful for modifying the behavior
            on a per-run basis.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.Tools">
            <summary>
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadAndRunRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadAndRunRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadAndRunRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateThreadRequest">
            <summary> The CreateThreadRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateThreadRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateThreadRequest"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadRequest.#ctor(System.Collections.Generic.IList{OpenAI.Official.Internal.CreateMessageRequest},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateThreadRequest"/>. </summary>
            <param name="messages"> A list of [messages](/docs/api-reference/messages) to start the thread with. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadRequest.Messages">
            <summary> A list of [messages](/docs/api-reference/messages) to start the thread with. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateThreadRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateThreadRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranscriptionRequest">
            <summary> The CreateTranscriptionRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateTranscriptionRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateTranscriptionRequestModel)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="file"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateTranscriptionRequestModel,System.String,System.String,System.Nullable{OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat},System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <param name="language">
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy
            and latency.
            </param>
            <param name="prompt">
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </param>
            <param name="responseFormat">
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </param>
            <param name="temperature">
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.File">
            <summary>
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.Model">
            <summary> ID of the model to use. Only `whisper-1` is currently available. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.Language">
            <summary>
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy
            and latency.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.Prompt">
            <summary>
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.ResponseFormat">
            <summary>
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequest.Temperature">
            <summary>
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranscriptionRequestModel">
            <summary> Enum for model in CreateTranscriptionRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestModel.Whisper1">
            <summary> whisper-1. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.op_Equality(OpenAI.Official.Internal.CreateTranscriptionRequestModel,OpenAI.Official.Internal.CreateTranscriptionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.op_Inequality(OpenAI.Official.Internal.CreateTranscriptionRequestModel,OpenAI.Official.Internal.CreateTranscriptionRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranscriptionRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.Equals(OpenAI.Official.Internal.CreateTranscriptionRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat">
            <summary> Enum for response_format in CreateTranscriptionRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Json">
            <summary> json. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Text">
            <summary> text. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Srt">
            <summary> srt. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.VerboseJson">
            <summary> verbose_json. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Vtt">
            <summary> vtt. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat,OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat,OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranscriptionResponse">
            <summary> The CreateTranscriptionResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateTranscriptionResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponse.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponse"/>. </summary>
            <param name="text"> The transcribed text for the provided audio data. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="text"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponse.#ctor(System.String,System.Nullable{OpenAI.Official.Internal.CreateTranscriptionResponseTask},System.String,System.Nullable{System.TimeSpan},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.AudioSegment},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponse"/>. </summary>
            <param name="text"> The transcribed text for the provided audio data. </param>
            <param name="task"> The label that describes which operation type generated the accompanying response data. </param>
            <param name="language"> The spoken language that was detected in the audio data. </param>
            <param name="duration"> The total duration of the audio processed to produce accompanying transcription information. </param>
            <param name="segments">
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponse.Text">
            <summary> The transcribed text for the provided audio data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponse.Task">
            <summary> The label that describes which operation type generated the accompanying response data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponse.Language">
            <summary> The spoken language that was detected in the audio data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponse.Duration">
            <summary> The total duration of the audio processed to produce accompanying transcription information. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponse.Segments">
            <summary>
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranscriptionResponseTask">
            <summary> The CreateTranscriptionResponse_task. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponseTask"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranscriptionResponseTask.Transcribe">
            <summary> transcribe. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.op_Equality(OpenAI.Official.Internal.CreateTranscriptionResponseTask,OpenAI.Official.Internal.CreateTranscriptionResponseTask)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponseTask"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.op_Inequality(OpenAI.Official.Internal.CreateTranscriptionResponseTask,OpenAI.Official.Internal.CreateTranscriptionResponseTask)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponseTask"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranscriptionResponseTask">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranscriptionResponseTask"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.Equals(OpenAI.Official.Internal.CreateTranscriptionResponseTask)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranscriptionResponseTask.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranslationRequest">
            <summary> The CreateTranslationRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateTranslationRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateTranslationRequestModel)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to translate, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="file"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequest.#ctor(System.BinaryData,OpenAI.Official.Internal.CreateTranslationRequestModel,System.String,System.Nullable{OpenAI.Official.Internal.CreateTranslationRequestResponseFormat},System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to translate, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <param name="prompt">
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </param>
            <param name="responseFormat">
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </param>
            <param name="temperature">
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequest.File">
            <summary>
            The audio file object (not file name) to translate, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequest.Model">
            <summary> ID of the model to use. Only `whisper-1` is currently available. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequest.Prompt">
            <summary>
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequest.ResponseFormat">
            <summary>
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequest.Temperature">
            <summary>
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranslationRequestModel">
            <summary> Enum for model in CreateTranslationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestModel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestModel.Whisper1">
            <summary> whisper-1. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.op_Equality(OpenAI.Official.Internal.CreateTranslationRequestModel,OpenAI.Official.Internal.CreateTranslationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestModel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.op_Inequality(OpenAI.Official.Internal.CreateTranslationRequestModel,OpenAI.Official.Internal.CreateTranslationRequestModel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestModel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranslationRequestModel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestModel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.Equals(OpenAI.Official.Internal.CreateTranslationRequestModel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestModel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat">
            <summary> Enum for response_format in CreateTranslationRequest. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Json">
            <summary> json. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Text">
            <summary> text. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Srt">
            <summary> srt. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.VerboseJson">
            <summary> verbose_json. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Vtt">
            <summary> vtt. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.op_Equality(OpenAI.Official.Internal.CreateTranslationRequestResponseFormat,OpenAI.Official.Internal.CreateTranslationRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.op_Inequality(OpenAI.Official.Internal.CreateTranslationRequestResponseFormat,OpenAI.Official.Internal.CreateTranslationRequestResponseFormat)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranslationRequestResponseFormat">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.Equals(OpenAI.Official.Internal.CreateTranslationRequestResponseFormat)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationRequestResponseFormat.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranslationResponse">
            <summary> The CreateTranslationResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.CreateTranslationResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponse.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationResponse"/>. </summary>
            <param name="text"> The translated text for the provided audio data. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="text"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponse.#ctor(System.String,System.Nullable{OpenAI.Official.Internal.CreateTranslationResponseTask},System.String,System.Nullable{System.TimeSpan},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.AudioSegment},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationResponse"/>. </summary>
            <param name="text"> The translated text for the provided audio data. </param>
            <param name="task"> The label that describes which operation type generated the accompanying response data. </param>
            <param name="language"> The spoken language that was detected in the audio data. </param>
            <param name="duration"> The total duration of the audio processed to produce accompanying translation information. </param>
            <param name="segments">
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponse.Text">
            <summary> The translated text for the provided audio data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponse.Task">
            <summary> The label that describes which operation type generated the accompanying response data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponse.Language">
            <summary> The spoken language that was detected in the audio data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponse.Duration">
            <summary> The total duration of the audio processed to produce accompanying translation information. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponse.Segments">
            <summary>
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.CreateTranslationResponseTask">
            <summary> The CreateTranslationResponse_task. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.CreateTranslationResponseTask"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.CreateTranslationResponseTask.Translate">
            <summary> translate. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.op_Equality(OpenAI.Official.Internal.CreateTranslationResponseTask,OpenAI.Official.Internal.CreateTranslationResponseTask)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationResponseTask"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.op_Inequality(OpenAI.Official.Internal.CreateTranslationResponseTask,OpenAI.Official.Internal.CreateTranslationResponseTask)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.CreateTranslationResponseTask"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.op_Implicit(System.String)~OpenAI.Official.Internal.CreateTranslationResponseTask">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.CreateTranslationResponseTask"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.Equals(OpenAI.Official.Internal.CreateTranslationResponseTask)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.CreateTranslationResponseTask.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteAssistantFileResponse">
            <summary>
            Deletes the association between the assistant and the file, but does not delete the
            [File](/docs/api-reference/files) object itself.
            </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.DeleteAssistantFileResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponse.#ctor(System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponse.#ctor(System.String,System.Boolean,OpenAI.Official.Internal.DeleteAssistantFileResponseObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantFileResponse.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantFileResponse.Deleted">
            <summary> Gets the deleted. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantFileResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteAssistantFileResponseObject">
            <summary> The DeleteAssistantFileResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.AssistantFileDeleted">
            <summary> assistant.file.deleted. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.op_Equality(OpenAI.Official.Internal.DeleteAssistantFileResponseObject,OpenAI.Official.Internal.DeleteAssistantFileResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.op_Inequality(OpenAI.Official.Internal.DeleteAssistantFileResponseObject,OpenAI.Official.Internal.DeleteAssistantFileResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.DeleteAssistantFileResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.DeleteAssistantFileResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.Equals(OpenAI.Official.Internal.DeleteAssistantFileResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantFileResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteAssistantResponse">
            <summary> The DeleteAssistantResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.DeleteAssistantResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponse.#ctor(System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponse.#ctor(System.String,System.Boolean,OpenAI.Official.Internal.DeleteAssistantResponseObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantResponse.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantResponse.Deleted">
            <summary> Gets the deleted. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteAssistantResponseObject">
            <summary> The DeleteAssistantResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteAssistantResponseObject.AssistantDeleted">
            <summary> assistant.deleted. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.op_Equality(OpenAI.Official.Internal.DeleteAssistantResponseObject,OpenAI.Official.Internal.DeleteAssistantResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.op_Inequality(OpenAI.Official.Internal.DeleteAssistantResponseObject,OpenAI.Official.Internal.DeleteAssistantResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.DeleteAssistantResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.DeleteAssistantResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.Equals(OpenAI.Official.Internal.DeleteAssistantResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteAssistantResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteFileResponse">
            <summary> The DeleteFileResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.DeleteFileResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponse.#ctor(System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponse.#ctor(System.String,OpenAI.Official.Internal.DeleteFileResponseObject,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="object"></param>
            <param name="deleted"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteFileResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteFileResponse.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteFileResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteFileResponse.Deleted">
            <summary> Gets the deleted. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteFileResponseObject">
            <summary> The DeleteFileResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteFileResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteFileResponseObject.File">
            <summary> file. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.op_Equality(OpenAI.Official.Internal.DeleteFileResponseObject,OpenAI.Official.Internal.DeleteFileResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteFileResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.op_Inequality(OpenAI.Official.Internal.DeleteFileResponseObject,OpenAI.Official.Internal.DeleteFileResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteFileResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.DeleteFileResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.DeleteFileResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.Equals(OpenAI.Official.Internal.DeleteFileResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteFileResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteModelResponse">
            <summary> The DeleteModelResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.DeleteModelResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponse.#ctor(System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteModelResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponse.#ctor(System.String,System.Boolean,OpenAI.Official.Internal.DeleteModelResponseObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteModelResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteModelResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteModelResponse.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteModelResponse.Deleted">
            <summary> Gets the deleted. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteModelResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteModelResponseObject">
            <summary> The DeleteModelResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteModelResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteModelResponseObject.Model">
            <summary> model. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.op_Equality(OpenAI.Official.Internal.DeleteModelResponseObject,OpenAI.Official.Internal.DeleteModelResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteModelResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.op_Inequality(OpenAI.Official.Internal.DeleteModelResponseObject,OpenAI.Official.Internal.DeleteModelResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteModelResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.DeleteModelResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.DeleteModelResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.Equals(OpenAI.Official.Internal.DeleteModelResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteModelResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteThreadResponse">
            <summary> The DeleteThreadResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.DeleteThreadResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponse.#ctor(System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteThreadResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponse.#ctor(System.String,System.Boolean,OpenAI.Official.Internal.DeleteThreadResponseObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteThreadResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteThreadResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteThreadResponse.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteThreadResponse.Deleted">
            <summary> Gets the deleted. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteThreadResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.DeleteThreadResponseObject">
            <summary> The DeleteThreadResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.DeleteThreadResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.DeleteThreadResponseObject.ThreadDeleted">
            <summary> thread.deleted. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.op_Equality(OpenAI.Official.Internal.DeleteThreadResponseObject,OpenAI.Official.Internal.DeleteThreadResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteThreadResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.op_Inequality(OpenAI.Official.Internal.DeleteThreadResponseObject,OpenAI.Official.Internal.DeleteThreadResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.DeleteThreadResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.DeleteThreadResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.DeleteThreadResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.Equals(OpenAI.Official.Internal.DeleteThreadResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.DeleteThreadResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Embedding">
            <summary> Represents an embedding vector returned by embedding endpoint. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.Embedding._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Embedding.#ctor(System.Int64,System.BinaryData)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Embedding"/>. </summary>
            <param name="index"> The index of the embedding in the list of embeddings. </param>
            <param name="embeddingProperty">
            The embedding vector, which is a list of floats. The length of vector depends on the model as
            listed in the [embedding guide](/docs/guides/embeddings).
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embeddingProperty"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Embedding.#ctor(System.Int64,System.BinaryData,OpenAI.Official.Internal.EmbeddingObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Embedding"/>. </summary>
            <param name="index"> The index of the embedding in the list of embeddings. </param>
            <param name="embeddingProperty">
            The embedding vector, which is a list of floats. The length of vector depends on the model as
            listed in the [embedding guide](/docs/guides/embeddings).
            </param>
            <param name="object"> The object type, which is always "embedding". </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Embedding.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Embedding"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Embedding.Index">
            <summary> The index of the embedding in the list of embeddings. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Embedding.EmbeddingProperty">
            <summary>
            The embedding vector, which is a list of floats. The length of vector depends on the model as
            listed in the [embedding guide](/docs/guides/embeddings).
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:System.Collections.Generic.IList`1"/> where <c>T</c> is of type <see cref="T:System.Double"/></description>
            </item>
            <item>
            <description><see cref="T:System.String"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Embedding.Object">
            <summary> The object type, which is always "embedding". </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Embedding.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Embedding.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.EmbeddingObject">
            <summary> The Embedding_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.EmbeddingObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.EmbeddingObject.Embedding">
            <summary> embedding. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.op_Equality(OpenAI.Official.Internal.EmbeddingObject,OpenAI.Official.Internal.EmbeddingObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.EmbeddingObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.op_Inequality(OpenAI.Official.Internal.EmbeddingObject,OpenAI.Official.Internal.EmbeddingObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.EmbeddingObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.op_Implicit(System.String)~OpenAI.Official.Internal.EmbeddingObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.EmbeddingObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.Equals(OpenAI.Official.Internal.EmbeddingObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.EmbeddingObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Embeddings">
            <summary> The Embeddings sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Embeddings.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Embeddings.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.#ctor">
            <summary> Initializes a new instance of Embeddings for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Embeddings. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.CreateEmbeddingAsync(OpenAI.Official.Internal.CreateEmbeddingRequest,System.Threading.CancellationToken)">
            <summary> Creates an embedding vector representing the input text. </summary>
            <param name="embedding"> The <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embedding"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.CreateEmbedding(OpenAI.Official.Internal.CreateEmbeddingRequest,System.Threading.CancellationToken)">
            <summary> Creates an embedding vector representing the input text. </summary>
            <param name="embedding"> The <see cref="T:OpenAI.Official.Internal.CreateEmbeddingRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="embedding"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.CreateEmbeddingAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an embedding vector representing the input text.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Embeddings.CreateEmbeddingAsync(OpenAI.Official.Internal.CreateEmbeddingRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Embeddings.CreateEmbedding(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an embedding vector representing the input text.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Embeddings.CreateEmbedding(OpenAI.Official.Internal.CreateEmbeddingRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.Files">
            <summary> The Files sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Files.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Files.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.#ctor">
            <summary> Initializes a new instance of Files for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Files. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.CreateFileAsync(OpenAI.Official.Internal.CreateFileRequest,System.Threading.CancellationToken)">
             <summary>
             Upload a file that can be used across various endpoints. The size of all the files uploaded by
             one organization can be up to 100 GB.
            
             The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See
             the [Assistants Tools guide](/docs/assistants/tools) to learn more about the types of files
             supported. The Fine-tuning API only supports `.jsonl` files.
            
             Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
             </summary>
             <param name="file"> The <see cref="T:OpenAI.Official.Internal.CreateFileRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="file"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.CreateFile(OpenAI.Official.Internal.CreateFileRequest,System.Threading.CancellationToken)">
             <summary>
             Upload a file that can be used across various endpoints. The size of all the files uploaded by
             one organization can be up to 100 GB.
            
             The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See
             the [Assistants Tools guide](/docs/assistants/tools) to learn more about the types of files
             supported. The Fine-tuning API only supports `.jsonl` files.
            
             Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
             </summary>
             <param name="file"> The <see cref="T:OpenAI.Official.Internal.CreateFileRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="file"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.CreateFileAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Upload a file that can be used across various endpoints. The size of all the files uploaded by
             one organization can be up to 100 GB.
            
             The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See
             the [Assistants Tools guide](/docs/assistants/tools) to learn more about the types of files
             supported. The Fine-tuning API only supports `.jsonl` files.
            
             Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.CreateFileAsync(OpenAI.Official.Internal.CreateFileRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.CreateFile(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Upload a file that can be used across various endpoints. The size of all the files uploaded by
             one organization can be up to 100 GB.
            
             The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See
             the [Assistants Tools guide](/docs/assistants/tools) to learn more about the types of files
             supported. The Fine-tuning API only supports `.jsonl` files.
            
             Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.CreateFile(OpenAI.Official.Internal.CreateFileRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.GetFilesAsync(System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of files that belong to the user's organization. </summary>
            <param name="purpose"> Only return files with the given purpose. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.GetFiles(System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of files that belong to the user's organization. </summary>
            <param name="purpose"> Only return files with the given purpose. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.GetFilesAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of files that belong to the user's organization.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.GetFilesAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="purpose"> Only return files with the given purpose. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.GetFiles(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of files that belong to the user's organization.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.GetFiles(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="purpose"> Only return files with the given purpose. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.RetrieveFileAsync(System.String,System.Threading.CancellationToken)">
            <summary> Returns information about a specific file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.RetrieveFile(System.String,System.Threading.CancellationToken)">
            <summary> Returns information about a specific file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.RetrieveFileAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns information about a specific file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.RetrieveFileAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.RetrieveFile(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns information about a specific file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.RetrieveFile(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DeleteFileAsync(System.String,System.Threading.CancellationToken)">
            <summary> Delete a file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DeleteFile(System.String,System.Threading.CancellationToken)">
            <summary> Delete a file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DeleteFileAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a file
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.DeleteFileAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DeleteFile(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a file
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.DeleteFile(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DownloadFileAsync(System.String,System.Threading.CancellationToken)">
            <summary> Returns the contents of the specified file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DownloadFile(System.String,System.Threading.CancellationToken)">
            <summary> Returns the contents of the specified file. </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DownloadFileAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns the contents of the specified file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.DownloadFileAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Files.DownloadFile(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns the contents of the specified file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Files.DownloadFile(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fileId"> The ID of the file to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTune">
            <summary> The `FineTune` object represents a legacy fine-tune job that has been created through the API. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTune._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTune.#ctor(System.String,System.DateTimeOffset,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.FineTuneStatus,OpenAI.Official.Internal.FineTuneHyperparams,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTune"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="updatedAt"> The Unix timestamp (in seconds) for when the fine-tuning job was last updated. </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel"> The name of the fine-tuned model that is being created. </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparams">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
            </param>
            <param name="trainingFiles"> The list of files used for training. </param>
            <param name="validationFiles"> The list of files used for validation. </param>
            <param name="resultFiles"> The compiled results files for the fine-tuning job. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="model"/>, <paramref name="organizationId"/>, <paramref name="hyperparams"/>, <paramref name="trainingFiles"/>, <paramref name="validationFiles"/> or <paramref name="resultFiles"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTune.#ctor(System.String,OpenAI.Official.Internal.FineTuneObject,System.DateTimeOffset,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.FineTuneStatus,OpenAI.Official.Internal.FineTuneHyperparams,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.FineTuneEvent},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTune"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="object"> The object type, which is always "fine-tune". </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="updatedAt"> The Unix timestamp (in seconds) for when the fine-tuning job was last updated. </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel"> The name of the fine-tuned model that is being created. </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparams">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
            </param>
            <param name="trainingFiles"> The list of files used for training. </param>
            <param name="validationFiles"> The list of files used for validation. </param>
            <param name="resultFiles"> The compiled results files for the fine-tuning job. </param>
            <param name="events"> The list of events that have been observed in the lifecycle of the FineTune job. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTune.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTune"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Id">
            <summary> The object identifier, which can be referenced in the API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Object">
            <summary> The object type, which is always "fine-tune". </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the fine-tuning job was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.UpdatedAt">
            <summary> The Unix timestamp (in seconds) for when the fine-tuning job was last updated. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Model">
            <summary> The base model that is being fine-tuned. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.FineTunedModel">
            <summary> The name of the fine-tuned model that is being created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.OrganizationId">
            <summary> The organization that owns the fine-tuning job. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Status">
            <summary>
            The current status of the fine-tuning job, which can be either `created`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Hyperparams">
            <summary>
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.TrainingFiles">
            <summary> The list of files used for training. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.ValidationFiles">
            <summary> The list of files used for validation. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.ResultFiles">
            <summary> The compiled results files for the fine-tuning job. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTune.Events">
            <summary> The list of events that have been observed in the lifecycle of the FineTune job. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTune.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTune.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuneEvent">
            <summary> The FineTuneEvent. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuneEvent._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneEvent.#ctor(System.String,System.DateTimeOffset,System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneEvent"/>. </summary>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="object"/>, <paramref name="level"/> or <paramref name="message"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneEvent.#ctor(System.String,System.DateTimeOffset,System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneEvent"/>. </summary>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneEvent.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneEvent"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneEvent.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneEvent.CreatedAt">
            <summary> Gets the created at. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneEvent.Level">
            <summary> Gets the level. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneEvent.Message">
            <summary> Gets the message. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneEvent.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneEvent.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuneHyperparams">
            <summary> The FineTuneHyperparams. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuneHyperparams._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneHyperparams.#ctor(System.Int64,System.Int64,System.Double,System.Double)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneHyperparams"/>. </summary>
            <param name="nEpochs">
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </param>
            <param name="batchSize">
            The batch size to use for training. The batch size is the number of training examples used to
            train a single forward and backward pass.
            </param>
            <param name="promptLossWeight"> The weight to use for loss on the prompt tokens. </param>
            <param name="learningRateMultiplier"> The learning rate multiplier to use for training. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneHyperparams.#ctor(System.Int64,System.Int64,System.Double,System.Double,System.Nullable{System.Boolean},System.String,System.Nullable{System.Int64},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneHyperparams"/>. </summary>
            <param name="nEpochs">
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </param>
            <param name="batchSize">
            The batch size to use for training. The batch size is the number of training examples used to
            train a single forward and backward pass.
            </param>
            <param name="promptLossWeight"> The weight to use for loss on the prompt tokens. </param>
            <param name="learningRateMultiplier"> The learning rate multiplier to use for training. </param>
            <param name="computeClassificationMetrics"> The classification metrics to compute using the validation dataset at the end of every epoch. </param>
            <param name="classificationPositiveClass"> The positive class to use for computing classification metrics. </param>
            <param name="classificationNClasses"> The number of classes to use for computing classification metrics. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneHyperparams.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneHyperparams"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.NEpochs">
            <summary>
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.BatchSize">
            <summary>
            The batch size to use for training. The batch size is the number of training examples used to
            train a single forward and backward pass.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.PromptLossWeight">
            <summary> The weight to use for loss on the prompt tokens. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.LearningRateMultiplier">
            <summary> The learning rate multiplier to use for training. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.ComputeClassificationMetrics">
            <summary> The classification metrics to compute using the validation dataset at the end of every epoch. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.ClassificationPositiveClass">
            <summary> The positive class to use for computing classification metrics. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneHyperparams.ClassificationNClasses">
            <summary> The number of classes to use for computing classification metrics. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneHyperparams.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneHyperparams.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuneObject">
            <summary> The FineTune_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneObject.FineTune">
            <summary> fine-tune. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.op_Equality(OpenAI.Official.Internal.FineTuneObject,OpenAI.Official.Internal.FineTuneObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuneObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.op_Inequality(OpenAI.Official.Internal.FineTuneObject,OpenAI.Official.Internal.FineTuneObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuneObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.op_Implicit(System.String)~OpenAI.Official.Internal.FineTuneObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.FineTuneObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.Equals(OpenAI.Official.Internal.FineTuneObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.FineTunes">
            <summary> The FineTunes sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTunes.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTunes.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.#ctor">
            <summary> Initializes a new instance of FineTunes for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of FineTunes. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CreateFineTuneAsync(OpenAI.Official.Internal.CreateFineTuneRequest,System.Threading.CancellationToken)">
             <summary>
             Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             </summary>
             <param name="fineTune"> The <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTune"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CreateFineTune(OpenAI.Official.Internal.CreateFineTuneRequest,System.Threading.CancellationToken)">
             <summary>
             Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             </summary>
             <param name="fineTune"> The <see cref="T:OpenAI.Official.Internal.CreateFineTuneRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTune"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CreateFineTuneAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.CreateFineTuneAsync(OpenAI.Official.Internal.CreateFineTuneRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CreateFineTune(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.CreateFineTune(OpenAI.Official.Internal.CreateFineTuneRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTunesAsync(System.Threading.CancellationToken)">
            <summary> List your organization's fine-tuning jobs. </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTunes(System.Threading.CancellationToken)">
            <summary> List your organization's fine-tuning jobs. </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTunesAsync(System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] List your organization's fine-tuning jobs
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.GetFineTunesAsync(System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTunes(System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] List your organization's fine-tuning jobs
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.GetFineTunes(System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTuneAsync(System.String,System.Threading.CancellationToken)">
             <summary>
             Gets info about the fine-tune job.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTune(System.String,System.Threading.CancellationToken)">
             <summary>
             Gets info about the fine-tune job.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTuneAsync(System.String,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Gets info about the fine-tune job.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTuneAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTune(System.String,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Gets info about the fine-tune job.
            
             [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.RetrieveFineTune(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEventsAsync(System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
             <summary> Get fine-grained status updates for a fine-tune job. </summary>
             <param name="fineTuneId"> The ID of the fine-tune job to get events for. </param>
             <param name="stream">
             Whether to stream events for the fine-tune job. If set to true, events will be sent as
             data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available. The stream will terminate with a `data: [DONE]` message when the
             job is finished (succeeded, cancelled, or failed).
            
             If set to false, only events generated so far will be returned.
             </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEvents(System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
             <summary> Get fine-grained status updates for a fine-tune job. </summary>
             <param name="fineTuneId"> The ID of the fine-tune job to get events for. </param>
             <param name="stream">
             Whether to stream events for the fine-tune job. If set to true, events will be sent as
             data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available. The stream will terminate with a `data: [DONE]` message when the
             job is finished (succeeded, cancelled, or failed).
            
             If set to false, only events generated so far will be returned.
             </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEventsAsync(System.String,System.Nullable{System.Boolean},System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Get fine-grained status updates for a fine-tune job.
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEventsAsync(System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job to get events for. </param>
             <param name="stream">
             Whether to stream events for the fine-tune job. If set to true, events will be sent as
             data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available. The stream will terminate with a `data: [DONE]` message when the
             job is finished (succeeded, cancelled, or failed).
            
             If set to false, only events generated so far will be returned.
             </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEvents(System.String,System.Nullable{System.Boolean},System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Get fine-grained status updates for a fine-tune job.
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.GetFineTuneEvents(System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuneId"> The ID of the fine-tune job to get events for. </param>
             <param name="stream">
             Whether to stream events for the fine-tune job. If set to true, events will be sent as
             data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available. The stream will terminate with a `data: [DONE]` message when the
             job is finished (succeeded, cancelled, or failed).
            
             If set to false, only events generated so far will be returned.
             </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CancelFineTuneAsync(System.String,System.Threading.CancellationToken)">
            <summary> Immediately cancel a fine-tune job. </summary>
            <param name="fineTuneId"> The ID of the fine-tune job to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CancelFineTune(System.String,System.Threading.CancellationToken)">
            <summary> Immediately cancel a fine-tune job. </summary>
            <param name="fineTuneId"> The ID of the fine-tune job to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CancelFineTuneAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Immediately cancel a fine-tune job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.CancelFineTuneAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuneId"> The ID of the fine-tune job to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTunes.CancelFineTune(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Immediately cancel a fine-tune job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTunes.CancelFineTune(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuneId"> The ID of the fine-tune job to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuneId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuneId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuneStatus">
            <summary> Enum for status in FineTune. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuneStatus"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneStatus.Created">
            <summary> created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneStatus.Running">
            <summary> running. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneStatus.Succeeded">
            <summary> succeeded. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneStatus.Failed">
            <summary> failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuneStatus.Cancelled">
            <summary> cancelled. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.op_Equality(OpenAI.Official.Internal.FineTuneStatus,OpenAI.Official.Internal.FineTuneStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuneStatus"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.op_Inequality(OpenAI.Official.Internal.FineTuneStatus,OpenAI.Official.Internal.FineTuneStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuneStatus"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.op_Implicit(System.String)~OpenAI.Official.Internal.FineTuneStatus">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.FineTuneStatus"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.Equals(OpenAI.Official.Internal.FineTuneStatus)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuneStatus.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuning">
            <summary> The FineTuning sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuning.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuning.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuning.#ctor">
            <summary> Initializes a new instance of FineTuning for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuning.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of FineTuning. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuning.GetFineTuningJobsClient">
            <summary> Initializes a new instance of FineTuningJobs. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJob">
            <summary> The FineTuningJob. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuningJob._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJob.#ctor(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.String,System.String,System.String,OpenAI.Official.Internal.FineTuningJobStatus,OpenAI.Official.Internal.FineTuningJobHyperparameters,System.String,System.String,System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Int64},OpenAI.Official.Internal.FineTuningJobError)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJob"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="finishedAt">
            The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be
            null if the fine-tuning job is still running.
            </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel">
            The name of the fine-tuned model that is being created. The value will be null if the
            fine-tuning job is still running.
            </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparameters">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
            </param>
            <param name="trainingFile">
            The file ID used for training. You can retrieve the training data with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="validationFile">
            The file ID used for validation. You can retrieve the validation results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="resultFiles">
            The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="trainedTokens">
            The total number of billable tokens processed by this fine tuning job. The value will be null
            if the fine-tuning job is still running.
            </param>
            <param name="error">
            For fine-tuning jobs that have `failed`, this will contain more information on the cause of the
            failure.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="model"/>, <paramref name="organizationId"/>, <paramref name="hyperparameters"/>, <paramref name="trainingFile"/> or <paramref name="resultFiles"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJob.#ctor(System.String,OpenAI.Official.Internal.FineTuningJobObject,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.String,System.String,System.String,OpenAI.Official.Internal.FineTuningJobStatus,OpenAI.Official.Internal.FineTuningJobHyperparameters,System.String,System.String,System.Collections.Generic.IReadOnlyList{System.String},System.Nullable{System.Int64},OpenAI.Official.Internal.FineTuningJobError,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJob"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="object"> The object type, which is always "fine_tuning.job". </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="finishedAt">
            The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be
            null if the fine-tuning job is still running.
            </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel">
            The name of the fine-tuned model that is being created. The value will be null if the
            fine-tuning job is still running.
            </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparameters">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
            </param>
            <param name="trainingFile">
            The file ID used for training. You can retrieve the training data with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="validationFile">
            The file ID used for validation. You can retrieve the validation results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="resultFiles">
            The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="trainedTokens">
            The total number of billable tokens processed by this fine tuning job. The value will be null
            if the fine-tuning job is still running.
            </param>
            <param name="error">
            For fine-tuning jobs that have `failed`, this will contain more information on the cause of the
            failure.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJob.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJob"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Id">
            <summary> The object identifier, which can be referenced in the API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Object">
            <summary> The object type, which is always "fine_tuning.job". </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the fine-tuning job was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.FinishedAt">
            <summary>
            The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be
            null if the fine-tuning job is still running.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Model">
            <summary> The base model that is being fine-tuned. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.FineTunedModel">
            <summary>
            The name of the fine-tuned model that is being created. The value will be null if the
            fine-tuning job is still running.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.OrganizationId">
            <summary> The organization that owns the fine-tuning job. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Status">
            <summary>
            The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Hyperparameters">
            <summary>
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.TrainingFile">
            <summary>
            The file ID used for training. You can retrieve the training data with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.ValidationFile">
            <summary>
            The file ID used for validation. You can retrieve the validation results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.ResultFiles">
            <summary>
            The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.TrainedTokens">
            <summary>
            The total number of billable tokens processed by this fine tuning job. The value will be null
            if the fine-tuning job is still running.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJob.Error">
            <summary>
            For fine-tuning jobs that have `failed`, this will contain more information on the cause of the
            failure.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJob.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJob.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobError">
            <summary> The FineTuningJobError. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuningJobError._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobError.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobError"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobError.#ctor(System.String,System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobError"/>. </summary>
            <param name="message"> A human-readable error message. </param>
            <param name="code"> A machine-readable error code. </param>
            <param name="param">
            The parameter that was invalid, usually `training_file` or `validation_file`. This field
            will be null if the failure was not parameter-specific.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobError.Message">
            <summary> A human-readable error message. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobError.Code">
            <summary> A machine-readable error code. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobError.Param">
            <summary>
            The parameter that was invalid, usually `training_file` or `validation_file`. This field
            will be null if the failure was not parameter-specific.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobError.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobError.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobEvent">
            <summary> The FineTuningJobEvent. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuningJobEvent._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEvent.#ctor(System.String,System.String,System.DateTimeOffset,OpenAI.Official.Internal.FineTuningJobEventLevel,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobEvent"/>. </summary>
            <param name="id"></param>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="object"/> or <paramref name="message"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEvent.#ctor(System.String,System.String,System.DateTimeOffset,OpenAI.Official.Internal.FineTuningJobEventLevel,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobEvent"/>. </summary>
            <param name="id"></param>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEvent.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobEvent"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEvent.Id">
            <summary> Gets the id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEvent.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEvent.CreatedAt">
            <summary> Gets the created at. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEvent.Level">
            <summary> Gets the level. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEvent.Message">
            <summary> Gets the message. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEvent.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEvent.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobEventLevel">
            <summary> Enum for level in FineTuningJobEvent. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobEventLevel"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEventLevel.Info">
            <summary> info. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEventLevel.Warn">
            <summary> warn. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobEventLevel.Error">
            <summary> error. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.op_Equality(OpenAI.Official.Internal.FineTuningJobEventLevel,OpenAI.Official.Internal.FineTuningJobEventLevel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobEventLevel"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.op_Inequality(OpenAI.Official.Internal.FineTuningJobEventLevel,OpenAI.Official.Internal.FineTuningJobEventLevel)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobEventLevel"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.op_Implicit(System.String)~OpenAI.Official.Internal.FineTuningJobEventLevel">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.FineTuningJobEventLevel"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.Equals(OpenAI.Official.Internal.FineTuningJobEventLevel)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobEventLevel.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobHyperparameters">
            <summary> The FineTuningJobHyperparameters. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FineTuningJobHyperparameters._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobHyperparameters.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobHyperparameters"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobHyperparameters.#ctor(System.BinaryData,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
             <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobHyperparameters"/>. </summary>
             <param name="nEpochs">
             The number of epochs to train the model for. An epoch refers to one full cycle through the
             training dataset.
            
             "Auto" decides the optimal number of epochs based on the size of the dataset. If setting the
             number manually, we support any number between 1 and 50 epochs.
             </param>
             <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobHyperparameters.NEpochs">
             <summary>
             The number of epochs to train the model for. An epoch refers to one full cycle through the
             training dataset.
            
             "Auto" decides the optimal number of epochs based on the size of the dataset. If setting the
             number manually, we support any number between 1 and 50 epochs.
             <para>
             To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
             </para>
             <para>
             To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
             </para>
             <para>
             <remarks>
             Supported types:
             <list type="bullet">
             <item>
             <description>"auto"</description>
             </item>
             <item>
             <description><see cref="T:System.Int64"/></description>
             </item>
             </list>
             </remarks>
             Examples:
             <list type="bullet">
             <item>
             <term>BinaryData.FromObjectAsJson("foo")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromString("\"foo\"")</term>
             <description>Creates a payload of "foo".</description>
             </item>
             <item>
             <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             <item>
             <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
             <description>Creates a payload of { "key": "value" }.</description>
             </item>
             </list>
             </para>
             </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobHyperparameters.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobHyperparameters.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobObject">
            <summary> The FineTuningJob_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobObject.FineTuningJob">
            <summary> fine_tuning.job. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.op_Equality(OpenAI.Official.Internal.FineTuningJobObject,OpenAI.Official.Internal.FineTuningJobObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.op_Inequality(OpenAI.Official.Internal.FineTuningJobObject,OpenAI.Official.Internal.FineTuningJobObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.op_Implicit(System.String)~OpenAI.Official.Internal.FineTuningJobObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.FineTuningJobObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.Equals(OpenAI.Official.Internal.FineTuningJobObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobs">
            <summary> The FineTuningJobs sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobs.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobs.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.#ctor">
            <summary> Initializes a new instance of FineTuningJobs for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of FineTuningJobs. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJobAsync(OpenAI.Official.Internal.CreateFineTuningJobRequest,System.Threading.CancellationToken)">
             <summary>
             Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the
             fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             </summary>
             <param name="job"> The <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="job"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJob(OpenAI.Official.Internal.CreateFineTuningJobRequest,System.Threading.CancellationToken)">
             <summary>
             Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the
             fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             </summary>
             <param name="job"> The <see cref="T:OpenAI.Official.Internal.CreateFineTuningJobRequest"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="job"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJobAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the
             fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJobAsync(OpenAI.Official.Internal.CreateFineTuningJobRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJob(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Creates a job that fine-tunes a specified model from a given dataset.
            
             Response includes details of the enqueued job including job status and the name of the
             fine-tuned models once complete.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.CreateFineTuningJob(OpenAI.Official.Internal.CreateFineTuningJobRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="content"> The content to send as the body of the request. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobsAsync(System.String,System.Nullable{System.Int64},System.Threading.CancellationToken)">
            <param name="after"> Identifier for the last job from the previous pagination request. </param>
            <param name="limit"> Number of fine-tuning jobs to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobs(System.String,System.Nullable{System.Int64},System.Threading.CancellationToken)">
            <param name="after"> Identifier for the last job from the previous pagination request. </param>
            <param name="limit"> Number of fine-tuning jobs to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobsAsync(System.String,System.Nullable{System.Int64},System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method]
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobsAsync(System.String,System.Nullable{System.Int64},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="after"> Identifier for the last job from the previous pagination request. </param>
            <param name="limit"> Number of fine-tuning jobs to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobs(System.String,System.Nullable{System.Int64},System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method]
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.GetPaginatedFineTuningJobs(System.String,System.Nullable{System.Int64},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="after"> Identifier for the last job from the previous pagination request. </param>
            <param name="limit"> Number of fine-tuning jobs to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJobAsync(System.String,System.Threading.CancellationToken)">
             <summary>
             Get info about a fine-tuning job.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             </summary>
             <param name="fineTuningJobId"> The <see cref="T:System.String"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJob(System.String,System.Threading.CancellationToken)">
             <summary>
             Get info about a fine-tuning job.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             </summary>
             <param name="fineTuningJobId"> The <see cref="T:System.String"/> to use. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJobAsync(System.String,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Get info about a fine-tuning job.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJobAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuningJobId"> The <see cref="T:System.String"/> to use. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJob(System.String,System.ClientModel.RequestOptions)">
             <summary>
             [Protocol Method] Get info about a fine-tuning job.
            
             [Learn more about fine-tuning](/docs/guides/fine-tuning)
             <list type="bullet">
             <item>
             <description>
             This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
             </description>
             </item>
             <item>
             <description>
             Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.RetrieveFineTuningJob(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
             </description>
             </item>
             </list>
             </summary>
             <param name="fineTuningJobId"> The <see cref="T:System.String"/> to use. </param>
             <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
             <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
             <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
             <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEventsAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Get status updates for a fine-tuning job. </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to get events for. </param>
            <param name="after"> Identifier for the last event from the previous pagination request. </param>
            <param name="limit"> Number of events to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEvents(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Get status updates for a fine-tuning job. </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to get events for. </param>
            <param name="after"> Identifier for the last event from the previous pagination request. </param>
            <param name="limit"> Number of events to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEventsAsync(System.String,System.String,System.Nullable{System.Int32},System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Get status updates for a fine-tuning job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEventsAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to get events for. </param>
            <param name="after"> Identifier for the last event from the previous pagination request. </param>
            <param name="limit"> Number of events to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEvents(System.String,System.String,System.Nullable{System.Int32},System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Get status updates for a fine-tuning job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.GetFineTuningEvents(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to get events for. </param>
            <param name="after"> Identifier for the last event from the previous pagination request. </param>
            <param name="limit"> Number of events to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJobAsync(System.String,System.Threading.CancellationToken)">
            <summary> Immediately cancel a fine-tune job. </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJob(System.String,System.Threading.CancellationToken)">
            <summary> Immediately cancel a fine-tune job. </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJobAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Immediately cancel a fine-tune job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJobAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJob(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Immediately cancel a fine-tune job.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.FineTuningJobs.CancelFineTuningJob(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="fineTuningJobId"> The ID of the fine-tuning job to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="fineTuningJobId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="fineTuningJobId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.FineTuningJobStatus">
            <summary> Enum for status in FineTuningJob. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FineTuningJobStatus"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Created">
            <summary> created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Pending">
            <summary> pending. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Running">
            <summary> running. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Succeeded">
            <summary> succeeded. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Failed">
            <summary> failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FineTuningJobStatus.Cancelled">
            <summary> cancelled. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.op_Equality(OpenAI.Official.Internal.FineTuningJobStatus,OpenAI.Official.Internal.FineTuningJobStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobStatus"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.op_Inequality(OpenAI.Official.Internal.FineTuningJobStatus,OpenAI.Official.Internal.FineTuningJobStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.FineTuningJobStatus"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.op_Implicit(System.String)~OpenAI.Official.Internal.FineTuningJobStatus">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.FineTuningJobStatus"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.Equals(OpenAI.Official.Internal.FineTuningJobStatus)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.FineTuningJobStatus.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.FunctionObject">
            <summary> The FunctionObject. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.FunctionObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FunctionObject"/>. </summary>
            <param name="name">
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionObject.#ctor(System.String,System.String,OpenAI.Official.Internal.FunctionParameters,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FunctionObject"/>. </summary>
            <param name="description">
            A description of what the function does, used by the model to choose when and how to call the
            function.
            </param>
            <param name="name">
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </param>
            <param name="parameters"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FunctionObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FunctionObject.Description">
            <summary>
            A description of what the function does, used by the model to choose when and how to call the
            function.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FunctionObject.Name">
            <summary>
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.FunctionObject.Parameters">
            <summary> Gets or sets the parameters. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.FunctionParameters">
            <summary>
            The parameters the functions accepts, described as a JSON Schema object. See the
            [guide](/docs/guides/gpt/function-calling) for examples, and the
            [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation
            about the format.\n\nTo describe a function that accepts no parameters, provide the value
            `{\"type\": \"object\", \"properties\": {}}`.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionParameters.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FunctionParameters"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionParameters.#ctor(System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.FunctionParameters"/>. </summary>
            <param name="additionalProperties"> Additional Properties. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.FunctionParameters.AdditionalProperties">
            <summary>
            Additional Properties
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionParameters.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.FunctionParameters.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.Image">
            <summary> Represents the url or the content of an image generated by the OpenAI API. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.Image._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Image.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Image"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Image.#ctor(System.BinaryData,System.Uri,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Image"/>. </summary>
            <param name="b64Json"> The base64-encoded JSON of the generated image, if `response_format` is `b64_json`. </param>
            <param name="url"> The URL of the generated image, if `response_format` is `url` (default). </param>
            <param name="revisedPrompt"> The prompt that was used to generate the image, if there was any revision to the prompt. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.Image.B64Json">
            <summary>
            The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
            <para>
            To assign a byte[] to this property use <see cref="M:System.BinaryData.FromBytes(System.Byte[])"/>.
            The byte[] will be serialized to a Base64 encoded string.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
            <description>Creates a payload of "AQID".</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Image.Url">
            <summary> The URL of the generated image, if `response_format` is `url` (default). </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Image.RevisedPrompt">
            <summary> The prompt that was used to generate the image, if there was any revision to the prompt. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Image.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Image.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.Images">
            <summary> The Images sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Images.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Images.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.#ctor">
            <summary> Initializes a new instance of Images for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Images. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageAsync(OpenAI.Official.Internal.CreateImageRequest,System.Threading.CancellationToken)">
            <summary> Creates an image given a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImage(OpenAI.Official.Internal.CreateImageRequest,System.Threading.CancellationToken)">
            <summary> Creates an image given a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an image given a prompt
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImageAsync(OpenAI.Official.Internal.CreateImageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImage(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an image given a prompt
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImage(OpenAI.Official.Internal.CreateImageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageEditAsync(OpenAI.Official.Internal.CreateImageEditRequest,System.Threading.CancellationToken)">
            <summary> Creates an edited or extended image given an original image and a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageEditRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageEdit(OpenAI.Official.Internal.CreateImageEditRequest,System.Threading.CancellationToken)">
            <summary> Creates an edited or extended image given an original image and a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageEditRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageEditAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an edited or extended image given an original image and a prompt.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImageEditAsync(OpenAI.Official.Internal.CreateImageEditRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageEdit(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an edited or extended image given an original image and a prompt.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImageEdit(OpenAI.Official.Internal.CreateImageEditRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageVariationAsync(OpenAI.Official.Internal.CreateImageVariationRequest,System.Threading.CancellationToken)">
            <summary> Creates an edited or extended image given an original image and a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageVariation(OpenAI.Official.Internal.CreateImageVariationRequest,System.Threading.CancellationToken)">
            <summary> Creates an edited or extended image given an original image and a prompt. </summary>
            <param name="image"> The <see cref="T:OpenAI.Official.Internal.CreateImageVariationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="image"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageVariationAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an edited or extended image given an original image and a prompt.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImageVariationAsync(OpenAI.Official.Internal.CreateImageVariationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Images.CreateImageVariation(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Creates an edited or extended image given an original image and a prompt.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Images.CreateImageVariation(OpenAI.Official.Internal.CreateImageVariationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.ImagesResponse">
            <summary> The ImagesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ImagesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ImagesResponse.#ctor(System.DateTimeOffset,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Image})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ImagesResponse"/>. </summary>
            <param name="created"></param>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ImagesResponse.#ctor(System.DateTimeOffset,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.Image},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ImagesResponse"/>. </summary>
            <param name="created"></param>
            <param name="data"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ImagesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ImagesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ImagesResponse.Created">
            <summary> Gets the created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ImagesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ImagesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ImagesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListAssistantFilesResponse">
            <summary> The ListAssistantFilesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListAssistantFilesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AssistantFileObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponse.#ctor(OpenAI.Official.Internal.ListAssistantFilesResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.AssistantFileObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListAssistantFilesResponseObject">
            <summary> The ListAssistantFilesResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantFilesResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.op_Equality(OpenAI.Official.Internal.ListAssistantFilesResponseObject,OpenAI.Official.Internal.ListAssistantFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.op_Inequality(OpenAI.Official.Internal.ListAssistantFilesResponseObject,OpenAI.Official.Internal.ListAssistantFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListAssistantFilesResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListAssistantFilesResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.Equals(OpenAI.Official.Internal.ListAssistantFilesResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantFilesResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListAssistantsResponse">
            <summary> The ListAssistantsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListAssistantsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AssistantObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantsResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponse.#ctor(OpenAI.Official.Internal.ListAssistantsResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.AssistantObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListAssistantsResponseObject">
            <summary> The ListAssistantsResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListAssistantsResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListAssistantsResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.op_Equality(OpenAI.Official.Internal.ListAssistantsResponseObject,OpenAI.Official.Internal.ListAssistantsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListAssistantsResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.op_Inequality(OpenAI.Official.Internal.ListAssistantsResponseObject,OpenAI.Official.Internal.ListAssistantsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListAssistantsResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListAssistantsResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListAssistantsResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.Equals(OpenAI.Official.Internal.ListAssistantsResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListAssistantsResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListFilesResponse">
            <summary> The ListFilesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListFilesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFilesResponse"/>. </summary>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponse.#ctor(System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.OpenAIFile},OpenAI.Official.Internal.ListFilesResponseObject,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFilesResponse"/>. </summary>
            <param name="data"></param>
            <param name="object"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFilesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFilesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFilesResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListFilesResponseObject">
            <summary> The ListFilesResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFilesResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFilesResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.op_Equality(OpenAI.Official.Internal.ListFilesResponseObject,OpenAI.Official.Internal.ListFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListFilesResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.op_Inequality(OpenAI.Official.Internal.ListFilesResponseObject,OpenAI.Official.Internal.ListFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListFilesResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListFilesResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListFilesResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.Equals(OpenAI.Official.Internal.ListFilesResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListFilesResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListFineTuneEventsResponse">
            <summary> The ListFineTuneEventsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListFineTuneEventsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuneEventsResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuneEvent})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuneEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="object"/> or <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuneEventsResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.FineTuneEvent},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuneEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuneEventsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuneEventsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTuneEventsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTuneEventsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuneEventsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuneEventsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListFineTunesResponse">
            <summary> The ListFineTunesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListFineTunesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTunesResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTune})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTunesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="object"/> or <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTunesResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.FineTune},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTunesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTunesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTunesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTunesResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTunesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTunesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTunesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListFineTuningJobEventsResponse">
            <summary> The ListFineTuningJobEventsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListFineTuningJobEventsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuningJobEvent})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuningJobEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="object"/> or <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.FineTuningJobEvent},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuningJobEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListFineTuningJobEventsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListFineTuningJobEventsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListMessageFilesResponse">
            <summary> The ListMessageFilesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListMessageFilesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.MessageFileObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponse.#ctor(OpenAI.Official.Internal.ListMessageFilesResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.MessageFileObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListMessageFilesResponseObject">
            <summary> The ListMessageFilesResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessageFilesResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.op_Equality(OpenAI.Official.Internal.ListMessageFilesResponseObject,OpenAI.Official.Internal.ListMessageFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.op_Inequality(OpenAI.Official.Internal.ListMessageFilesResponseObject,OpenAI.Official.Internal.ListMessageFilesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListMessageFilesResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListMessageFilesResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.Equals(OpenAI.Official.Internal.ListMessageFilesResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessageFilesResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListMessagesResponse">
            <summary> The ListMessagesResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListMessagesResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.MessageObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessagesResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponse.#ctor(OpenAI.Official.Internal.ListMessagesResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.MessageObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessagesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessagesResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListMessagesResponseObject">
            <summary> The ListMessagesResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListMessagesResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListMessagesResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.op_Equality(OpenAI.Official.Internal.ListMessagesResponseObject,OpenAI.Official.Internal.ListMessagesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListMessagesResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.op_Inequality(OpenAI.Official.Internal.ListMessagesResponseObject,OpenAI.Official.Internal.ListMessagesResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListMessagesResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListMessagesResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListMessagesResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.Equals(OpenAI.Official.Internal.ListMessagesResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListMessagesResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListModelsResponse">
            <summary> The ListModelsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListModelsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Model})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListModelsResponse"/>. </summary>
            <param name="data"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponse.#ctor(OpenAI.Official.Internal.ListModelsResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.Model},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListModelsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListModelsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListModelsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListModelsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListModelsResponseObject">
            <summary> The ListModelsResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListModelsResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListModelsResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.op_Equality(OpenAI.Official.Internal.ListModelsResponseObject,OpenAI.Official.Internal.ListModelsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListModelsResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.op_Inequality(OpenAI.Official.Internal.ListModelsResponseObject,OpenAI.Official.Internal.ListModelsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListModelsResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListModelsResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListModelsResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.Equals(OpenAI.Official.Internal.ListModelsResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListModelsResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListOrder"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListOrder.Asc">
            <summary> asc. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListOrder.Desc">
            <summary> desc. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.op_Equality(OpenAI.Official.Internal.ListOrder,OpenAI.Official.Internal.ListOrder)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListOrder"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.op_Inequality(OpenAI.Official.Internal.ListOrder,OpenAI.Official.Internal.ListOrder)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListOrder"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.op_Implicit(System.String)~OpenAI.Official.Internal.ListOrder">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListOrder"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.Equals(OpenAI.Official.Internal.ListOrder)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListOrder.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse">
            <summary> The ListPaginatedFineTuningJobsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.#ctor(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuningJob},System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="object"/> or <paramref name="data"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.#ctor(System.String,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.FineTuningJob},System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListPaginatedFineTuningJobsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListRunsResponse">
            <summary> The ListRunsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListRunsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunsResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponse.#ctor(OpenAI.Official.Internal.ListRunsResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.RunObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListRunsResponseObject">
            <summary> The ListRunsResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunsResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunsResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.op_Equality(OpenAI.Official.Internal.ListRunsResponseObject,OpenAI.Official.Internal.ListRunsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListRunsResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.op_Inequality(OpenAI.Official.Internal.ListRunsResponseObject,OpenAI.Official.Internal.ListRunsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListRunsResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListRunsResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListRunsResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.Equals(OpenAI.Official.Internal.ListRunsResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunsResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ListRunStepsResponse">
            <summary> The ListRunStepsResponse. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ListRunStepsResponse._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponse.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunStepObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunStepsResponse"/>. </summary>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="data"/>, <paramref name="firstId"/> or <paramref name="lastId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponse.#ctor(OpenAI.Official.Internal.ListRunStepsResponseObject,System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.RunStepObject},System.String,System.String,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunStepsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponse.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunStepsResponse"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponse.Object">
            <summary> Gets the object. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponse.Data">
            <summary> Gets the data. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponse.FirstId">
            <summary> Gets the first id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponse.LastId">
            <summary> Gets the last id. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponse.HasMore">
            <summary> Gets the has more. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponse.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponse.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ListRunStepsResponseObject">
            <summary> The ListRunStepsResponse_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ListRunStepsResponseObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ListRunStepsResponseObject.List">
            <summary> list. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.op_Equality(OpenAI.Official.Internal.ListRunStepsResponseObject,OpenAI.Official.Internal.ListRunStepsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListRunStepsResponseObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.op_Inequality(OpenAI.Official.Internal.ListRunStepsResponseObject,OpenAI.Official.Internal.ListRunStepsResponseObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ListRunStepsResponseObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.op_Implicit(System.String)~OpenAI.Official.Internal.ListRunStepsResponseObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ListRunStepsResponseObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.Equals(OpenAI.Official.Internal.ListRunStepsResponseObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ListRunStepsResponseObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.MessageFileObject">
            <summary> A list of files attached to a `message`. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.MessageFileObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObject.#ctor(System.String,System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageFileObject"/>. </summary>
            <param name="id"> TThe identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message file was created. </param>
            <param name="messageId"> The ID of the [message](/docs/api-reference/messages) that the [File](/docs/api-reference/files) is attached to. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="messageId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObject.#ctor(System.String,OpenAI.Official.Internal.MessageFileObjectObject,System.DateTimeOffset,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageFileObject"/>. </summary>
            <param name="id"> TThe identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.message.file`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message file was created. </param>
            <param name="messageId"> The ID of the [message](/docs/api-reference/messages) that the [File](/docs/api-reference/files) is attached to. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageFileObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageFileObject.Id">
            <summary> TThe identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageFileObject.Object">
            <summary> The object type, which is always `thread.message.file`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageFileObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the message file was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageFileObject.MessageId">
            <summary> The ID of the [message](/docs/api-reference/messages) that the [File](/docs/api-reference/files) is attached to. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.MessageFileObjectObject">
            <summary> The MessageFileObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageFileObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageFileObjectObject.ThreadMessageFile">
            <summary> thread.message.file. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.op_Equality(OpenAI.Official.Internal.MessageFileObjectObject,OpenAI.Official.Internal.MessageFileObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageFileObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.op_Inequality(OpenAI.Official.Internal.MessageFileObjectObject,OpenAI.Official.Internal.MessageFileObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageFileObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.MessageFileObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.MessageFileObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.Equals(OpenAI.Official.Internal.MessageFileObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageFileObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.MessageObject">
            <summary> The MessageObject. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.MessageObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObject.#ctor(System.String,System.DateTimeOffset,System.String,OpenAI.Official.Internal.MessageObjectRole,System.Collections.Generic.IEnumerable{System.BinaryData},System.String,System.String,System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message was created. </param>
            <param name="threadId"> The [thread](/docs/api-reference/threads) ID that this message belongs to. </param>
            <param name="role"> The entity that produced the message. One of `user` or `assistant`. </param>
            <param name="content"> The content of the message in array of text and/or images. </param>
            <param name="assistantId">
            If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this
            message.
            </param>
            <param name="runId">
            If applicable, the ID of the [run](/docs/api-reference/runs) associated with the authoring of
            this message.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for
            tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be
            attached to a message.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="threadId"/>, <paramref name="content"/> or <paramref name="fileIds"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObject.#ctor(System.String,OpenAI.Official.Internal.MessageObjectObject,System.DateTimeOffset,System.String,OpenAI.Official.Internal.MessageObjectRole,System.Collections.Generic.IReadOnlyList{System.BinaryData},System.String,System.String,System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.message`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message was created. </param>
            <param name="threadId"> The [thread](/docs/api-reference/threads) ID that this message belongs to. </param>
            <param name="role"> The entity that produced the message. One of `user` or `assistant`. </param>
            <param name="content"> The content of the message in array of text and/or images. </param>
            <param name="assistantId">
            If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this
            message.
            </param>
            <param name="runId">
            If applicable, the ID of the [run](/docs/api-reference/runs) associated with the authoring of
            this message.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for
            tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be
            attached to a message.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.Id">
            <summary> The identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.Object">
            <summary> The object type, which is always `thread.message`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the message was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.ThreadId">
            <summary> The [thread](/docs/api-reference/threads) ID that this message belongs to. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.Role">
            <summary> The entity that produced the message. One of `user` or `assistant`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.Content">
            <summary>
            The content of the message in array of text and/or images.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.AssistantId">
            <summary>
            If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this
            message.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.RunId">
            <summary>
            If applicable, the ID of the [run](/docs/api-reference/runs) associated with the authoring of
            this message.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.FileIds">
            <summary>
            A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for
            tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be
            attached to a message.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObject.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.MessageObjectObject">
            <summary> The MessageObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObjectObject.ThreadMessage">
            <summary> thread.message. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.op_Equality(OpenAI.Official.Internal.MessageObjectObject,OpenAI.Official.Internal.MessageObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.op_Inequality(OpenAI.Official.Internal.MessageObjectObject,OpenAI.Official.Internal.MessageObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.MessageObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.MessageObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.Equals(OpenAI.Official.Internal.MessageObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.MessageObjectRole">
            <summary> Enum for role in MessageObject. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.MessageObjectRole"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObjectRole.User">
            <summary> user. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.MessageObjectRole.Assistant">
            <summary> assistant. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.op_Equality(OpenAI.Official.Internal.MessageObjectRole,OpenAI.Official.Internal.MessageObjectRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageObjectRole"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.op_Inequality(OpenAI.Official.Internal.MessageObjectRole,OpenAI.Official.Internal.MessageObjectRole)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.MessageObjectRole"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.op_Implicit(System.String)~OpenAI.Official.Internal.MessageObjectRole">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.MessageObjectRole"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.Equals(OpenAI.Official.Internal.MessageObjectRole)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.MessageObjectRole.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Messages">
            <summary> The Messages sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Messages.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Messages.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.#ctor">
            <summary> Initializes a new instance of Messages for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Messages. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.CreateMessageAsync(System.String,OpenAI.Official.Internal.CreateMessageRequest,System.Threading.CancellationToken)">
            <summary> Create a message. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to create a message for. </param>
            <param name="message"> The <see cref="T:OpenAI.Official.Internal.CreateMessageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="message"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.CreateMessage(System.String,OpenAI.Official.Internal.CreateMessageRequest,System.Threading.CancellationToken)">
            <summary> Create a message. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to create a message for. </param>
            <param name="message"> The <see cref="T:OpenAI.Official.Internal.CreateMessageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="message"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.CreateMessageAsync(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.CreateMessageAsync(System.String,OpenAI.Official.Internal.CreateMessageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to create a message for. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.CreateMessage(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.CreateMessage(System.String,OpenAI.Official.Internal.CreateMessageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to create a message for. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessagesAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of messages for a given thread. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) the messages belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessages(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of messages for a given thread. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) the messages belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessagesAsync(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of messages for a given thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessagesAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) the messages belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessages(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of messages for a given thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessages(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) the messages belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieve a message. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this message belongs. </param>
            <param name="messageId"> The ID of the message to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessage(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieve a message. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this message belongs. </param>
            <param name="messageId"> The ID of the message to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageAsync(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieve a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessageAsync(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this message belongs. </param>
            <param name="messageId"> The ID of the message to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessage(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieve a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessage(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this message belongs. </param>
            <param name="messageId"> The ID of the message to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.ModifyMessageAsync(System.String,System.String,OpenAI.Official.Internal.ModifyMessageRequest,System.Threading.CancellationToken)">
            <summary> Modifies a message. </summary>
            <param name="threadId"> The ID of the thread to which this message belongs. </param>
            <param name="messageId"> The ID of the message to modify. </param>
            <param name="message"> The <see cref="T:OpenAI.Official.Internal.ModifyMessageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="message"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.ModifyMessage(System.String,System.String,OpenAI.Official.Internal.ModifyMessageRequest,System.Threading.CancellationToken)">
            <summary> Modifies a message. </summary>
            <param name="threadId"> The ID of the thread to which this message belongs. </param>
            <param name="messageId"> The ID of the message to modify. </param>
            <param name="message"> The <see cref="T:OpenAI.Official.Internal.ModifyMessageRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="message"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.ModifyMessageAsync(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.ModifyMessageAsync(System.String,System.String,OpenAI.Official.Internal.ModifyMessageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which this message belongs. </param>
            <param name="messageId"> The ID of the message to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.ModifyMessage(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a message.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.ModifyMessage(System.String,System.String,OpenAI.Official.Internal.ModifyMessageRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which this message belongs. </param>
            <param name="messageId"> The ID of the message to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFilesAsync(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of message files. </summary>
            <param name="threadId"> The ID of the thread that the message and files belong to. </param>
            <param name="messageId"> The ID of the message that the files belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFiles(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of message files. </summary>
            <param name="threadId"> The ID of the thread that the message and files belong to. </param>
            <param name="messageId"> The ID of the message that the files belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFilesAsync(System.String,System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of message files.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessageFilesAsync(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread that the message and files belong to. </param>
            <param name="messageId"> The ID of the message that the files belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFiles(System.String,System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of message files.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessageFiles(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread that the message and files belong to. </param>
            <param name="messageId"> The ID of the message that the files belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="messageId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="messageId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFileAsync(System.String,System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a message file. </summary>
            <param name="threadId"> The ID of the thread to which the message and File belong. </param>
            <param name="messageId"> The ID of the message the file belongs to. </param>
            <param name="fileId"> The ID of the file being retrieved. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFile(System.String,System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a message file. </summary>
            <param name="threadId"> The ID of the thread to which the message and File belong. </param>
            <param name="messageId"> The ID of the message the file belongs to. </param>
            <param name="fileId"> The ID of the file being retrieved. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFileAsync(System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a message file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessageFileAsync(System.String,System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which the message and File belong. </param>
            <param name="messageId"> The ID of the message the file belongs to. </param>
            <param name="fileId"> The ID of the file being retrieved. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Messages.GetMessageFile(System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a message file.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Messages.GetMessageFile(System.String,System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which the message and File belong. </param>
            <param name="messageId"> The ID of the message the file belongs to. </param>
            <param name="fileId"> The ID of the file being retrieved. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="messageId"/> or <paramref name="fileId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.Model">
            <summary> Describes an OpenAI model offering that can be used with the API. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.Model._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Model.#ctor(System.String,System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Model"/>. </summary>
            <param name="id"> The model identifier, which can be referenced in the API endpoints. </param>
            <param name="created"> The Unix timestamp (in seconds) when the model was created. </param>
            <param name="ownedBy"> The organization that owns the model. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="ownedBy"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Model.#ctor(System.String,System.DateTimeOffset,OpenAI.Official.Internal.ModelObject,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Model"/>. </summary>
            <param name="id"> The model identifier, which can be referenced in the API endpoints. </param>
            <param name="created"> The Unix timestamp (in seconds) when the model was created. </param>
            <param name="object"> The object type, which is always "model". </param>
            <param name="ownedBy"> The organization that owns the model. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Model.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.Model"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Model.Id">
            <summary> The model identifier, which can be referenced in the API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Model.Created">
            <summary> The Unix timestamp (in seconds) when the model was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Model.Object">
            <summary> The object type, which is always "model". </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Model.OwnedBy">
            <summary> The organization that owns the model. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Model.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Model.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ModelObject">
            <summary> The Model_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModelObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ModelObject.Model">
            <summary> model. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.op_Equality(OpenAI.Official.Internal.ModelObject,OpenAI.Official.Internal.ModelObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ModelObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.op_Inequality(OpenAI.Official.Internal.ModelObject,OpenAI.Official.Internal.ModelObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ModelObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.op_Implicit(System.String)~OpenAI.Official.Internal.ModelObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ModelObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.Equals(OpenAI.Official.Internal.ModelObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ModelObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.ModelsOps">
            <summary> The ModelsOps sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModelsOps.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModelsOps.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.#ctor">
            <summary> Initializes a new instance of ModelsOps for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of ModelsOps. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.GetModelsAsync(System.Threading.CancellationToken)">
            <summary>
            Lists the currently available models, and provides basic information about each one such as the
            owner and availability.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.GetModels(System.Threading.CancellationToken)">
            <summary>
            Lists the currently available models, and provides basic information about each one such as the
            owner and availability.
            </summary>
            <param name="cancellationToken"> The cancellation token to use. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.GetModelsAsync(System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Lists the currently available models, and provides basic information about each one such as the
            owner and availability.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.GetModelsAsync(System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.GetModels(System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Lists the currently available models, and provides basic information about each one such as the
            owner and availability.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.GetModels(System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.RetrieveAsync(System.String,System.Threading.CancellationToken)">
            <summary>
            Retrieves a model instance, providing basic information about the model such as the owner and
            permissioning.
            </summary>
            <param name="model"> The ID of the model to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.Retrieve(System.String,System.Threading.CancellationToken)">
            <summary>
            Retrieves a model instance, providing basic information about the model such as the owner and
            permissioning.
            </summary>
            <param name="model"> The ID of the model to use for this request. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.RetrieveAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a model instance, providing basic information about the model such as the owner and
            permissioning.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.RetrieveAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="model"> The ID of the model to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.Retrieve(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a model instance, providing basic information about the model such as the owner and
            permissioning.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.Retrieve(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="model"> The ID of the model to use for this request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.DeleteAsync(System.String,System.Threading.CancellationToken)">
            <summary> Delete a fine-tuned model. You must have the Owner role in your organization to delete a model. </summary>
            <param name="model"> The model to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.Delete(System.String,System.Threading.CancellationToken)">
            <summary> Delete a fine-tuned model. You must have the Owner role in your organization to delete a model. </summary>
            <param name="model"> The model to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.DeleteAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.DeleteAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="model"> The model to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.ModelsOps.Delete(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.ModelsOps.Delete(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="model"> The model to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="model"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="model"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.Moderations">
            <summary> The Moderations sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Moderations.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Moderations.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.#ctor">
            <summary> Initializes a new instance of Moderations for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Moderations. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.CreateModerationAsync(OpenAI.Official.Internal.CreateModerationRequest,System.Threading.CancellationToken)">
            <summary> Classifies if text violates OpenAI's Content Policy. </summary>
            <param name="content"> The <see cref="T:OpenAI.Official.Internal.CreateModerationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.CreateModeration(OpenAI.Official.Internal.CreateModerationRequest,System.Threading.CancellationToken)">
            <summary> Classifies if text violates OpenAI's Content Policy. </summary>
            <param name="content"> The <see cref="T:OpenAI.Official.Internal.CreateModerationRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.CreateModerationAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Classifies if text violates OpenAI's Content Policy
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Moderations.CreateModerationAsync(OpenAI.Official.Internal.CreateModerationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Moderations.CreateModeration(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Classifies if text violates OpenAI's Content Policy
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Moderations.CreateModeration(OpenAI.Official.Internal.CreateModerationRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.ModifyAssistantRequest">
            <summary> The ModifyAssistantRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ModifyAssistantRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyAssistantRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyAssistantRequest"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyAssistantRequest.#ctor(System.String,System.String,System.String,System.String,System.Collections.Generic.IList{System.BinaryData},System.Collections.Generic.IList{System.String},System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyAssistantRequest"/>. </summary>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Model">
            <summary>
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Name">
            <summary> The name of the assistant. The maximum length is 256 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Description">
            <summary> The description of the assistant. The maximum length is 512 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Instructions">
            <summary> The system instructions that the assistant uses. The maximum length is 32768 characters. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Tools">
            <summary>
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.FileIds">
            <summary>
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyAssistantRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyAssistantRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyAssistantRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ModifyMessageRequest">
            <summary> The ModifyMessageRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ModifyMessageRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyMessageRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyMessageRequest"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyMessageRequest.#ctor(System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyMessageRequest"/>. </summary>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyMessageRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyMessageRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyMessageRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ModifyRunRequest">
            <summary> The ModifyRunRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ModifyRunRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyRunRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyRunRequest"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyRunRequest.#ctor(System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyRunRequest"/>. </summary>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyRunRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyRunRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyRunRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ModifyThreadRequest">
            <summary> The ModifyThreadRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ModifyThreadRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyThreadRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyThreadRequest"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyThreadRequest.#ctor(System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ModifyThreadRequest"/>. </summary>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.ModifyThreadRequest.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyThreadRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ModifyThreadRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIClient">
            <summary> The OpenAI service client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIClient.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIClient.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.#ctor">
            <summary> Initializes a new instance of OpenAIClient for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.#ctor(System.ClientModel.KeyCredential)">
            <summary> Initializes a new instance of OpenAIClient. </summary>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="credential"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.#ctor(System.Uri,System.ClientModel.KeyCredential,OpenAI.Official.Internal.OpenAIClientOptions)">
            <summary> Initializes a new instance of OpenAIClient. </summary>
            <param name="endpoint"> OpenAI Endpoint. </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetFineTuningClient">
            <summary> Initializes a new instance of FineTuning. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetAudioClient">
            <summary> Initializes a new instance of Audio. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetAssistantsClient">
            <summary> Initializes a new instance of Assistants. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetChatClient">
            <summary> Initializes a new instance of Chat. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetCompletionsClient">
            <summary> Initializes a new instance of Completions. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetEmbeddingsClient">
            <summary> Initializes a new instance of Embeddings. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetFilesClient">
            <summary> Initializes a new instance of Files. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetFineTunesClient">
            <summary> Initializes a new instance of FineTunes. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetImagesClient">
            <summary> Initializes a new instance of Images. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetMessagesClient">
            <summary> Initializes a new instance of Messages. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetModelsOpsClient">
            <summary> Initializes a new instance of ModelsOps. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetModerationsClient">
            <summary> Initializes a new instance of Moderations. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetRunsClient">
            <summary> Initializes a new instance of Runs. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIClient.GetThreadsClient">
            <summary> Initializes a new instance of Threads. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIClientOptions">
            <summary> Client options for OpenAIClient. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIFile">
            <summary> The `File` object represents a document that has been uploaded to OpenAI. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.OpenAIFile._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFile.#ctor(System.String,System.Int64,System.DateTimeOffset,System.String,OpenAI.Official.Internal.OpenAIFilePurpose,OpenAI.Official.Internal.OpenAIFileStatus)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFile"/>. </summary>
            <param name="id"> The file identifier, which can be referenced in the API endpoints. </param>
            <param name="bytes"> The size of the file, in bytes. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the file was created. </param>
            <param name="filename"> The name of the file. </param>
            <param name="purpose">
            The intended purpose of the file. Supported values are `fine-tune`, `fine-tune-results`,
            `assistants`, and `assistants_output`.
            </param>
            <param name="status">
            Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or
            `error`.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="filename"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFile.#ctor(System.String,System.Int64,System.DateTimeOffset,System.String,OpenAI.Official.Internal.OpenAIFileObject,OpenAI.Official.Internal.OpenAIFilePurpose,OpenAI.Official.Internal.OpenAIFileStatus,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFile"/>. </summary>
            <param name="id"> The file identifier, which can be referenced in the API endpoints. </param>
            <param name="bytes"> The size of the file, in bytes. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the file was created. </param>
            <param name="filename"> The name of the file. </param>
            <param name="object"> The object type, which is always "file". </param>
            <param name="purpose">
            The intended purpose of the file. Supported values are `fine-tune`, `fine-tune-results`,
            `assistants`, and `assistants_output`.
            </param>
            <param name="status">
            Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or
            `error`.
            </param>
            <param name="statusDetails">
            Deprecated. For details on why a fine-tuning training file failed validation, see the `error`
            field on `fine_tuning.job`.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFile.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFile"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Id">
            <summary> The file identifier, which can be referenced in the API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Bytes">
            <summary> The size of the file, in bytes. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the file was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Filename">
            <summary> The name of the file. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Object">
            <summary> The object type, which is always "file". </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Purpose">
            <summary>
            The intended purpose of the file. Supported values are `fine-tune`, `fine-tune-results`,
            `assistants`, and `assistants_output`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.Status">
            <summary>
            Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or
            `error`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFile.StatusDetails">
            <summary>
            Deprecated. For details on why a fine-tuning training file failed validation, see the `error`
            field on `fine_tuning.job`.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFile.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFile.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIFileObject">
            <summary> The OpenAIFile_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFileObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFileObject.File">
            <summary> file. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.op_Equality(OpenAI.Official.Internal.OpenAIFileObject,OpenAI.Official.Internal.OpenAIFileObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFileObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.op_Inequality(OpenAI.Official.Internal.OpenAIFileObject,OpenAI.Official.Internal.OpenAIFileObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFileObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.op_Implicit(System.String)~OpenAI.Official.Internal.OpenAIFileObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.OpenAIFileObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.Equals(OpenAI.Official.Internal.OpenAIFileObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIFilePurpose">
            <summary> Enum for purpose in OpenAIFile. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFilePurpose"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFilePurpose.FineTune">
            <summary> fine-tune. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFilePurpose.FineTuneResults">
            <summary> fine-tune-results. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFilePurpose.Assistants">
            <summary> assistants. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFilePurpose.AssistantsOutput">
            <summary> assistants_output. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.op_Equality(OpenAI.Official.Internal.OpenAIFilePurpose,OpenAI.Official.Internal.OpenAIFilePurpose)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFilePurpose"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.op_Inequality(OpenAI.Official.Internal.OpenAIFilePurpose,OpenAI.Official.Internal.OpenAIFilePurpose)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFilePurpose"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.op_Implicit(System.String)~OpenAI.Official.Internal.OpenAIFilePurpose">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.OpenAIFilePurpose"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.Equals(OpenAI.Official.Internal.OpenAIFilePurpose)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFilePurpose.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIFileStatus">
            <summary> Enum for status in OpenAIFile. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.OpenAIFileStatus"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFileStatus.Uploaded">
            <summary> uploaded. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFileStatus.Processed">
            <summary> processed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.OpenAIFileStatus.Error">
            <summary> error. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.op_Equality(OpenAI.Official.Internal.OpenAIFileStatus,OpenAI.Official.Internal.OpenAIFileStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFileStatus"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.op_Inequality(OpenAI.Official.Internal.OpenAIFileStatus,OpenAI.Official.Internal.OpenAIFileStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.OpenAIFileStatus"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.op_Implicit(System.String)~OpenAI.Official.Internal.OpenAIFileStatus">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.OpenAIFileStatus"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.Equals(OpenAI.Official.Internal.OpenAIFileStatus)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIFileStatus.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.OpenAIOfficialModelFactory">
            <summary> Model factory for models. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateFineTuningJobRequest(System.String,System.String,OpenAI.Official.Internal.CreateFineTuningJobRequestModel,OpenAI.Official.Internal.CreateFineTuningJobRequestHyperparameters,System.String)">
             <summary> Initializes a new instance of <see cref="!:Official.CreateFineTuningJobRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with
             the purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </param>
             <param name="validationFile">
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should
             not be present in both train and validation files.
            
             Your dataset must be formatted as a JSONL file. You must upload your file with the purpose
             `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
             </param>
             <param name="model">
             The name of the model to fine-tune. You can select one of the
             [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
             </param>
             <param name="hyperparameters"> The hyperparameters used for the fine-tuning job. </param>
             <param name="suffix">
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
             </param>
             <returns> A new <see cref="!:Official.CreateFineTuningJobRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuningJob(System.String,OpenAI.Official.Internal.FineTuningJobObject,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.String,System.String,System.String,OpenAI.Official.Internal.FineTuningJobStatus,OpenAI.Official.Internal.FineTuningJobHyperparameters,System.String,System.String,System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Int64},OpenAI.Official.Internal.FineTuningJobError)">
            <summary> Initializes a new instance of <see cref="!:Official.FineTuningJob"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="object"> The object type, which is always "fine_tuning.job". </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="finishedAt">
            The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be
            null if the fine-tuning job is still running.
            </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel">
            The name of the fine-tuned model that is being created. The value will be null if the
            fine-tuning job is still running.
            </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparameters">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
            </param>
            <param name="trainingFile">
            The file ID used for training. You can retrieve the training data with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="validationFile">
            The file ID used for validation. You can retrieve the validation results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="resultFiles">
            The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
            </param>
            <param name="trainedTokens">
            The total number of billable tokens processed by this fine tuning job. The value will be null
            if the fine-tuning job is still running.
            </param>
            <param name="error">
            For fine-tuning jobs that have `failed`, this will contain more information on the cause of the
            failure.
            </param>
            <returns> A new <see cref="!:Official.FineTuningJob"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuningJobHyperparameters(System.BinaryData)">
             <summary> Initializes a new instance of <see cref="!:Official.FineTuningJobHyperparameters"/>. </summary>
             <param name="nEpochs">
             The number of epochs to train the model for. An epoch refers to one full cycle through the
             training dataset.
            
             "Auto" decides the optimal number of epochs based on the size of the dataset. If setting the
             number manually, we support any number between 1 and 50 epochs.
             </param>
             <returns> A new <see cref="!:Official.FineTuningJobHyperparameters"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuningJobError(System.String,System.String,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.FineTuningJobError"/>. </summary>
            <param name="message"> A human-readable error message. </param>
            <param name="code"> A machine-readable error code. </param>
            <param name="param">
            The parameter that was invalid, usually `training_file` or `validation_file`. This field
            will be null if the failure was not parameter-specific.
            </param>
            <returns> A new <see cref="!:Official.FineTuningJobError"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListPaginatedFineTuningJobsResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuningJob},System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListPaginatedFineTuningJobsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListPaginatedFineTuningJobsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListFineTuningJobEventsResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuningJobEvent})">
            <summary> Initializes a new instance of <see cref="!:Official.ListFineTuningJobEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <returns> A new <see cref="!:Official.ListFineTuningJobEventsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuningJobEvent(System.String,System.String,System.DateTimeOffset,OpenAI.Official.Internal.FineTuningJobEventLevel,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.FineTuningJobEvent"/>. </summary>
            <param name="id"></param>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <returns> A new <see cref="!:Official.FineTuningJobEvent"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateSpeechRequest(OpenAI.Official.Internal.CreateSpeechRequestModel,System.String,OpenAI.Official.Internal.CreateSpeechRequestVoice,System.Nullable{OpenAI.Official.Internal.CreateSpeechRequestResponseFormat},System.Nullable{System.Double})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateSpeechRequest"/>. </summary>
            <param name="model"> One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`. </param>
            <param name="input"> The text to generate audio for. The maximum length is 4096 characters. </param>
            <param name="voice">
            The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`,
            `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the
            [Text to speech guide](/docs/guides/text-to-speech/voice-options).
            </param>
            <param name="responseFormat"> The format to audio in. Supported formats are `mp3`, `opus`, `aac`, and `flac`. </param>
            <param name="speed"> The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default. </param>
            <returns> A new <see cref="!:Official.CreateSpeechRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateTranscriptionRequest(System.BinaryData,OpenAI.Official.Internal.CreateTranscriptionRequestModel,System.String,System.String,System.Nullable{OpenAI.Official.Internal.CreateTranscriptionRequestResponseFormat},System.Nullable{System.Double})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateTranscriptionRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <param name="language">
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy
            and latency.
            </param>
            <param name="prompt">
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </param>
            <param name="responseFormat">
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </param>
            <param name="temperature">
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </param>
            <returns> A new <see cref="!:Official.CreateTranscriptionRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateTranscriptionResponse(System.String,System.Nullable{OpenAI.Official.Internal.CreateTranscriptionResponseTask},System.String,System.Nullable{System.TimeSpan},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AudioSegment})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateTranscriptionResponse"/>. </summary>
            <param name="text"> The transcribed text for the provided audio data. </param>
            <param name="task"> The label that describes which operation type generated the accompanying response data. </param>
            <param name="language"> The spoken language that was detected in the audio data. </param>
            <param name="duration"> The total duration of the audio processed to produce accompanying transcription information. </param>
            <param name="segments">
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </param>
            <returns> A new <see cref="!:Official.CreateTranscriptionResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.AudioSegment(System.Int64,System.Int64,System.TimeSpan,System.TimeSpan,System.String,System.Collections.Generic.IEnumerable{System.Int64},System.Double,System.Double,System.Double,System.Double)">
            <summary> Initializes a new instance of <see cref="!:Official.AudioSegment"/>. </summary>
            <param name="id"> The zero-based index of this segment. </param>
            <param name="seek">
            The seek position associated with the processing of this audio segment. Seek positions are
            expressed as hundredths of seconds. The model may process several segments from a single seek
            position, so while the seek position will never represent a later time than the segment's
            start, the segment's start may represent a significantly later time than the segment's
            associated seek position.
            </param>
            <param name="start"> The time at which this segment started relative to the beginning of the audio. </param>
            <param name="end"> The time at which this segment ended relative to the beginning of the audio. </param>
            <param name="text"> The text that was part of this audio segment. </param>
            <param name="tokens"> The token IDs matching the text in this audio segment. </param>
            <param name="temperature"> The temperature score associated with this audio segment. </param>
            <param name="avgLogprob"> The average log probability associated with this audio segment. </param>
            <param name="compressionRatio"> The compression ratio of this audio segment. </param>
            <param name="noSpeechProb"> The probability of no speech detection within this audio segment. </param>
            <returns> A new <see cref="!:Official.AudioSegment"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateTranslationRequest(System.BinaryData,OpenAI.Official.Internal.CreateTranslationRequestModel,System.String,System.Nullable{OpenAI.Official.Internal.CreateTranslationRequestResponseFormat},System.Nullable{System.Double})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateTranslationRequest"/>. </summary>
            <param name="file">
            The audio file object (not file name) to translate, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
            </param>
            <param name="model"> ID of the model to use. Only `whisper-1` is currently available. </param>
            <param name="prompt">
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
            </param>
            <param name="responseFormat">
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
            </param>
            <param name="temperature">
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
            </param>
            <returns> A new <see cref="!:Official.CreateTranslationRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateTranslationResponse(System.String,System.Nullable{OpenAI.Official.Internal.CreateTranslationResponseTask},System.String,System.Nullable{System.TimeSpan},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AudioSegment})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateTranslationResponse"/>. </summary>
            <param name="text"> The translated text for the provided audio data. </param>
            <param name="task"> The label that describes which operation type generated the accompanying response data. </param>
            <param name="language"> The spoken language that was detected in the audio data. </param>
            <param name="duration"> The total duration of the audio processed to produce accompanying translation information. </param>
            <param name="segments">
            A collection of information about the timing, probabilities, and other detail of each processed
            audio segment.
            </param>
            <returns> A new <see cref="!:Official.CreateTranslationResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateAssistantRequest(System.String,System.String,System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateAssistantRequest"/>. </summary>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.CreateAssistantRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.AssistantObject(System.String,OpenAI.Official.Internal.AssistantObjectObject,System.DateTimeOffset,System.String,System.String,System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.AssistantObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `assistant`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant was created. </param>
            <param name="name"> The name of the assistant. The maximum length is 256 characters. </param>
            <param name="description"> The description of the assistant. The maximum length is 512 characters. </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="instructions"> The system instructions that the assistant uses. The maximum length is 32768 characters. </param>
            <param name="tools">
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant.
            Tools can be of types `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a
            maximum of 20 files attached to the assistant. Files are ordered by their creation date in
            ascending order.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.AssistantObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListAssistantsResponse(OpenAI.Official.Internal.ListAssistantsResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AssistantObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListAssistantsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListAssistantsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.DeleteAssistantResponse(System.String,System.Boolean,OpenAI.Official.Internal.DeleteAssistantResponseObject)">
            <summary> Initializes a new instance of <see cref="!:Official.DeleteAssistantResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <returns> A new <see cref="!:Official.DeleteAssistantResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.AssistantFileObject(System.String,OpenAI.Official.Internal.AssistantFileObjectObject,System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.AssistantFileObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `assistant.file`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the assistant file was created. </param>
            <param name="assistantId"> The assistant ID that the file is attached to. </param>
            <returns> A new <see cref="!:Official.AssistantFileObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListAssistantFilesResponse(OpenAI.Official.Internal.ListAssistantFilesResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.AssistantFileObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListAssistantFilesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListAssistantFilesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.DeleteAssistantFileResponse(System.String,System.Boolean,OpenAI.Official.Internal.DeleteAssistantFileResponseObject)">
            <summary> Initializes a new instance of <see cref="!:Official.DeleteAssistantFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <returns> A new <see cref="!:Official.DeleteAssistantFileResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateChatCompletionRequest(System.Collections.Generic.IEnumerable{System.BinaryData},OpenAI.Official.Internal.CreateChatCompletionRequestModel,System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.Int64},System.Nullable{System.Boolean},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},OpenAI.Official.Internal.CreateChatCompletionRequestResponseFormat,System.Nullable{System.Int64},System.BinaryData,System.Nullable{System.Boolean},System.Nullable{System.Double},System.Nullable{System.Double},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionTool},System.BinaryData,System.String,System.BinaryData,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionFunctions})">
             <summary> Initializes a new instance of <see cref="!:Official.CreateChatCompletionRequest"/>. </summary>
             <param name="messages">
             A list of messages comprising the conversation so far.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
             </param>
             <param name="model">
             ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
             table for details on which models work with the Chat API.
             </param>
             <param name="frequencyPenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="logitBias">
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an
             associated bias value from -100 to 100. Mathematically, the bias is added to the logits
             generated by the model prior to sampling. The exact effect will vary per model, but values
             between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100
             should result in a ban or exclusive selection of the relevant token.
             </param>
             <param name="logprobs">
             Whether to return log probabilities of the output tokens or not. If true, returns the log
             probabilities of each output token returned in the `content` of `message`. This option is
             currently not available on the `gpt-4-vision-preview` model.
             </param>
             <param name="topLogprobs">
             An integer between 0 and 5 specifying the number of most likely tokens to return at each token
             position, each with an associated log probability. `logprobs` must be set to `true` if this
             parameter is used.
             </param>
             <param name="maxTokens">
             The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.
            
             The total length of input tokens and generated tokens is limited by the model's context length.
             [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
             for counting tokens.
             </param>
             <param name="n">
             How many chat completion choices to generate for each input message. Note that you will be
             charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to
             minimize costs.
             </param>
             <param name="presencePenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="responseFormat">
             An object specifying the format that the model must output. Compatible with
             [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and `gpt-3.5-turbo-1106`.
            
             Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the
             model generates is valid JSON.
            
             **Important:** when using JSON mode, you **must** also instruct the model to produce JSON
             yourself via a system or user message. Without this, the model may generate an unending stream
             of whitespace until the generation reaches the token limit, resulting in a long-running and
             seemingly "stuck" request. Also note that the message content may be partially cut off if
             `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the
             conversation exceeded the max context length.
             </param>
             <param name="seed">
             This feature is in Beta.
            
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </param>
             <param name="stop"> Up to 4 sequences where the API will stop generating further tokens. </param>
             <param name="stream">
             If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available, with the stream terminated by a `data: [DONE]` message.
             [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
             </param>
             <param name="temperature">
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </param>
             <param name="topP">
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </param>
             <param name="tools">
             A list of tools the model may call. Currently, only functions are supported as a tool. Use this
             to provide a list of functions the model may generate JSON inputs for.
             </param>
             <param name="toolChoice"></param>
             <param name="user">
             A unique identifier representing your end-user, which can help OpenAI to monitor and detect
             abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
             </param>
             <param name="functionCall">
             Deprecated in favor of `tool_choice`.
            
             Controls which (if any) function is called by the model. `none` means the model will not call a
             function and instead generates a message. `auto` means the model can pick between generating a
             message or calling a function. Specifying a particular function via `{"name": "my_function"}`
             forces the model to call that function.
            
             `none` is the default when no functions are present. `auto` is the default if functions are
             present.
             </param>
             <param name="functions">
             Deprecated in favor of `tools`.
            
             A list of functions the model may generate JSON inputs for.
             </param>
             <returns> A new <see cref="!:Official.CreateChatCompletionRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionMessageToolCall(System.String,OpenAI.Official.Internal.ChatCompletionMessageToolCallType,OpenAI.Official.Internal.ChatCompletionMessageToolCallFunction)">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionMessageToolCall"/>. </summary>
            <param name="id"> The ID of the tool call. </param>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"> The function that the model called. </param>
            <returns> A new <see cref="!:Official.ChatCompletionMessageToolCall"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionTool(OpenAI.Official.Internal.ChatCompletionToolType,OpenAI.Official.Internal.FunctionObject)">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionTool"/>. </summary>
            <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
            <param name="function"></param>
            <returns> A new <see cref="!:Official.ChatCompletionTool"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionFunctions(System.String,System.String,OpenAI.Official.Internal.FunctionParameters)">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionFunctions"/>. </summary>
            <param name="description">
            A description of what the function does, used by the model to choose when and how to call the
            function.
            </param>
            <param name="name">
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
            </param>
            <param name="parameters"></param>
            <returns> A new <see cref="!:Official.ChatCompletionFunctions"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateChatCompletionResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateChatCompletionResponseChoice},System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.CreateChatCompletionResponseObject,OpenAI.Official.Internal.CompletionUsage)">
             <summary> Initializes a new instance of <see cref="!:Official.CreateChatCompletionResponse"/>. </summary>
             <param name="id"> A unique identifier for the chat completion. </param>
             <param name="choices"> A list of chat completion choices. Can be more than one if `n` is greater than 1. </param>
             <param name="created"> The Unix timestamp (in seconds) of when the chat completion was created. </param>
             <param name="model"> The model used for the chat completion. </param>
             <param name="systemFingerprint">
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </param>
             <param name="object"> The object type, which is always `chat.completion`. </param>
             <param name="usage"></param>
             <returns> A new <see cref="!:Official.CreateChatCompletionResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateChatCompletionResponseChoice(OpenAI.Official.Internal.CreateChatCompletionResponseChoiceFinishReason,System.Int64,OpenAI.Official.Internal.ChatCompletionResponseMessage,OpenAI.Official.Internal.CreateChatCompletionResponseChoiceLogprobs)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateChatCompletionResponseChoice"/>. </summary>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, `length` if the maximum number of tokens
            specified in the request was reached, `content_filter` if content was omitted due to a flag
            from our content filters, `tool_calls` if the model called a tool, or `function_call`
            (deprecated) if the model called a function.
            </param>
            <param name="index"> The index of the choice in the list of choices. </param>
            <param name="message"></param>
            <param name="logprobs"> Log probability information for the choice. </param>
            <returns> A new <see cref="!:Official.CreateChatCompletionResponseChoice"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionResponseMessage(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionMessageToolCall},OpenAI.Official.Internal.ChatCompletionResponseMessageRole,OpenAI.Official.Internal.ChatCompletionResponseMessageFunctionCall)">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionResponseMessage"/>. </summary>
            <param name="content"> The contents of the message. </param>
            <param name="toolCalls"></param>
            <param name="role"> The role of the author of this message. </param>
            <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
            <returns> A new <see cref="!:Official.ChatCompletionResponseMessage"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionResponseMessageFunctionCall(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionResponseMessageFunctionCall"/>. </summary>
            <param name="arguments">
            The arguments to call the function with, as generated by the model in JSON format. Note that
            the model does not always generate valid JSON, and may hallucinate parameters not defined by
            your function schema. Validate the arguments in your code before calling your function.
            </param>
            <param name="name"> The name of the function to call. </param>
            <returns> A new <see cref="!:Official.ChatCompletionResponseMessageFunctionCall"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateChatCompletionResponseChoiceLogprobs(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionTokenLogprob})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateChatCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="content"></param>
            <returns> A new <see cref="!:Official.CreateChatCompletionResponseChoiceLogprobs"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionTokenLogprob(System.String,System.Double,System.Collections.Generic.IEnumerable{System.Int64},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.ChatCompletionTokenLogprobTopLogprob})">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionTokenLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <param name="topLogprobs">
            List of the most likely tokens and their log probability, at this token position. In rare
            cases, there may be fewer than the number of requested `top_logprobs` returned.
            </param>
            <returns> A new <see cref="!:Official.ChatCompletionTokenLogprob"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ChatCompletionTokenLogprobTopLogprob(System.String,System.Double,System.Collections.Generic.IEnumerable{System.Int64})">
            <summary> Initializes a new instance of <see cref="!:Official.ChatCompletionTokenLogprobTopLogprob"/>. </summary>
            <param name="token"> The token. </param>
            <param name="logprob"> The log probability of this token. </param>
            <param name="bytes">
            A list of integers representing the UTF-8 bytes representation of the token. Useful in
            instances where characters are represented by multiple tokens and their byte representations
            must be combined to generate the correct text representation. Can be `null` if there is no
            bytes representation for the token.
            </param>
            <returns> A new <see cref="!:Official.ChatCompletionTokenLogprobTopLogprob"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CompletionUsage(System.Int64,System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="!:Official.CompletionUsage"/>. </summary>
            <param name="promptTokens"> Number of tokens in the prompt. </param>
            <param name="completionTokens"> Number of tokens in the generated completion. </param>
            <param name="totalTokens"> Total number of tokens used in the request (prompt + completion). </param>
            <returns> A new <see cref="!:Official.CompletionUsage"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateCompletionRequest(OpenAI.Official.Internal.CreateCompletionRequestModel,System.BinaryData,System.Nullable{System.Int64},System.Nullable{System.Boolean},System.Nullable{System.Double},System.Collections.Generic.IDictionary{System.String,System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},System.Nullable{System.Int64},System.BinaryData,System.Nullable{System.Boolean},System.String,System.Nullable{System.Double},System.Nullable{System.Double},System.String)">
             <summary> Initializes a new instance of <see cref="!:Official.CreateCompletionRequest"/>. </summary>
             <param name="model">
             ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
             see all of your available models, or see our [Model overview](/docs/models/overview) for
             descriptions of them.
             </param>
             <param name="prompt">
             The prompt(s) to generate completions for, encoded as a string, array of strings, array of
             tokens, or array of token arrays.
            
             Note that &lt;|endoftext|&gt; is the document separator that the model sees during training, so if a
             prompt is not specified the model will generate as if from the beginning of a new document.
             </param>
             <param name="bestOf">
             Generates `best_of` completions server-side and returns the "best" (the one with the highest
             log probability per token). Results cannot be streamed.
            
             When used with `n`, `best_of` controls the number of candidate completions and `n` specifies
             how many to return – `best_of` must be greater than `n`.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </param>
             <param name="echo"> Echo back the prompt in addition to the completion. </param>
             <param name="frequencyPenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
             frequency in the text so far, decreasing the model's likelihood to repeat the same line
             verbatim.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="logitBias">
             Modify the likelihood of specified tokens appearing in the completion.
            
             Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an
             associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe)
             to convert text to token IDs. Mathematically, the bias is added to the logits generated by the
             model prior to sampling. The exact effect will vary per model, but values between -1 and 1
             should decrease or increase likelihood of selection; values like -100 or 100 should result in a
             ban or exclusive selection of the relevant token.
            
             As an example, you can pass `{"50256": -100}` to prevent the &lt;|endoftext|&gt; token from being
             generated.
             </param>
             <param name="logprobs">
             Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens.
             For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The
             API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1`
             elements in the response.
            
             The maximum value for `logprobs` is 5.
             </param>
             <param name="maxTokens">
             The maximum number of [tokens](/tokenizer) to generate in the completion.
            
             The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
             for counting tokens.
             </param>
             <param name="n">
             How many completions to generate for each prompt.
            
             **Note:** Because this parameter generates many completions, it can quickly consume your token
             quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
             </param>
             <param name="presencePenalty">
             Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
             in the text so far, increasing the model's likelihood to talk about new topics.
            
             [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
             </param>
             <param name="seed">
             If specified, our system will make a best effort to sample deterministically, such that
             repeated requests with the same `seed` and parameters should return the same result.
            
             Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
             parameter to monitor changes in the backend.
             </param>
             <param name="stop"> Up to 4 sequences where the API will stop generating further tokens. </param>
             <param name="stream">
             If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
             [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
             as they become available, with the stream terminated by a `data: [DONE]` message.
             [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
             </param>
             <param name="suffix"> The suffix that comes after a completion of inserted text. </param>
             <param name="temperature">
             What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
             more random, while lower values like 0.2 will make it more focused and deterministic.
            
             We generally recommend altering this or `top_p` but not both.
             </param>
             <param name="topP">
             An alternative to sampling with temperature, called nucleus sampling, where the model considers
             the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
             the top 10% probability mass are considered.
            
             We generally recommend altering this or `temperature` but not both.
             </param>
             <param name="user">
             A unique identifier representing your end-user, which can help OpenAI to monitor and detect
             abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
             </param>
             <returns> A new <see cref="!:Official.CreateCompletionRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateCompletionResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateCompletionResponseChoice},System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.CreateCompletionResponseObject,OpenAI.Official.Internal.CompletionUsage)">
             <summary> Initializes a new instance of <see cref="!:Official.CreateCompletionResponse"/>. </summary>
             <param name="id"> A unique identifier for the completion. </param>
             <param name="choices"> The list of completion choices the model generated for the input. </param>
             <param name="created"> The Unix timestamp (in seconds) of when the completion was created. </param>
             <param name="model"> The model used for the completion. </param>
             <param name="systemFingerprint">
             This fingerprint represents the backend configuration that the model runs with.
            
             Can be used in conjunction with the `seed` request parameter to understand when backend changes
             have been made that might impact determinism.
             </param>
             <param name="object"> The object type, which is always `text_completion`. </param>
             <param name="usage"> Usage statistics for the completion request. </param>
             <returns> A new <see cref="!:Official.CreateCompletionResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateCompletionResponseChoice(System.Int64,System.String,OpenAI.Official.Internal.CreateCompletionResponseChoiceLogprobs,OpenAI.Official.Internal.CreateCompletionResponseChoiceFinishReason)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateCompletionResponseChoice"/>. </summary>
            <param name="index"></param>
            <param name="text"></param>
            <param name="logprobs"></param>
            <param name="finishReason">
            The reason the model stopped generating tokens. This will be `stop` if the model hit a
            natural stop point or a provided stop sequence, or `content_filter` if content was omitted
            due to a flag from our content filters, `length` if the maximum number of tokens specified
            in the request was reached, or `content_filter` if content was omitted due to a flag from our
            content filters.
            </param>
            <returns> A new <see cref="!:Official.CreateCompletionResponseChoice"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateCompletionResponseChoiceLogprobs(System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Collections.Generic.IDictionary{System.String,System.Int64}},System.Collections.Generic.IEnumerable{System.Int64})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateCompletionResponseChoiceLogprobs"/>. </summary>
            <param name="tokens"></param>
            <param name="tokenLogprobs"></param>
            <param name="topLogprobs"></param>
            <param name="textOffset"></param>
            <returns> A new <see cref="!:Official.CreateCompletionResponseChoiceLogprobs"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateEmbeddingRequest(System.BinaryData,OpenAI.Official.Internal.CreateEmbeddingRequestModel,System.Nullable{OpenAI.Official.Internal.CreateEmbeddingRequestEncodingFormat},System.Nullable{System.Int64},System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateEmbeddingRequest"/>. </summary>
            <param name="input">
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
            single request, pass an array of strings or array of token arrays. Each input must not exceed
            the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an
            empty string.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
            </param>
            <param name="model">
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
            </param>
            <param name="encodingFormat">
            The format to return the embeddings in. Can be either `float` or
            [`base64`](https://pypi.org/project/pybase64/).
            </param>
            <param name="dimensions">
            The number of dimensions the resulting output embeddings should have. Only supported in
            `text-embedding-3` and later models.
            </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <returns> A new <see cref="!:Official.CreateEmbeddingRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateEmbeddingResponse(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Embedding},System.String,OpenAI.Official.Internal.CreateEmbeddingResponseObject,OpenAI.Official.Internal.CreateEmbeddingResponseUsage)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateEmbeddingResponse"/>. </summary>
            <param name="data"> The list of embeddings generated by the model. </param>
            <param name="model"> The name of the model used to generate the embedding. </param>
            <param name="object"> The object type, which is always "list". </param>
            <param name="usage"> The usage information for the request. </param>
            <returns> A new <see cref="!:Official.CreateEmbeddingResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.Embedding(System.Int64,System.BinaryData,OpenAI.Official.Internal.EmbeddingObject)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Embedding"/>. </summary>
            <param name="index"> The index of the embedding in the list of embeddings. </param>
            <param name="embeddingProperty">
            The embedding vector, which is a list of floats. The length of vector depends on the model as
            listed in the [embedding guide](/docs/guides/embeddings).
            </param>
            <param name="object"> The object type, which is always "embedding". </param>
            <returns> A new <see cref="T:OpenAI.Official.Embedding"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateEmbeddingResponseUsage(System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateEmbeddingResponseUsage"/>. </summary>
            <param name="promptTokens"> The number of tokens used by the prompt. </param>
            <param name="totalTokens"> The total number of tokens used by the request. </param>
            <returns> A new <see cref="!:Official.CreateEmbeddingResponseUsage"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.OpenAIFile(System.String,System.Int64,System.DateTimeOffset,System.String,OpenAI.Official.Internal.OpenAIFileObject,OpenAI.Official.Internal.OpenAIFilePurpose,OpenAI.Official.Internal.OpenAIFileStatus,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.OpenAIFile"/>. </summary>
            <param name="id"> The file identifier, which can be referenced in the API endpoints. </param>
            <param name="bytes"> The size of the file, in bytes. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the file was created. </param>
            <param name="filename"> The name of the file. </param>
            <param name="object"> The object type, which is always "file". </param>
            <param name="purpose">
            The intended purpose of the file. Supported values are `fine-tune`, `fine-tune-results`,
            `assistants`, and `assistants_output`.
            </param>
            <param name="status">
            Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or
            `error`.
            </param>
            <param name="statusDetails">
            Deprecated. For details on why a fine-tuning training file failed validation, see the `error`
            field on `fine_tuning.job`.
            </param>
            <returns> A new <see cref="!:Official.OpenAIFile"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListFilesResponse(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},OpenAI.Official.Internal.ListFilesResponseObject)">
            <summary> Initializes a new instance of <see cref="!:Official.ListFilesResponse"/>. </summary>
            <param name="data"></param>
            <param name="object"></param>
            <returns> A new <see cref="!:Official.ListFilesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.DeleteFileResponse(System.String,OpenAI.Official.Internal.DeleteFileResponseObject,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.DeleteFileResponse"/>. </summary>
            <param name="id"></param>
            <param name="object"></param>
            <param name="deleted"></param>
            <returns> A new <see cref="!:Official.DeleteFileResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateFineTuneRequest(System.String,System.String,System.Nullable{OpenAI.Official.Internal.CreateFineTuneRequestModel},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{System.Boolean},System.Nullable{System.Int64},System.String,System.Collections.Generic.IEnumerable{System.Double},System.String)">
             <summary> Initializes a new instance of <see cref="!:Official.CreateFineTuneRequest"/>. </summary>
             <param name="trainingFile">
             The ID of an uploaded file that contains training data.
            
             See [upload file](/docs/api-reference/files/upload) for how to upload a file.
            
             Your dataset must be formatted as a JSONL file, where each training example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </param>
             <param name="validationFile">
             The ID of an uploaded file that contains validation data.
            
             If you provide this file, the data is used to generate validation metrics periodically during
             fine-tuning. These metrics can be viewed in the
             [fine-tuning results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
             Your train and validation data should be mutually exclusive.
            
             Your dataset must be formatted as a JSONL file, where each validation example is a JSON object
             with the keys "prompt" and "completion". Additionally, you must upload your file with the
             purpose `fine-tune`.
            
             See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
             details.
             </param>
             <param name="model">
             The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie",
             "davinci", or a fine-tuned model created after 2022-04-21 and before 2023-08-22. To learn more
             about these models, see the [Models](/docs/models) documentation.
             </param>
             <param name="nEpochs">
             The number of epochs to train the model for. An epoch refers to one full cycle through the
             training dataset.
             </param>
             <param name="batchSize">
             The batch size to use for training. The batch size is the number of training examples used to
             train a single forward and backward pass.
            
             By default, the batch size will be dynamically configured to be ~0.2% of the number of examples
             in the training set, capped at 256 - in general, we've found that larger batch sizes tend to
             work better for larger datasets.
             </param>
             <param name="learningRateMultiplier">
             The learning rate multiplier to use for training. The fine-tuning learning rate is the original
             learning rate used for pretraining multiplied by this value.
            
             By default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final
             `batch_size` (larger learning rates tend to perform better with larger batch sizes). We
             recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best
             results.
             </param>
             <param name="promptLossRate">
             The weight to use for loss on the prompt tokens. This controls how much the model tries to
             learn to generate the prompt (as compared to the completion which always has a weight of 1.0),
             and can add a stabilizing effect to training when completions are short.
            
             If prompts are extremely long (relative to completions), it may make sense to reduce this
             weight so as to avoid over-prioritizing learning the prompt.
             </param>
             <param name="computeClassificationMetrics">
             If set, we calculate classification-specific metrics such as accuracy and F-1 score using the
             validation set at the end of every epoch. These metrics can be viewed in the
             [results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
            
             In order to compute classification metrics, you must provide a `validation_file`. Additionally,
             you must specify `classification_n_classes` for multiclass classification or
             `classification_positive_class` for binary classification.
             </param>
             <param name="classificationNClasses">
             The number of classes in a classification task.
            
             This parameter is required for multiclass classification.
             </param>
             <param name="classificationPositiveClass">
             The positive class in binary classification.
            
             This parameter is needed to generate precision, recall, and F1 metrics when doing binary
             classification.
             </param>
             <param name="classificationBetas">
             If this is provided, we calculate F-beta scores at the specified beta values. The F-beta score
             is a generalization of F-1 score. This is only used for binary classification.
            
             With a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger
             beta score puts more weight on recall and less on precision. A smaller beta score puts more
             weight on precision and less on recall.
             </param>
             <param name="suffix">
             A string of up to 18 characters that will be added to your fine-tuned model name.
            
             For example, a `suffix` of "custom-model-name" would produce a model name like
             `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.
             </param>
             <returns> A new <see cref="!:Official.CreateFineTuneRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTune(System.String,OpenAI.Official.Internal.FineTuneObject,System.DateTimeOffset,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.FineTuneStatus,OpenAI.Official.Internal.FineTuneHyperparams,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.OpenAIFile},System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuneEvent})">
            <summary> Initializes a new instance of <see cref="!:Official.FineTune"/>. </summary>
            <param name="id"> The object identifier, which can be referenced in the API endpoints. </param>
            <param name="object"> The object type, which is always "fine-tune". </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the fine-tuning job was created. </param>
            <param name="updatedAt"> The Unix timestamp (in seconds) for when the fine-tuning job was last updated. </param>
            <param name="model"> The base model that is being fine-tuned. </param>
            <param name="fineTunedModel"> The name of the fine-tuned model that is being created. </param>
            <param name="organizationId"> The organization that owns the fine-tuning job. </param>
            <param name="status">
            The current status of the fine-tuning job, which can be either `created`, `running`,
            `succeeded`, `failed`, or `cancelled`.
            </param>
            <param name="hyperparams">
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
            </param>
            <param name="trainingFiles"> The list of files used for training. </param>
            <param name="validationFiles"> The list of files used for validation. </param>
            <param name="resultFiles"> The compiled results files for the fine-tuning job. </param>
            <param name="events"> The list of events that have been observed in the lifecycle of the FineTune job. </param>
            <returns> A new <see cref="!:Official.FineTune"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuneHyperparams(System.Int64,System.Int64,System.Double,System.Double,System.Nullable{System.Boolean},System.String,System.Nullable{System.Int64})">
            <summary> Initializes a new instance of <see cref="!:Official.FineTuneHyperparams"/>. </summary>
            <param name="nEpochs">
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
            </param>
            <param name="batchSize">
            The batch size to use for training. The batch size is the number of training examples used to
            train a single forward and backward pass.
            </param>
            <param name="promptLossWeight"> The weight to use for loss on the prompt tokens. </param>
            <param name="learningRateMultiplier"> The learning rate multiplier to use for training. </param>
            <param name="computeClassificationMetrics"> The classification metrics to compute using the validation dataset at the end of every epoch. </param>
            <param name="classificationPositiveClass"> The positive class to use for computing classification metrics. </param>
            <param name="classificationNClasses"> The number of classes to use for computing classification metrics. </param>
            <returns> A new <see cref="!:Official.FineTuneHyperparams"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.FineTuneEvent(System.String,System.DateTimeOffset,System.String,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.FineTuneEvent"/>. </summary>
            <param name="object"></param>
            <param name="createdAt"></param>
            <param name="level"></param>
            <param name="message"></param>
            <returns> A new <see cref="!:Official.FineTuneEvent"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListFineTunesResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTune})">
            <summary> Initializes a new instance of <see cref="!:Official.ListFineTunesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <returns> A new <see cref="!:Official.ListFineTunesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListFineTuneEventsResponse(System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.FineTuneEvent})">
            <summary> Initializes a new instance of <see cref="!:Official.ListFineTuneEventsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <returns> A new <see cref="!:Official.ListFineTuneEventsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateImageRequest(System.String,System.Nullable{OpenAI.Official.Internal.CreateImageRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageRequestQuality},System.Nullable{OpenAI.Official.Internal.CreateImageRequestResponseFormat},System.Nullable{OpenAI.Official.Internal.CreateImageRequestSize},System.Nullable{OpenAI.Official.Internal.CreateImageRequestStyle},System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateImageRequest"/>. </summary>
            <param name="prompt">
            A text description of the desired image(s). The maximum length is 1000 characters for
            `dall-e-2` and 4000 characters for `dall-e-3`.
            </param>
            <param name="model"> The model to use for image generation. </param>
            <param name="n">
            The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is
            supported.
            </param>
            <param name="quality">
            The quality of the image that will be generated. `hd` creates images with finer details and
            greater consistency across the image. This param is only supported for `dall-e-3`.
            </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="size">
            The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for
            `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.
            </param>
            <param name="style">
            The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model
            to lean towards generating hyper-real and dramatic images. Natural causes the model to produce
            more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.
            </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <returns> A new <see cref="!:Official.CreateImageRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ImagesResponse(System.DateTimeOffset,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Image})">
            <summary> Initializes a new instance of <see cref="!:Official.ImagesResponse"/>. </summary>
            <param name="created"></param>
            <param name="data"></param>
            <returns> A new <see cref="!:Official.ImagesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.Image(System.BinaryData,System.Uri,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.Image"/>. </summary>
            <param name="b64Json"> The base64-encoded JSON of the generated image, if `response_format` is `b64_json`. </param>
            <param name="url"> The URL of the generated image, if `response_format` is `url` (default). </param>
            <param name="revisedPrompt"> The prompt that was used to generate the image, if there was any revision to the prompt. </param>
            <returns> A new <see cref="!:Official.Image"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateImageEditRequest(System.BinaryData,System.String,System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestSize},System.Nullable{OpenAI.Official.Internal.CreateImageEditRequestResponseFormat},System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateImageEditRequest"/>. </summary>
            <param name="image">
            The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
            provided, image must have transparency, which will be used as the mask.
            </param>
            <param name="prompt"> A text description of the desired image(s). The maximum length is 1000 characters. </param>
            <param name="mask">
            An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where
            `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions
            as `image`.
            </param>
            <param name="model"> The model to use for image generation. Only `dall-e-2` is supported at this time. </param>
            <param name="n"> The number of images to generate. Must be between 1 and 10. </param>
            <param name="size"> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <returns> A new <see cref="!:Official.CreateImageEditRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateImageVariationRequest(System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestModel},System.Nullable{System.Int64},System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestResponseFormat},System.Nullable{OpenAI.Official.Internal.CreateImageVariationRequestSize},System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateImageVariationRequest"/>. </summary>
            <param name="image">
            The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB,
            and square.
            </param>
            <param name="model"> The model to use for image generation. Only `dall-e-2` is supported at this time. </param>
            <param name="n"> The number of images to generate. Must be between 1 and 10. </param>
            <param name="responseFormat"> The format in which the generated images are returned. Must be one of `url` or `b64_json`. </param>
            <param name="size"> The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`. </param>
            <param name="user">
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
            </param>
            <returns> A new <see cref="!:Official.CreateImageVariationRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateMessageRequest(OpenAI.Official.Internal.CreateMessageRequestRole,System.String,System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateMessageRequest"/>. </summary>
            <param name="role"> The role of the entity that is creating the message. Currently only `user` is supported. </param>
            <param name="content"> The content of the message. </param>
            <param name="fileIds">
            A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a
            maximum of 10 files attached to a message. Useful for tools like `retrieval` and
            `code_interpreter` that can access and use files.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.CreateMessageRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.MessageObject(System.String,OpenAI.Official.Internal.MessageObjectObject,System.DateTimeOffset,System.String,OpenAI.Official.Internal.MessageObjectRole,System.Collections.Generic.IEnumerable{System.BinaryData},System.String,System.String,System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.MessageObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.message`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message was created. </param>
            <param name="threadId"> The [thread](/docs/api-reference/threads) ID that this message belongs to. </param>
            <param name="role"> The entity that produced the message. One of `user` or `assistant`. </param>
            <param name="content"> The content of the message in array of text and/or images. </param>
            <param name="assistantId">
            If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this
            message.
            </param>
            <param name="runId">
            If applicable, the ID of the [run](/docs/api-reference/runs) associated with the authoring of
            this message.
            </param>
            <param name="fileIds">
            A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for
            tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be
            attached to a message.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.MessageObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListMessagesResponse(OpenAI.Official.Internal.ListMessagesResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.MessageObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListMessagesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListMessagesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListMessageFilesResponse(OpenAI.Official.Internal.ListMessageFilesResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.MessageFileObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListMessageFilesResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListMessageFilesResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.MessageFileObject(System.String,OpenAI.Official.Internal.MessageFileObjectObject,System.DateTimeOffset,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.MessageFileObject"/>. </summary>
            <param name="id"> TThe identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.message.file`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the message file was created. </param>
            <param name="messageId"> The ID of the [message](/docs/api-reference/messages) that the [File](/docs/api-reference/files) is attached to. </param>
            <returns> A new <see cref="!:Official.MessageFileObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListModelsResponse(OpenAI.Official.Internal.ListModelsResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.Model})">
            <summary> Initializes a new instance of <see cref="!:Official.ListModelsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <returns> A new <see cref="!:Official.ListModelsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.Model(System.String,System.DateTimeOffset,OpenAI.Official.Internal.ModelObject,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.Model"/>. </summary>
            <param name="id"> The model identifier, which can be referenced in the API endpoints. </param>
            <param name="created"> The Unix timestamp (in seconds) when the model was created. </param>
            <param name="object"> The object type, which is always "model". </param>
            <param name="ownedBy"> The organization that owns the model. </param>
            <returns> A new <see cref="!:Official.Model"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.DeleteModelResponse(System.String,System.Boolean,OpenAI.Official.Internal.DeleteModelResponseObject)">
            <summary> Initializes a new instance of <see cref="!:Official.DeleteModelResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <returns> A new <see cref="!:Official.DeleteModelResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateModerationRequest(System.BinaryData,System.Nullable{OpenAI.Official.Internal.CreateModerationRequestModel})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateModerationRequest"/>. </summary>
            <param name="input"> The input text to classify. </param>
            <param name="model">
            Two content moderations models are available: `text-moderation-stable` and
            `text-moderation-latest`. The default is `text-moderation-latest` which will be automatically
            upgraded over time. This ensures you are always using our most accurate model. If you use
            `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy
            of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
            </param>
            <returns> A new <see cref="!:Official.CreateModerationRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateModerationResponse(System.String,System.String,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.CreateModerationResponseResult})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateModerationResponse"/>. </summary>
            <param name="id"> The unique identifier for the moderation request. </param>
            <param name="model"> The model used to generate the moderation results. </param>
            <param name="results"> A list of moderation objects. </param>
            <returns> A new <see cref="!:Official.CreateModerationResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateModerationResponseResult(System.Boolean,OpenAI.Official.Internal.CreateModerationResponseResultCategories,OpenAI.Official.Internal.CreateModerationResponseResultCategoryScores)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateModerationResponseResult"/>. </summary>
            <param name="flagged"> Whether the content violates [OpenAI's usage policies](/policies/usage-policies). </param>
            <param name="categories"> A list of the categories, and whether they are flagged or not. </param>
            <param name="categoryScores"> A list of the categories along with their scores as predicted by model. </param>
            <returns> A new <see cref="!:Official.CreateModerationResponseResult"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateModerationResponseResultCategories(System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateModerationResponseResultCategories"/>. </summary>
            <param name="hate">
            Content that expresses, incites, or promotes hate based on race, gender, ethnicity,
            religion, nationality, sexual orientation, disability status, or caste. Hateful content
            aimed at non-protected groups (e.g., chess players) is harrassment.
            </param>
            <param name="hateThreatening">
            Hateful content that also includes violence or serious harm towards the targeted group
            based on race, gender, ethnicity, religion, nationality, sexual orientation, disability
            status, or caste.
            </param>
            <param name="harassment"> Content that expresses, incites, or promotes harassing language towards any target. </param>
            <param name="harassmentThreatening"> Harassment content that also includes violence or serious harm towards any target. </param>
            <param name="selfHarm">
            Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting,
            and eating disorders.
            </param>
            <param name="selfHarmIntent">
            Content where the speaker expresses that they are engaging or intend to engage in acts of
            self-harm, such as suicide, cutting, and eating disorders.
            </param>
            <param name="selfHarmInstructions">
            Content that encourages performing acts of self-harm, such as suicide, cutting, and eating
            disorders, or that gives instructions or advice on how to commit such acts.
            </param>
            <param name="sexual">
            Content meant to arouse sexual excitement, such as the description of sexual activity, or
            that promotes sexual services (excluding sex education and wellness).
            </param>
            <param name="sexualMinors"> Sexual content that includes an individual who is under 18 years old. </param>
            <param name="violence"> Content that depicts death, violence, or physical injury. </param>
            <param name="violenceGraphic"> Content that depicts death, violence, or physical injury in graphic detail. </param>
            <returns> A new <see cref="!:Official.CreateModerationResponseResultCategories"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateModerationResponseResultCategoryScores(System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
            <summary> Initializes a new instance of <see cref="!:Official.CreateModerationResponseResultCategoryScores"/>. </summary>
            <param name="hate"> The score for the category 'hate'. </param>
            <param name="hateThreatening"> The score for the category 'hate/threatening'. </param>
            <param name="harassment"> The score for the category 'harassment'. </param>
            <param name="harassmentThreatening"> The score for the category 'harassment/threatening'. </param>
            <param name="selfHarm"> The score for the category 'self-harm'. </param>
            <param name="selfHarmIntent"> The score for the category 'self-harm/intent'. </param>
            <param name="selfHarmInstructions"> The score for the category 'self-harm/instructive'. </param>
            <param name="sexual"> The score for the category 'sexual'. </param>
            <param name="sexualMinors"> The score for the category 'sexual/minors'. </param>
            <param name="violence"> The score for the category 'violence'. </param>
            <param name="violenceGraphic"> The score for the category 'violence/graphic'. </param>
            <returns> A new <see cref="!:Official.CreateModerationResponseResultCategoryScores"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateThreadAndRunRequest(System.String,OpenAI.Official.Internal.CreateThreadRequest,System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateThreadAndRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <param name="thread"> If no thread is provided, an empty thread will be created. </param>
            <param name="model">
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is
            provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </param>
            <param name="instructions">
            Override the default system message of the assistant. This is useful for modifying the behavior
            on a per-run basis.
            </param>
            <param name="tools">
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.CreateThreadAndRunRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunObject(System.String,OpenAI.Official.Internal.RunObjectObject,System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.RunObjectStatus,OpenAI.Official.Internal.RunObjectRequiredAction,OpenAI.Official.Internal.RunObjectLastError,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage)">
            <summary> Initializes a new instance of <see cref="!:Official.RunObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.run`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run was created. </param>
            <param name="threadId">
            The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this
            run.
            </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run. </param>
            <param name="status">
            The status of the run, which can be either `queued`, `in_progress`, `requires_action`,
            `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.
            </param>
            <param name="requiredAction">
            Details on the action required to continue the run. Will be `null` if no action is
            required.
            </param>
            <param name="lastError"> The last error associated with this run. Will be `null` if there are no errors. </param>
            <param name="expiresAt"> The Unix timestamp (in seconds) for when the run will expire. </param>
            <param name="startedAt"> The Unix timestamp (in seconds) for when the run was started. </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run failed. </param>
            <param name="completedAt"> The Unix timestamp (in seconds) for when the run was completed. </param>
            <param name="model"> The model that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="instructions"> The instructions that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="tools"> The list of tools that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="fileIds">
            The list of [File](/docs/api-reference/files) IDs the
            [assistant](/docs/api-reference/assistants) used for this run.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <returns> A new <see cref="!:Official.RunObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunObjectRequiredAction(OpenAI.Official.Internal.RunObjectRequiredActionType,OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs)">
            <summary> Initializes a new instance of <see cref="!:Official.RunObjectRequiredAction"/>. </summary>
            <param name="type"> For now, this is always `submit_tool_outputs`. </param>
            <param name="submitToolOutputs"> Details on the tool outputs needed for this run to continue. </param>
            <returns> A new <see cref="!:Official.RunObjectRequiredAction"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunObjectRequiredActionSubmitToolOutputs(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunToolCallObject})">
            <summary> Initializes a new instance of <see cref="!:Official.RunObjectRequiredActionSubmitToolOutputs"/>. </summary>
            <param name="toolCalls"> A list of the relevant tool calls. </param>
            <returns> A new <see cref="!:Official.RunObjectRequiredActionSubmitToolOutputs"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunToolCallObject(System.String,OpenAI.Official.Internal.RunToolCallObjectType,OpenAI.Official.Internal.RunToolCallObjectFunction)">
            <summary> Initializes a new instance of <see cref="!:Official.RunToolCallObject"/>. </summary>
            <param name="id">
            The ID of the tool call. This ID must be referenced when you submit the tool outputs in using
            the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.
            </param>
            <param name="type"> The type of tool call the output is required for. For now, this is always `function`. </param>
            <param name="function"> The function definition. </param>
            <returns> A new <see cref="!:Official.RunToolCallObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunToolCallObjectFunction(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.RunToolCallObjectFunction"/>. </summary>
            <param name="name"> The name of the function. </param>
            <param name="arguments"> The arguments that the model expects you to pass to the function. </param>
            <returns> A new <see cref="!:Official.RunToolCallObjectFunction"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunObjectLastError(OpenAI.Official.Internal.RunObjectLastErrorCode,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.RunObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <returns> A new <see cref="!:Official.RunObjectLastError"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunCompletionUsage(System.Int64,System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="!:Official.RunCompletionUsage"/>. </summary>
            <param name="completionTokens"> Number of completion tokens used over the course of the run. </param>
            <param name="promptTokens"> Number of prompt tokens used over the course of the run. </param>
            <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
            <returns> A new <see cref="!:Official.RunCompletionUsage"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.CreateRunRequest(System.String,System.String,System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.CreateRunRequest"/>. </summary>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run. </param>
            <param name="model">
            The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value
            is provided here, it will override the model associated with the assistant. If not, the model
            associated with the assistant will be used.
            </param>
            <param name="instructions">
            Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant.
            This is useful for modifying the behavior on a per-run basis.
            </param>
            <param name="additionalInstructions">
            Appends additional instructions at the end of the instructions for the run. This is useful for
            modifying the behavior on a per-run basis without overriding other instructions.
            </param>
            <param name="tools">
            Override the tools the assistant can use for this run. This is useful for modifying the
            behavior on a per-run basis.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.CreateRunRequest"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListRunsResponse(OpenAI.Official.Internal.ListRunsResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListRunsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListRunsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ListRunStepsResponse(OpenAI.Official.Internal.ListRunStepsResponseObject,System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunStepObject},System.String,System.String,System.Boolean)">
            <summary> Initializes a new instance of <see cref="!:Official.ListRunStepsResponse"/>. </summary>
            <param name="object"></param>
            <param name="data"></param>
            <param name="firstId"></param>
            <param name="lastId"></param>
            <param name="hasMore"></param>
            <returns> A new <see cref="!:Official.ListRunStepsResponse"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunStepObject(System.String,OpenAI.Official.Internal.RunStepObjectObject,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.RunStepObjectType,OpenAI.Official.Internal.RunStepObjectStatus,System.BinaryData,OpenAI.Official.Internal.RunStepObjectLastError,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage)">
            <summary> Initializes a new instance of <see cref="!:Official.RunStepObject"/>. </summary>
            <param name="id"> The identifier of the run step, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.run.step`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run step was created. </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) associated with the run step. </param>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the [run](/docs/api-reference/runs) that this run step is a part of. </param>
            <param name="type"> The type of run step, which can be either `message_creation` or `tool_calls`. </param>
            <param name="status">
            The status of the run step, which can be either `in_progress`, `cancelled`, `failed`,
            `completed`, or `expired`.
            </param>
            <param name="stepDetails"> The details of the run step. </param>
            <param name="lastError"> The last error associated with this run step. Will be `null` if there are no errors. </param>
            <param name="expiresAt">
            The Unix timestamp (in seconds) for when the run step expired. A step is considered expired
            if the parent run is expired.
            </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run step was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run step failed. </param>
            <param name="completedAt"> T The Unix timestamp (in seconds) for when the run step completed.. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <returns> A new <see cref="!:Official.RunStepObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.RunStepObjectLastError(OpenAI.Official.Internal.RunStepObjectLastErrorCode,System.String)">
            <summary> Initializes a new instance of <see cref="!:Official.RunStepObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <returns> A new <see cref="!:Official.RunStepObjectLastError"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.ThreadObject(System.String,OpenAI.Official.Internal.ThreadObjectObject,System.DateTimeOffset,System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="!:Official.ThreadObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the thread was created. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <returns> A new <see cref="!:Official.ThreadObject"/> instance for mocking. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.OpenAIOfficialModelFactory.DeleteThreadResponse(System.String,System.Boolean,OpenAI.Official.Internal.DeleteThreadResponseObject)">
            <summary> Initializes a new instance of <see cref="!:Official.DeleteThreadResponse"/>. </summary>
            <param name="id"></param>
            <param name="deleted"></param>
            <param name="object"></param>
            <returns> A new <see cref="!:Official.DeleteThreadResponse"/> instance for mocking. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.RunCompletionUsage">
            <summary>
            Usage statistics related to the run. This value will be `null` if the run is not in a terminal
            state (i.e. `in_progress`, `queued`, etc.).
            </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunCompletionUsage._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunCompletionUsage.#ctor(System.Int64,System.Int64,System.Int64)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunCompletionUsage"/>. </summary>
            <param name="completionTokens"> Number of completion tokens used over the course of the run. </param>
            <param name="promptTokens"> Number of prompt tokens used over the course of the run. </param>
            <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunCompletionUsage.#ctor(System.Int64,System.Int64,System.Int64,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunCompletionUsage"/>. </summary>
            <param name="completionTokens"> Number of completion tokens used over the course of the run. </param>
            <param name="promptTokens"> Number of prompt tokens used over the course of the run. </param>
            <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunCompletionUsage.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunCompletionUsage"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunCompletionUsage.CompletionTokens">
            <summary> Number of completion tokens used over the course of the run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunCompletionUsage.PromptTokens">
            <summary> Number of prompt tokens used over the course of the run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunCompletionUsage.TotalTokens">
            <summary> Total number of tokens used (prompt + completion). </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunCompletionUsage.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunCompletionUsage.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunObject">
            <summary> Represents an execution run on a [thread](/docs/api-reference/threads). </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObject.#ctor(System.String,System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.RunObjectStatus,OpenAI.Official.Internal.RunObjectRequiredAction,OpenAI.Official.Internal.RunObjectLastError,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.String,System.String,System.Collections.Generic.IEnumerable{System.BinaryData},System.Collections.Generic.IEnumerable{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run was created. </param>
            <param name="threadId">
            The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this
            run.
            </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run. </param>
            <param name="status">
            The status of the run, which can be either `queued`, `in_progress`, `requires_action`,
            `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.
            </param>
            <param name="requiredAction">
            Details on the action required to continue the run. Will be `null` if no action is
            required.
            </param>
            <param name="lastError"> The last error associated with this run. Will be `null` if there are no errors. </param>
            <param name="expiresAt"> The Unix timestamp (in seconds) for when the run will expire. </param>
            <param name="startedAt"> The Unix timestamp (in seconds) for when the run was started. </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run failed. </param>
            <param name="completedAt"> The Unix timestamp (in seconds) for when the run was completed. </param>
            <param name="model"> The model that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="instructions"> The instructions that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="tools"> The list of tools that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="fileIds">
            The list of [File](/docs/api-reference/files) IDs the
            [assistant](/docs/api-reference/assistants) used for this run.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="threadId"/>, <paramref name="assistantId"/>, <paramref name="model"/>, <paramref name="instructions"/>, <paramref name="tools"/> or <paramref name="fileIds"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObject.#ctor(System.String,OpenAI.Official.Internal.RunObjectObject,System.DateTimeOffset,System.String,System.String,OpenAI.Official.Internal.RunObjectStatus,OpenAI.Official.Internal.RunObjectRequiredAction,OpenAI.Official.Internal.RunObjectLastError,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.String,System.String,System.Collections.Generic.IReadOnlyList{System.BinaryData},System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.run`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run was created. </param>
            <param name="threadId">
            The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this
            run.
            </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run. </param>
            <param name="status">
            The status of the run, which can be either `queued`, `in_progress`, `requires_action`,
            `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.
            </param>
            <param name="requiredAction">
            Details on the action required to continue the run. Will be `null` if no action is
            required.
            </param>
            <param name="lastError"> The last error associated with this run. Will be `null` if there are no errors. </param>
            <param name="expiresAt"> The Unix timestamp (in seconds) for when the run will expire. </param>
            <param name="startedAt"> The Unix timestamp (in seconds) for when the run was started. </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run failed. </param>
            <param name="completedAt"> The Unix timestamp (in seconds) for when the run was completed. </param>
            <param name="model"> The model that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="instructions"> The instructions that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="tools"> The list of tools that the [assistant](/docs/api-reference/assistants) used for this run. </param>
            <param name="fileIds">
            The list of [File](/docs/api-reference/files) IDs the
            [assistant](/docs/api-reference/assistants) used for this run.
            </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Id">
            <summary> The identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Object">
            <summary> The object type, which is always `thread.run`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the run was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.ThreadId">
            <summary>
            The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this
            run.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.AssistantId">
            <summary> The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Status">
            <summary>
            The status of the run, which can be either `queued`, `in_progress`, `requires_action`,
            `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.RequiredAction">
            <summary>
            Details on the action required to continue the run. Will be `null` if no action is
            required.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.LastError">
            <summary> The last error associated with this run. Will be `null` if there are no errors. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.ExpiresAt">
            <summary> The Unix timestamp (in seconds) for when the run will expire. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.StartedAt">
            <summary> The Unix timestamp (in seconds) for when the run was started. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.CancelledAt">
            <summary> The Unix timestamp (in seconds) for when the run was cancelled. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.FailedAt">
            <summary> The Unix timestamp (in seconds) for when the run failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.CompletedAt">
            <summary> The Unix timestamp (in seconds) for when the run was completed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Model">
            <summary> The model that the [assistant](/docs/api-reference/assistants) used for this run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Instructions">
            <summary> The instructions that the [assistant](/docs/api-reference/assistants) used for this run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Tools">
            <summary>
            The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.FileIds">
            <summary>
            The list of [File](/docs/api-reference/files) IDs the
            [assistant](/docs/api-reference/assistants) used for this run.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObject.Usage">
            <summary> Gets the usage. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectLastError">
            <summary> The RunObjectLastError. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunObjectLastError._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastError.#ctor(OpenAI.Official.Internal.RunObjectLastErrorCode,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="message"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastError.#ctor(OpenAI.Official.Internal.RunObjectLastErrorCode,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastError.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectLastError"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectLastError.Code">
            <summary> One of `server_error` or `rate_limit_exceeded`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectLastError.Message">
            <summary> A human-readable description of the error. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastError.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastError.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectLastErrorCode">
            <summary> Enum for code in RunObjectLastError. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectLastErrorCode"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectLastErrorCode.ServerError">
            <summary> server_error. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectLastErrorCode.RateLimitExceeded">
            <summary> rate_limit_exceeded. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.op_Equality(OpenAI.Official.Internal.RunObjectLastErrorCode,OpenAI.Official.Internal.RunObjectLastErrorCode)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectLastErrorCode"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.op_Inequality(OpenAI.Official.Internal.RunObjectLastErrorCode,OpenAI.Official.Internal.RunObjectLastErrorCode)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectLastErrorCode"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.op_Implicit(System.String)~OpenAI.Official.Internal.RunObjectLastErrorCode">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunObjectLastErrorCode"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.Equals(OpenAI.Official.Internal.RunObjectLastErrorCode)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectLastErrorCode.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectObject">
            <summary> The RunObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectObject.ThreadRun">
            <summary> thread.run. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.op_Equality(OpenAI.Official.Internal.RunObjectObject,OpenAI.Official.Internal.RunObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.op_Inequality(OpenAI.Official.Internal.RunObjectObject,OpenAI.Official.Internal.RunObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.RunObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.Equals(OpenAI.Official.Internal.RunObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectRequiredAction">
            <summary> The RunObjectRequiredAction. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunObjectRequiredAction._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredAction.#ctor(OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredAction"/>. </summary>
            <param name="submitToolOutputs"> Details on the tool outputs needed for this run to continue. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="submitToolOutputs"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredAction.#ctor(OpenAI.Official.Internal.RunObjectRequiredActionType,OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredAction"/>. </summary>
            <param name="type"> For now, this is always `submit_tool_outputs`. </param>
            <param name="submitToolOutputs"> Details on the tool outputs needed for this run to continue. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredAction.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredAction"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectRequiredAction.Type">
            <summary> For now, this is always `submit_tool_outputs`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectRequiredAction.SubmitToolOutputs">
            <summary> Details on the tool outputs needed for this run to continue. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredAction.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredAction.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs">
            <summary> The RunObjectRequiredActionSubmitToolOutputs. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.#ctor(System.Collections.Generic.IEnumerable{OpenAI.Official.Internal.RunToolCallObject})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs"/>. </summary>
            <param name="toolCalls"> A list of the relevant tool calls. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="toolCalls"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.#ctor(System.Collections.Generic.IReadOnlyList{OpenAI.Official.Internal.RunToolCallObject},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs"/>. </summary>
            <param name="toolCalls"> A list of the relevant tool calls. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.ToolCalls">
            <summary> A list of the relevant tool calls. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionSubmitToolOutputs.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectRequiredActionType">
            <summary> The RunObjectRequiredAction_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectRequiredActionType.SubmitToolOutputs">
            <summary> submit_tool_outputs. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.op_Equality(OpenAI.Official.Internal.RunObjectRequiredActionType,OpenAI.Official.Internal.RunObjectRequiredActionType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.op_Inequality(OpenAI.Official.Internal.RunObjectRequiredActionType,OpenAI.Official.Internal.RunObjectRequiredActionType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.op_Implicit(System.String)~OpenAI.Official.Internal.RunObjectRequiredActionType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunObjectRequiredActionType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.Equals(OpenAI.Official.Internal.RunObjectRequiredActionType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectRequiredActionType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunObjectStatus">
            <summary> Enum for status in RunObject. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunObjectStatus"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Queued">
            <summary> queued. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.InProgress">
            <summary> in_progress. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.RequiresAction">
            <summary> requires_action. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Cancelling">
            <summary> cancelling. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Cancelled">
            <summary> cancelled. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Failed">
            <summary> failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Completed">
            <summary> completed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunObjectStatus.Expired">
            <summary> expired. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.op_Equality(OpenAI.Official.Internal.RunObjectStatus,OpenAI.Official.Internal.RunObjectStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectStatus"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.op_Inequality(OpenAI.Official.Internal.RunObjectStatus,OpenAI.Official.Internal.RunObjectStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunObjectStatus"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.op_Implicit(System.String)~OpenAI.Official.Internal.RunObjectStatus">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunObjectStatus"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.Equals(OpenAI.Official.Internal.RunObjectStatus)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunObjectStatus.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Runs">
            <summary> The Runs sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Runs.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Runs.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.#ctor">
            <summary> Initializes a new instance of Runs for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Runs. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateThreadAndRunAsync(OpenAI.Official.Internal.CreateThreadAndRunRequest,System.Threading.CancellationToken)">
            <summary> Create a thread and run it in one request. </summary>
            <param name="threadAndRun"> The <see cref="T:OpenAI.Official.Internal.CreateThreadAndRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadAndRun"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateThreadAndRun(OpenAI.Official.Internal.CreateThreadAndRunRequest,System.Threading.CancellationToken)">
            <summary> Create a thread and run it in one request. </summary>
            <param name="threadAndRun"> The <see cref="T:OpenAI.Official.Internal.CreateThreadAndRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadAndRun"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateThreadAndRunAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a thread and run it in one request.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CreateThreadAndRunAsync(OpenAI.Official.Internal.CreateThreadAndRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateThreadAndRun(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a thread and run it in one request.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CreateThreadAndRun(OpenAI.Official.Internal.CreateThreadAndRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateRunAsync(System.String,OpenAI.Official.Internal.CreateRunRequest,System.Threading.CancellationToken)">
            <summary> Create a run. </summary>
            <param name="threadId"> The ID of the thread to run. </param>
            <param name="run"> The <see cref="T:OpenAI.Official.Internal.CreateRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="run"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateRun(System.String,OpenAI.Official.Internal.CreateRunRequest,System.Threading.CancellationToken)">
            <summary> Create a run. </summary>
            <param name="threadId"> The ID of the thread to run. </param>
            <param name="run"> The <see cref="T:OpenAI.Official.Internal.CreateRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="run"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateRunAsync(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CreateRunAsync(System.String,OpenAI.Official.Internal.CreateRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to run. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CreateRun(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CreateRun(System.String,OpenAI.Official.Internal.CreateRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to run. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunsAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of runs belonging to a thread. </summary>
            <param name="threadId"> The ID of the thread the run belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRuns(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of runs belonging to a thread. </summary>
            <param name="threadId"> The ID of the thread the run belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunsAsync(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of runs belonging to a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunsAsync(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread the run belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRuns(System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of runs belonging to a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRuns(System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread the run belongs to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a run. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRun(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a run. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunAsync(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunAsync(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRun(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRun(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.ModifyRunAsync(System.String,System.String,OpenAI.Official.Internal.ModifyRunRequest,System.Threading.CancellationToken)">
            <summary> Modifies a run. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to modify. </param>
            <param name="run"> The <see cref="T:OpenAI.Official.Internal.ModifyRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="run"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.ModifyRun(System.String,System.String,OpenAI.Official.Internal.ModifyRunRequest,System.Threading.CancellationToken)">
            <summary> Modifies a run. </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to modify. </param>
            <param name="run"> The <see cref="T:OpenAI.Official.Internal.ModifyRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="run"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.ModifyRunAsync(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.ModifyRunAsync(System.String,System.String,OpenAI.Official.Internal.ModifyRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.ModifyRun(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.ModifyRun(System.String,System.String,OpenAI.Official.Internal.ModifyRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the run to modify. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CancelRunAsync(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Cancels a run that is `in_progress`. </summary>
            <param name="threadId"> The ID of the thread to which this run belongs. </param>
            <param name="runId"> The ID of the run to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CancelRun(System.String,System.String,System.Threading.CancellationToken)">
            <summary> Cancels a run that is `in_progress`. </summary>
            <param name="threadId"> The ID of the thread to which this run belongs. </param>
            <param name="runId"> The ID of the run to cancel. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CancelRunAsync(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Cancels a run that is `in_progress`.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CancelRunAsync(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which this run belongs. </param>
            <param name="runId"> The ID of the run to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.CancelRun(System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Cancels a run that is `in_progress`.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.CancelRun(System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which this run belongs. </param>
            <param name="runId"> The ID of the run to cancel. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRunAsync(System.String,System.String,OpenAI.Official.Internal.SubmitToolOutputsRunRequest,System.Threading.CancellationToken)">
            <summary>
            When a run has the `status: "requires_action"` and `required_action.type` is
            `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once
            they're all completed. All outputs must be submitted in a single request.
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this run belongs. </param>
            <param name="runId"> The ID of the run that requires the tool output submission. </param>
            <param name="submitToolOutputsRun"> The <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="submitToolOutputsRun"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRun(System.String,System.String,OpenAI.Official.Internal.SubmitToolOutputsRunRequest,System.Threading.CancellationToken)">
            <summary>
            When a run has the `status: "requires_action"` and `required_action.type` is
            `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once
            they're all completed. All outputs must be submitted in a single request.
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this run belongs. </param>
            <param name="runId"> The ID of the run that requires the tool output submission. </param>
            <param name="submitToolOutputsRun"> The <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="submitToolOutputsRun"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRunAsync(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] When a run has the `status: "requires_action"` and `required_action.type` is
            `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once
            they're all completed. All outputs must be submitted in a single request.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRunAsync(System.String,System.String,OpenAI.Official.Internal.SubmitToolOutputsRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this run belongs. </param>
            <param name="runId"> The ID of the run that requires the tool output submission. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRun(System.String,System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] When a run has the `status: "requires_action"` and `required_action.type` is
            `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once
            they're all completed. All outputs must be submitted in a single request.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.SubmitToolOuputsToRun(System.String,System.String,OpenAI.Official.Internal.SubmitToolOutputsRunRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) to which this run belongs. </param>
            <param name="runId"> The ID of the run that requires the tool output submission. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStepsAsync(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of run steps belonging to a run. </summary>
            <param name="threadId"> The ID of the thread the run and run steps belong to. </param>
            <param name="runId"> The ID of the run the run steps belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunSteps(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)">
            <summary> Returns a list of run steps belonging to a run. </summary>
            <param name="threadId"> The ID of the thread the run and run steps belong to. </param>
            <param name="runId"> The ID of the run the run steps belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order.
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStepsAsync(System.String,System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of run steps belonging to a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunStepsAsync(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread the run and run steps belong to. </param>
            <param name="runId"> The ID of the run the run steps belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunSteps(System.String,System.String,System.Nullable{System.Int32},System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Returns a list of run steps belonging to a run.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunSteps(System.String,System.String,System.Nullable{System.Int32},System.Nullable{OpenAI.Official.Internal.ListOrder},System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread the run and run steps belong to. </param>
            <param name="runId"> The ID of the run the run steps belong to. </param>
            <param name="limit">
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
            </param>
            <param name="order">
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and`desc`
            for descending order. Allowed values: "asc" | "desc"
            </param>
            <param name="after">
            A cursor for use in pagination. `after` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include after=obj_foo in order to fetch the next page of the list.
            </param>
            <param name="before">
            A cursor for use in pagination. `before` is an object ID that defines your place in the list.
            For instance, if you make a list request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
            </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="runId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> or <paramref name="runId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStepAsync(System.String,System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a run step. </summary>
            <param name="threadId"> The ID of the thread to which the run and run step belongs. </param>
            <param name="runId"> The ID of the run to which the run step belongs. </param>
            <param name="stepId"> The ID of the run step to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStep(System.String,System.String,System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a run step. </summary>
            <param name="threadId"> The ID of the thread to which the run and run step belongs. </param>
            <param name="runId"> The ID of the run to which the run step belongs. </param>
            <param name="stepId"> The ID of the run step to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStepAsync(System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a run step.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunStepAsync(System.String,System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which the run and run step belongs. </param>
            <param name="runId"> The ID of the run to which the run step belongs. </param>
            <param name="stepId"> The ID of the run step to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Runs.GetRunStep(System.String,System.String,System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a run step.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Runs.GetRunStep(System.String,System.String,System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to which the run and run step belongs. </param>
            <param name="runId"> The ID of the run to which the run step belongs. </param>
            <param name="stepId"> The ID of the run step to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject">
            <summary> Details of the message creation by the run step. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.#ctor(OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject"/>. </summary>
            <param name="messageCreation"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="messageCreation"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.#ctor(OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType,OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject"/>. </summary>
            <param name="type"> Details of the message creation by the run step. </param>
            <param name="messageCreation"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.Type">
            <summary> Details of the message creation by the run step. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.MessageCreation">
            <summary> Gets the message creation. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation">
            <summary> The RunStepDetailsMessageCreationObjectMessageCreation. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation"/>. </summary>
            <param name="messageId"> The ID of the message that was created by this run step. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="messageId"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.#ctor(System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation"/>. </summary>
            <param name="messageId"> The ID of the message that was created by this run step. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.MessageId">
            <summary> The ID of the message that was created by this run step. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectMessageCreation.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType">
            <summary> The RunStepDetailsMessageCreationObject_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.MessageCreation">
            <summary> message_creation. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.op_Equality(OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType,OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.op_Inequality(OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType,OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.Equals(OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsMessageCreationObjectType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObject">
            <summary> Details of the tool call. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunStepDetailsToolCallsObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.#ctor(System.Collections.Generic.IEnumerable{System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObject"/>. </summary>
            <param name="toolCalls">
            An array of tool calls the run step was involved in. These can be associated with one of three
            types of tools: `code_interpreter`, `retrieval`, or `function`.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="toolCalls"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.#ctor(OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType,System.Collections.Generic.IReadOnlyList{System.BinaryData},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObject"/>. </summary>
            <param name="type"> Always `tool_calls`. </param>
            <param name="toolCalls">
            An array of tool calls the run step was involved in. These can be associated with one of three
            types of tools: `code_interpreter`, `retrieval`, or `function`.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.Type">
            <summary> Always `tool_calls`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.ToolCalls">
            <summary>
            An array of tool calls the run step was involved in. These can be associated with one of three
            types of tools: `code_interpreter`, `retrieval`, or `function`.
            <para>
            To assign an object to the element of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType">
            <summary> The RunStepDetailsToolCallsObject_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.ToolCalls">
            <summary> tool_calls. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.op_Equality(OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType,OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.op_Inequality(OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType,OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.Equals(OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepDetailsToolCallsObjectType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObject">
            <summary> Represents a step in execution of a run. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunStepObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObject.#ctor(System.String,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.RunStepObjectType,OpenAI.Official.Internal.RunStepObjectStatus,System.BinaryData,OpenAI.Official.Internal.RunStepObjectLastError,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObject"/>. </summary>
            <param name="id"> The identifier of the run step, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run step was created. </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) associated with the run step. </param>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the [run](/docs/api-reference/runs) that this run step is a part of. </param>
            <param name="type"> The type of run step, which can be either `message_creation` or `tool_calls`. </param>
            <param name="status">
            The status of the run step, which can be either `in_progress`, `cancelled`, `failed`,
            `completed`, or `expired`.
            </param>
            <param name="stepDetails"> The details of the run step. </param>
            <param name="lastError"> The last error associated with this run step. Will be `null` if there are no errors. </param>
            <param name="expiresAt">
            The Unix timestamp (in seconds) for when the run step expired. A step is considered expired
            if the parent run is expired.
            </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run step was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run step failed. </param>
            <param name="completedAt"> T The Unix timestamp (in seconds) for when the run step completed.. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/>, <paramref name="assistantId"/>, <paramref name="threadId"/>, <paramref name="runId"/> or <paramref name="stepDetails"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObject.#ctor(System.String,OpenAI.Official.Internal.RunStepObjectObject,System.DateTimeOffset,System.String,System.String,System.String,OpenAI.Official.Internal.RunStepObjectType,OpenAI.Official.Internal.RunStepObjectStatus,System.BinaryData,OpenAI.Official.Internal.RunStepObjectLastError,System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Nullable{System.DateTimeOffset},System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},OpenAI.Official.Internal.RunCompletionUsage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObject"/>. </summary>
            <param name="id"> The identifier of the run step, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread.run.step`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the run step was created. </param>
            <param name="assistantId"> The ID of the [assistant](/docs/api-reference/assistants) associated with the run step. </param>
            <param name="threadId"> The ID of the [thread](/docs/api-reference/threads) that was run. </param>
            <param name="runId"> The ID of the [run](/docs/api-reference/runs) that this run step is a part of. </param>
            <param name="type"> The type of run step, which can be either `message_creation` or `tool_calls`. </param>
            <param name="status">
            The status of the run step, which can be either `in_progress`, `cancelled`, `failed`,
            `completed`, or `expired`.
            </param>
            <param name="stepDetails"> The details of the run step. </param>
            <param name="lastError"> The last error associated with this run step. Will be `null` if there are no errors. </param>
            <param name="expiresAt">
            The Unix timestamp (in seconds) for when the run step expired. A step is considered expired
            if the parent run is expired.
            </param>
            <param name="cancelledAt"> The Unix timestamp (in seconds) for when the run step was cancelled. </param>
            <param name="failedAt"> The Unix timestamp (in seconds) for when the run step failed. </param>
            <param name="completedAt"> T The Unix timestamp (in seconds) for when the run step completed.. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="usage"></param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Id">
            <summary> The identifier of the run step, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Object">
            <summary> The object type, which is always `thread.run.step`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the run step was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.AssistantId">
            <summary> The ID of the [assistant](/docs/api-reference/assistants) associated with the run step. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.ThreadId">
            <summary> The ID of the [thread](/docs/api-reference/threads) that was run. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.RunId">
            <summary> The ID of the [run](/docs/api-reference/runs) that this run step is a part of. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Type">
            <summary> The type of run step, which can be either `message_creation` or `tool_calls`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Status">
            <summary>
            The status of the run step, which can be either `in_progress`, `cancelled`, `failed`,
            `completed`, or `expired`.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.StepDetails">
            <summary>
            The details of the run step.
            <para>
            To assign an object to this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            <remarks>
            Supported types:
            <list type="bullet">
            <item>
            <description><see cref="T:OpenAI.Official.Internal.RunStepDetailsMessageCreationObject"/></description>
            </item>
            <item>
            <description><see cref="T:OpenAI.Official.Internal.RunStepDetailsToolCallsObject"/></description>
            </item>
            </list>
            </remarks>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.LastError">
            <summary> The last error associated with this run step. Will be `null` if there are no errors. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.ExpiresAt">
            <summary>
            The Unix timestamp (in seconds) for when the run step expired. A step is considered expired
            if the parent run is expired.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.CancelledAt">
            <summary> The Unix timestamp (in seconds) for when the run step was cancelled. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.FailedAt">
            <summary> The Unix timestamp (in seconds) for when the run step failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.CompletedAt">
            <summary> T The Unix timestamp (in seconds) for when the run step completed.. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObject.Usage">
            <summary> Gets the usage. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObjectLastError">
            <summary> The RunStepObjectLastError. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunStepObjectLastError._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastError.#ctor(OpenAI.Official.Internal.RunStepObjectLastErrorCode,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="message"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastError.#ctor(OpenAI.Official.Internal.RunStepObjectLastErrorCode,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectLastError"/>. </summary>
            <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
            <param name="message"> A human-readable description of the error. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastError.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectLastError"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectLastError.Code">
            <summary> One of `server_error` or `rate_limit_exceeded`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectLastError.Message">
            <summary> A human-readable description of the error. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastError.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastError.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObjectLastErrorCode">
            <summary> Enum for code in RunStepObjectLastError. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectLastErrorCode"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectLastErrorCode.ServerError">
            <summary> server_error. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectLastErrorCode.RateLimitExceeded">
            <summary> rate_limit_exceeded. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.op_Equality(OpenAI.Official.Internal.RunStepObjectLastErrorCode,OpenAI.Official.Internal.RunStepObjectLastErrorCode)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectLastErrorCode"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.op_Inequality(OpenAI.Official.Internal.RunStepObjectLastErrorCode,OpenAI.Official.Internal.RunStepObjectLastErrorCode)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectLastErrorCode"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepObjectLastErrorCode">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepObjectLastErrorCode"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.Equals(OpenAI.Official.Internal.RunStepObjectLastErrorCode)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectLastErrorCode.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObjectObject">
            <summary> The RunStepObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectObject.ThreadRunStep">
            <summary> thread.run.step. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.op_Equality(OpenAI.Official.Internal.RunStepObjectObject,OpenAI.Official.Internal.RunStepObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.op_Inequality(OpenAI.Official.Internal.RunStepObjectObject,OpenAI.Official.Internal.RunStepObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.Equals(OpenAI.Official.Internal.RunStepObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObjectStatus">
            <summary> Enum for status in RunStepObject. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectStatus"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectStatus.InProgress">
            <summary> in_progress. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectStatus.Cancelled">
            <summary> cancelled. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectStatus.Failed">
            <summary> failed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectStatus.Completed">
            <summary> completed. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectStatus.Expired">
            <summary> expired. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.op_Equality(OpenAI.Official.Internal.RunStepObjectStatus,OpenAI.Official.Internal.RunStepObjectStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectStatus"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.op_Inequality(OpenAI.Official.Internal.RunStepObjectStatus,OpenAI.Official.Internal.RunStepObjectStatus)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectStatus"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepObjectStatus">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepObjectStatus"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.Equals(OpenAI.Official.Internal.RunStepObjectStatus)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectStatus.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunStepObjectType">
            <summary> Enum for type in RunStepObject. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunStepObjectType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectType.MessageCreation">
            <summary> message_creation. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunStepObjectType.ToolCalls">
            <summary> tool_calls. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.op_Equality(OpenAI.Official.Internal.RunStepObjectType,OpenAI.Official.Internal.RunStepObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.op_Inequality(OpenAI.Official.Internal.RunStepObjectType,OpenAI.Official.Internal.RunStepObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunStepObjectType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.op_Implicit(System.String)~OpenAI.Official.Internal.RunStepObjectType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunStepObjectType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.Equals(OpenAI.Official.Internal.RunStepObjectType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunStepObjectType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.RunToolCallObject">
            <summary> Tool call objects. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunToolCallObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObject.#ctor(System.String,OpenAI.Official.Internal.RunToolCallObjectFunction)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObject"/>. </summary>
            <param name="id">
            The ID of the tool call. This ID must be referenced when you submit the tool outputs in using
            the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.
            </param>
            <param name="function"> The function definition. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> or <paramref name="function"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObject.#ctor(System.String,OpenAI.Official.Internal.RunToolCallObjectType,OpenAI.Official.Internal.RunToolCallObjectFunction,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObject"/>. </summary>
            <param name="id">
            The ID of the tool call. This ID must be referenced when you submit the tool outputs in using
            the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.
            </param>
            <param name="type"> The type of tool call the output is required for. For now, this is always `function`. </param>
            <param name="function"> The function definition. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObject.Id">
            <summary>
            The ID of the tool call. This ID must be referenced when you submit the tool outputs in using
            the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObject.Type">
            <summary> The type of tool call the output is required for. For now, this is always `function`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObject.Function">
            <summary> The function definition. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunToolCallObjectFunction">
            <summary> The RunToolCallObjectFunction. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.RunToolCallObjectFunction._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectFunction.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObjectFunction"/>. </summary>
            <param name="name"> The name of the function. </param>
            <param name="arguments"> The arguments that the model expects you to pass to the function. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="name"/> or <paramref name="arguments"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectFunction.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObjectFunction"/>. </summary>
            <param name="name"> The name of the function. </param>
            <param name="arguments"> The arguments that the model expects you to pass to the function. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectFunction.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObjectFunction"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObjectFunction.Name">
            <summary> The name of the function. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObjectFunction.Arguments">
            <summary> The arguments that the model expects you to pass to the function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectFunction.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectFunction.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.RunToolCallObjectType">
            <summary> The RunToolCallObject_type. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.RunToolCallObjectType"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.RunToolCallObjectType.Function">
            <summary> function. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.op_Equality(OpenAI.Official.Internal.RunToolCallObjectType,OpenAI.Official.Internal.RunToolCallObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunToolCallObjectType"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.op_Inequality(OpenAI.Official.Internal.RunToolCallObjectType,OpenAI.Official.Internal.RunToolCallObjectType)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.RunToolCallObjectType"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.op_Implicit(System.String)~OpenAI.Official.Internal.RunToolCallObjectType">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.RunToolCallObjectType"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.Equals(OpenAI.Official.Internal.RunToolCallObjectType)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.RunToolCallObjectType.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest">
            <summary> The SubmitToolOutputsRunRequest. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.SubmitToolOutputsRunRequest._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.#ctor(OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest"/>. </summary>
            <param name="toolOutputs"> A list of tools for which the outputs are being submitted. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="toolOutputs"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.#ctor(OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest"/>. </summary>
            <param name="toolOutputs"> A list of tools for which the outputs are being submitted. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequest"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.ToolOutputs">
            <summary> A list of tools for which the outputs are being submitted. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequest.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs">
            <summary> The SubmitToolOutputsRunRequestToolOutputs. </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs"/>. </summary>
            <param name="toolCallId">
            The ID of the tool call in the `required_action` object within the run object the output is
            being submitted for.
            </param>
            <param name="output"> The output of the tool call to be submitted to continue the run. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.ToolCallId">
            <summary>
            The ID of the tool call in the `required_action` object within the run object the output is
            being submitted for.
            </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.Output">
            <summary> The output of the tool call to be submitted to continue the run. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.SubmitToolOutputsRunRequestToolOutputs.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ThreadObject">
            <summary> Represents a thread that contains [messages](/docs/api-reference/messages). </summary>
        </member>
        <member name="F:OpenAI.Official.Internal.ThreadObject._serializedAdditionalRawData">
            <summary>
            Keeps track of any properties unknown to the library.
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)"/>.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)"/>.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObject.#ctor(System.String,System.DateTimeOffset,System.Collections.Generic.IReadOnlyDictionary{System.String,System.String})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ThreadObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the thread was created. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="id"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObject.#ctor(System.String,OpenAI.Official.Internal.ThreadObjectObject,System.DateTimeOffset,System.Collections.Generic.IReadOnlyDictionary{System.String,System.String},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ThreadObject"/>. </summary>
            <param name="id"> The identifier, which can be referenced in API endpoints. </param>
            <param name="object"> The object type, which is always `thread`. </param>
            <param name="createdAt"> The Unix timestamp (in seconds) for when the thread was created. </param>
            <param name="metadata">
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObject.#ctor">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ThreadObject"/> for deserialization. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ThreadObject.Id">
            <summary> The identifier, which can be referenced in API endpoints. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ThreadObject.Object">
            <summary> The object type, which is always `thread`. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ThreadObject.CreatedAt">
            <summary> The Unix timestamp (in seconds) for when the thread was created. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.ThreadObject.Metadata">
            <summary>
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing
            additional information about the object in a structured format. Keys can be a maximum of 64
            characters long and values can be a maxium of 512 characters long.
            </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObject.FromResponse(System.ClientModel.Primitives.PipelineResponse)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The result to deserialize the model from. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObject.ToRequestBody">
            <summary> Convert into a Utf8JsonRequestBody. </summary>
        </member>
        <member name="T:OpenAI.Official.Internal.ThreadObjectObject">
            <summary> The ThreadObject_object. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:OpenAI.Official.Internal.ThreadObjectObject"/>. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value"/> is null. </exception>
        </member>
        <member name="P:OpenAI.Official.Internal.ThreadObjectObject.Thread">
            <summary> thread. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.op_Equality(OpenAI.Official.Internal.ThreadObjectObject,OpenAI.Official.Internal.ThreadObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ThreadObjectObject"/> values are the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.op_Inequality(OpenAI.Official.Internal.ThreadObjectObject,OpenAI.Official.Internal.ThreadObjectObject)">
            <summary> Determines if two <see cref="T:OpenAI.Official.Internal.ThreadObjectObject"/> values are not the same. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.op_Implicit(System.String)~OpenAI.Official.Internal.ThreadObjectObject">
            <summary> Converts a string to a <see cref="T:OpenAI.Official.Internal.ThreadObjectObject"/>. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.Equals(System.Object)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.Equals(OpenAI.Official.Internal.ThreadObjectObject)">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.GetHashCode">
            <inheritdoc />
        </member>
        <member name="M:OpenAI.Official.Internal.ThreadObjectObject.ToString">
            <inheritdoc />
        </member>
        <member name="T:OpenAI.Official.Internal.Threads">
            <summary> The Threads sub-client. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Threads.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:OpenAI.Official.Internal.Threads.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.#ctor">
            <summary> Initializes a new instance of Threads for mocking. </summary>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.#ctor(System.ClientModel.Primitives.TelemetrySource,System.ClientModel.Primitives.Pipeline.MessagePipeline,System.ClientModel.KeyCredential,System.Uri)">
            <summary> Initializes a new instance of Threads. </summary>
            <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
            <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
            <param name="keyCredential"> The key credential to copy. </param>
            <param name="endpoint"> OpenAI Endpoint. </param>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.CreateThreadAsync(OpenAI.Official.Internal.CreateThreadRequest,System.Threading.CancellationToken)">
            <summary> Create a thread. </summary>
            <param name="thread"> The <see cref="T:OpenAI.Official.Internal.CreateThreadRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="thread"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.CreateThread(OpenAI.Official.Internal.CreateThreadRequest,System.Threading.CancellationToken)">
            <summary> Create a thread. </summary>
            <param name="thread"> The <see cref="T:OpenAI.Official.Internal.CreateThreadRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="thread"/> is null. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.CreateThreadAsync(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.CreateThreadAsync(OpenAI.Official.Internal.CreateThreadRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.CreateThread(System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Create a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.CreateThread(OpenAI.Official.Internal.CreateThreadRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.GetThreadAsync(System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a thread. </summary>
            <param name="threadId"> The ID of the thread to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.GetThread(System.String,System.Threading.CancellationToken)">
            <summary> Retrieves a thread. </summary>
            <param name="threadId"> The ID of the thread to retrieve. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.GetThreadAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.GetThreadAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.GetThread(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Retrieves a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.GetThread(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to retrieve. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.ModifyThreadAsync(System.String,OpenAI.Official.Internal.ModifyThreadRequest,System.Threading.CancellationToken)">
            <summary> Modifies a thread. </summary>
            <param name="threadId"> The ID of the thread to modify. Only the `metadata` can be modified. </param>
            <param name="thread"> The <see cref="T:OpenAI.Official.Internal.ModifyThreadRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="thread"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.ModifyThread(System.String,OpenAI.Official.Internal.ModifyThreadRequest,System.Threading.CancellationToken)">
            <summary> Modifies a thread. </summary>
            <param name="threadId"> The ID of the thread to modify. Only the `metadata` can be modified. </param>
            <param name="thread"> The <see cref="T:OpenAI.Official.Internal.ModifyThreadRequest"/> to use. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="thread"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.ModifyThreadAsync(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.ModifyThreadAsync(System.String,OpenAI.Official.Internal.ModifyThreadRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to modify. Only the `metadata` can be modified. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.ModifyThread(System.String,System.ClientModel.Primitives.RequestBody,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Modifies a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.ModifyThread(System.String,OpenAI.Official.Internal.ModifyThreadRequest,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to modify. Only the `metadata` can be modified. </param>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> or <paramref name="content"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.DeleteThreadAsync(System.String,System.Threading.CancellationToken)">
            <summary> Delete a thread. </summary>
            <param name="threadId"> The ID of the thread to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.DeleteThread(System.String,System.Threading.CancellationToken)">
            <summary> Delete a thread. </summary>
            <param name="threadId"> The ID of the thread to delete. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.DeleteThreadAsync(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.DeleteThreadAsync(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:OpenAI.Official.Internal.Threads.DeleteThread(System.String,System.ClientModel.RequestOptions)">
            <summary>
            [Protocol Method] Delete a thread.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:OpenAI.Official.Internal.Threads.DeleteThread(System.String,System.Threading.CancellationToken)"/> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="threadId"> The ID of the thread to delete. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="threadId"/> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="threadId"/> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:System.ClientModel.MessageFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
    </members>
</doc>
